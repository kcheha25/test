import cv2
import numpy as np
import matplotlib.pyplot as plt
from mmrotate.apis import inference_detector, init_detector

def apply_fourier_transform(image):
    """
    Applique la transformée de Fourier sur une image et retourne le spectre de fréquence.
    :param image: Image d'entrée (numpy array)
    :return: Spectre de fréquence
    """
    # Convertir l'image en niveau de gris si nécessaire
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Appliquer la transformée de Fourier sur l'image
    f = np.fft.fft2(gray_image)
    fshift = np.fft.fftshift(f)  # Décaler les fréquences basses au centre

    # Calculer la magnitude du spectre
    magnitude_spectrum = np.abs(fshift)

    return magnitude_spectrum, fshift

def plot_bboxes_with_fourier(image, result):
    """
    Affiche l'image avec les boîtes englobantes détectées et à côté, la transformée de Fourier pour chaque ROI.
    :param image: Image originale (numpy array)
    :param result: Résultats des détections (liste de bboxes [x, y, w, h, angle, score])
    """
    # Copier l'image originale pour dessiner les boîtes englobantes
    image_copy = image.copy()

    for i, bbox in enumerate(result[0]):  # result[0] est un tableau de bboxes
        x, y, w, h, angle, score = bbox

        # Découper la région d'intérêt (ROI) de l'image
        roi = image[int(y):int(y+h), int(x):int(x+w)]

        # Appliquer la transformée de Fourier sur la ROI
        magnitude_spectrum, _ = apply_fourier_transform(roi)

        # Afficher l'image originale avec la boîte englobante
        cv2.rectangle(image_copy, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)

        # Tracer l'image avec la transformée de Fourier
        plt.figure(figsize=(12, 6))

        # Image originale avec bbox
        plt.subplot(1, 2, 1)
        plt.imshow(cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB))
        plt.title(f"Image with bbox {i}")
        plt.axis('off')

        # Transformée de Fourier pour la ROI
        plt.subplot(1, 2, 2)
        plt.imshow(np.log(1 + magnitude_spectrum), cmap='gray')
        plt.title(f"Fourier Transform for bbox {i}")
        plt.axis('off')

        plt.show()

# Charger le modèle et les poids
config_file = 'configs/s2anet/s2anet_r50_fpn_1x_dota.py'
checkpoint_file = 'checkpoints/s2anet_r50.pth'
model = init_detector(config_file, checkpoint_file, device='cuda:0')

# Charger l'image à traiter
image_path = 'path_to_your_image.jpg'
image = cv2.imread(image_path)

# Faire les prédictions avec le modèle
result = inference_detector(model, image)

# Afficher les boîtes englobantes avec la transformée de Fourier pour chaque ROI
plot_bboxes_with_fourier(image, result)

import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks, cwt, morlet

def rotate_and_crop(image, bbox):
    """
    Effectue une rotation et extrait la région d'intérêt (ROI) en tenant compte de l'angle.
    """
    x, y, w, h, angle_rad, _ = bbox
    x, y, w, h = map(int, [x, y, w, h])
    
    # Convertir l'angle de radians en degrés
    angle_deg = np.degrees(angle_rad)

    # Définir la matrice de rotation
    center = (x, y)
    M = cv2.getRotationMatrix2D(center, -angle_deg, 1.0)

    # Faire pivoter l'image entière
    rotated_img = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]),
                                 flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

    # Extraire la région rectangulaire après rotation
    x1, y1 = int(x - w / 2), int(y - h / 2)
    x2, y2 = int(x + w / 2), int(y + h / 2)

    roi = rotated_img[max(y1, 0):min(y2, image.shape[0]), max(x1, 0):min(x2, image.shape[1])]
    
    return roi

def count_sheets_in_bbox(image, bbox):
    """
    Compte les feuillets dans une bbox détectée par MMRotate.
    """
    x, y, w, h, angle_rad, score = bbox  # Décompositions du bbox
    roi = rotate_and_crop(image, bbox)

    # Convertir en niveaux de gris
    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

    # Détection des contours (Sobel)
    edges = cv2.Sobel(gray_roi, cv2.CV_64F, 1, 0, ksize=3)
    edges = np.abs(edges)

    # Projection selon l'axe des feuillets (sommation des intensités)
    intensity_profile = np.sum(edges, axis=1)

    # Détection des pics dans le profil d'intensité
    peaks, _ = find_peaks(intensity_profile, distance=max(5, int(h * 0.1)), 
                          height=np.max(intensity_profile) * 0.3)

    # Appliquer la Transformée de Wavelet Continue (CWT)
    wavelet_scales = np.arange(1, 100)  # Plage de scales pour la CWT
    cwt_result = cwt(intensity_profile, morlet, wavelet_scales)

    # Trouver les pics dans la CWT (dans la direction de l'orientation)
    peak_indices = []
    for i in range(cwt_result.shape[0]):
        peaks_cwt, _ = find_peaks(np.abs(cwt_result[i]), distance=5)
        peak_indices.append(peaks_cwt)

    # Affichage des résultats
    plt.figure(figsize=(12, 6))

    # Affichage de l'image ROI
    plt.subplot(1, 3, 1)
    plt.imshow(gray_roi, cmap='gray')
    plt.title(f"ROI alignée - {len(peaks)} feuillets détectés")

    # Affichage du profil d'intensité avec pics détectés
    plt.subplot(1, 3, 2)
    plt.plot(intensity_profile)
    plt.scatter(peaks, intensity_profile[peaks], color='r')
    plt.title("Profil d'intensité avec pics")

    # Affichage du spectre CWT
    plt.subplot(1, 3, 3)
    plt.imshow(np.abs(cwt_result), aspect='auto', extent=[0, len(intensity_profile), 1, 100])
    plt.title("Spectre CWT")
    plt.colorbar(label="Magnitude")
    plt.xlabel("Position")
    plt.ylabel("Scales")
    plt.show()

    # Retourner le nombre de pics détectés
    return len(peaks)

# Chargement de l'image et exécution de MMRotate
image_path = "path_to_your_image.jpg"
image = cv2.imread(image_path)

# Résultats de l'inférence MMRotate
result = inference_detector(model, image)

# Boucle sur chaque bbox détectée
for bbox in result[0]:  
    num_sheets = count_sheets_in_bbox(image, bbox)
    print(f"Nombre estimé de feuillets dans la bbox {bbox[:4]} : {num_sheets}")




