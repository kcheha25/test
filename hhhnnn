import cv2
import numpy as np
import matplotlib.pyplot as plt
import pywt
from scipy.signal import find_peaks
from scipy.fftpack import fft

def rotate_and_crop(image, bbox):
    """
    Effectue une rotation et extrait la r√©gion d'int√©r√™t (ROI) en tenant compte de l'angle.
    """
    x, y, w, h, angle_rad, _ = bbox
    x, y, w, h = map(int, [x, y, w, h])
    
    angle_deg = np.degrees(angle_rad)
    center = (x, y)
    M = cv2.getRotationMatrix2D(center, -angle_deg, 1.0)

    rotated_img = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]),
                                 flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

    x1, y1 = int(x - w / 2), int(y - h / 2)
    x2, y2 = int(x + w / 2), int(y + h / 2)

    roi = rotated_img[max(y1, 0):min(y2, image.shape[0]), max(x1, 0):min(x2, image.shape[1])]
    
    return roi

def integrate_in_orientation(image, bbox):
    """
    Projette les intensit√©s dans la direction de l'angle de la bbox.
    """
    x, y, w, h, angle_rad, _ = bbox
    roi = rotate_and_crop(image, bbox)

    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

    angle_deg = np.degrees(angle_rad)
    direction = np.array([np.cos(angle_rad), np.sin(angle_rad)])

    rows, cols = gray_roi.shape
    projection = np.zeros(rows)

    for i in range(rows):
        for j in range(cols):
            x_proj = int(i + direction[0] * j)
            y_proj = int(j + direction[1] * i)

            if 0 <= x_proj < rows and 0 <= y_proj < cols:
                projection[i] += gray_roi[x_proj, y_proj]
    
    return projection

def count_sheets_in_bbox(image, bbox):
    """
    Applique plusieurs m√©thodes d'analyse sur le profil d'intensit√© :
    1. D√©tection des pics
    2. Analyse spectrale FFT
    3. D√©composition multi-niveaux (wavedec)
    4. D√©composition simple (dwt)
    """
    intensity_profile = integrate_in_orientation(image, bbox)

    # 1. D√©tection des pics
    peaks, _ = find_peaks(intensity_profile, distance=max(5, int(len(intensity_profile) * 0.1)), 
                          height=np.max(intensity_profile) * 0.3)

    # 2. Spectre FFT
    fft_spectrum = np.abs(fft(intensity_profile))
    fft_freqs = np.fft.fftfreq(len(intensity_profile))

    # D√©tection de la fr√©quence dominante
    peak_idx = np.argmax(fft_spectrum[1:]) + 1  # On ignore la fr√©quence DC (0)
    dominant_freq = abs(fft_freqs[peak_idx])

    # 3. D√©composition multi-niveaux par ondelettes de Haar
    coeffs = pywt.wavedec(intensity_profile, 'haar', level=3)
    haar_spectrum = coeffs[0]  # Approximation de bas niveau

    # 4. D√©composition simple (DWT niveau 1)
    cA, cD = pywt.dwt(intensity_profile, 'haar')

    # Affichage des r√©sultats
    fig, axes = plt.subplots(2, 3, figsize=(18, 8))

    # (a) Profil d'intensit√© avec pics
    axes[0, 0].plot(intensity_profile, label="Profil d'intensit√©")
    axes[0, 0].scatter(peaks, intensity_profile[peaks], color='r', label="Pics d√©tect√©s")
    axes[0, 0].set_title(f"Find Peaks - {len(peaks)} feuillets d√©tect√©s")
    axes[0, 0].legend()

    # (b) Spectre FFT brut
    axes[0, 1].plot(fft_freqs[:len(fft_freqs)//2], fft_spectrum[:len(fft_spectrum)//2])
    axes[0, 1].set_title("Spectre FFT - Brute")

    # (c) Spectre FFT avec fr√©quence dominante
    axes[0, 2].plot(fft_freqs[:len(fft_freqs)//2], fft_spectrum[:len(fft_spectrum)//2], label="FFT Spectrum")
    axes[0, 2].axvline(dominant_freq, color='r', linestyle='--', label=f"Fr√©quence dominante: {dominant_freq:.2f}")
    axes[0, 2].set_title("Spectre FFT avec pic marqu√©")
    axes[0, 2].legend()

    # (d) D√©composition multi-niveaux (wavedec)
    axes[1, 0].plot(haar_spectrum)
    axes[1, 0].set_title("Spectre Haar (wavedec)")

    # (e) D√©composition simple (DWT niveau 1)
    axes[1, 1].plot(cA, label="Approximation (cA)")
    axes[1, 1].plot(cD, label="D√©tails (cD)", linestyle="dashed")
    axes[1, 1].set_title("DWT Niveau 1 - Approximation & D√©tails")
    axes[1, 1].legend()

    # (f) ROI extraite
    roi = rotate_and_crop(image, bbox)
    axes[1, 2].imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
    axes[1, 2].set_title("ROI align√©e")

    plt.tight_layout()
    plt.show()

    return len(peaks)

# Chargement de l'image et ex√©cution de MMRotate
image_path = "path_to_your_image.jpg"
image = cv2.imread(image_path)

# R√©sultats de l'inf√©rence MMRotate
result = inference_detector(model, image)

# Boucle sur chaque bbox d√©tect√©e
for bbox in result[0]:  
    num_sheets = count_sheets_in_bbox(image, bbox)
    print(f"Nombre estim√© de feuillets dans la bbox {bbox[:4]} : {num_sheets}")

import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from sklearn.cluster import KMeans

def apply_kmeans_segmentation(roi):
    """
    Applique K-means clustering √† 2 classes sur une ROI en niveaux de gris.
    """
    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    
    # Mise en forme des donn√©es pour K-means (transforme en un vecteur de pixels)
    pixels = gray_roi.reshape(-1, 1)
    
    # Application du K-means clustering
    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
    kmeans.fit(pixels)
    labels = kmeans.labels_.reshape(gray_roi.shape)  # Remettre sous forme d'image
    
    # Cr√©ation d'une image couleur pour la visualisation des clusters
    segmented_img = np.zeros_like(roi)
    segmented_img[labels == 0] = [255, 0, 0]  # Bleu pour une classe
    segmented_img[labels == 1] = [0, 255, 0]  # Vert pour l'autre
    
    return segmented_img

def count_sheets_with_kmeans(image, bbox):
    """
    Compte les feuillets dans une bbox et applique K-means clustering sur la ROI.
    """
    roi = rotate_and_crop(image, bbox)
    
    # Appliquer K-means clustering
    segmented_roi = apply_kmeans_segmentation(roi)
    
    # Calcul du profil d'intensit√© projet√©
    intensity_profile = integrate_in_orientation(image, bbox)
    
    # D√©tection des pics dans le profil d'intensit√© projet√©
    peaks, _ = find_peaks(intensity_profile, distance=max(5, int(bbox[3] * 0.1)),
                          height=np.max(intensity_profile) * 0.3)
    
    # Affichage des r√©sultats
    plt.figure(figsize=(12, 6))
    
    # Affichage du profil d'intensit√© projet√© avec pics d√©tect√©s
    plt.subplot(1, 3, 1)
    plt.plot(intensity_profile)
    plt.scatter(peaks, intensity_profile[peaks], color='r')
    plt.title(f"Profil d'intensit√© - {len(peaks)} feuillets d√©tect√©s")
    
    # Affichage de la ROI originale
    plt.subplot(1, 3, 2)
    plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
    plt.title("ROI align√©e")
    
    # Affichage de la segmentation K-means
    plt.subplot(1, 3, 3)
    plt.imshow(segmented_roi)
    plt.title("Segmentation K-means")
    
    plt.show()
    
    return len(peaks)

# Exemple d'utilisation avec une image et des bbox d√©tect√©es
image_path = "path_to_your_image.jpg"
image = cv2.imread(image_path)

# R√©sultats de l'inf√©rence du mod√®le de d√©tection (ex: MMRotate)
result = inference_detector(model, image)

for bbox in result[0]:  
    num_sheets = count_sheets_with_kmeans(image, bbox)
    print(f"Nombre estim√© de feuillets dans la bbox {bbox[:4]} : {num_sheets}")
def apply_kmeans_segmentation(roi, n_clusters=2):
    """
    Applique K-means clustering avec un nombre dynamique de classes sur une ROI en niveaux de gris.
    """
    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    
    # Mise en forme des donn√©es pour K-means (transforme en un vecteur de pixels)
    pixels = gray_roi.reshape(-1, 1)
    
    # Application du K-means clustering
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    kmeans.fit(pixels)
    labels = kmeans.labels_.reshape(gray_roi.shape)  # Remettre sous forme d'image
    
    # G√©n√©rer des couleurs dynamiques pour chaque cluster
    colors = np.random.randint(0, 255, (n_clusters, 3), dtype=np.uint8)
    
    # Cr√©ation d'une image couleur pour visualisation des clusters
    segmented_img = np.zeros_like(roi)
    for k in range(n_clusters):
        segmented_img[labels == k] = colors[k]
    
    return segmented_img

    import cv2
import numpy as np
import matplotlib.pyplot as plt

import os

def yolo_to_dota(yolo_file, img_width, img_height, class_names, output_dir):
    """
    Convertit un fichier d'annotations YOLO en format DOTA.
    yolo_file : Chemin vers le fichier d'annotations YOLO (.txt).
    img_width, img_height : Largeur et hauteur de l'image en pixels.
    class_names : Liste des noms de classes pour l'indexation.
    output_dir : R√©pertoire o√π les fichiers DOTA seront enregistr√©s.
    """
    
    with open(yolo_file, 'r') as f:
        annotations = f.readlines()

    dota_annotations = []
    
    for annotation in annotations:
        parts = annotation.strip().split()
        
        # Convertir les coordonn√©es de YOLO en coordonn√©es r√©elles
        class_id = int(parts[0])
        x_center = float(parts[1]) * img_width
        y_center = float(parts[2]) * img_height
        width = float(parts[3]) * img_width
        height = float(parts[4]) * img_height
        
        # Calculer les coins de la bounding box (rectangle orient√©)
        x1 = x_center - width / 2
        y1 = y_center - height / 2
        x2 = x_center + width / 2
        y2 = y_center - height / 2
        x3 = x_center + width / 2
        y3 = y_center + height / 2
        x4 = x_center - width / 2
        y4 = y_center + height / 2
        
        # Formater la ligne pour DOTA
        dota_annotation = f"{x1} {y1} {x2} {y2} {x3} {y3} {x4} {y4} {class_id} 0"
        dota_annotations.append(dota_annotation)
    
    # Enregistrer les annotations DOTA dans un fichier
    output_file = os.path.join(output_dir, os.path.basename(yolo_file).replace('.txt', '.txt'))
    with open(output_file, 'w') as f:
        f.write("\n".join(dota_annotations))
    
    print(f"Conversion termin√©e pour {yolo_file}. Les annotations DOTA ont √©t√© enregistr√©es dans {output_file}.")

def convert_yolo_to_dota(yolo_dir, img_dir, class_names, output_dir):
    """
    Convertit toutes les annotations YOLO d'un r√©pertoire en format DOTA.
    yolo_dir : R√©pertoire contenant les fichiers d'annotations YOLO (.txt).
    img_dir : R√©pertoire contenant les images (utilis√© pour obtenir la taille des images).
    class_names : Liste des noms de classes.
    output_dir : R√©pertoire o√π les fichiers DOTA seront enregistr√©s.
    """
    
    os.makedirs(output_dir, exist_ok=True)

    for yolo_file in os.listdir(yolo_dir):
        if yolo_file.endswith('.txt'):
            img_path = os.path.join(img_dir, yolo_file.replace('.txt', '.jpg'))  # Assumer que les images sont en .jpg
            img = cv2.imread(img_path)
            img_height, img_width = img.shape[:2]
            
            yolo_to_dota(os.path.join(yolo_dir, yolo_file), img_width, img_height, class_names, output_dir)

# Exemple d'utilisation
class_names = ["plane", "car", "bus", "train"]  # Liste des classes
yolo_dir = 'path/to/yolo/annotations'
img_dir = 'path/to/images'
output_dir = 'path/to/output/dota_annotations'

convert_yolo_to_dota(yolo_dir, img_dir, class_names, output_dir)


    projections = integrate_in_orientation(image, bbox)

    # Identifier la projection avec la plus grande valeur individuelle
    projections_values = [
        (max(projections[0]), 'Projection principale'),
        (max(projections[1]), 'Projection perpendiculaire'),
        (max(projections[2]), 'Projection diagonale 1'),
        (max(projections[3]), 'Projection diagonale 2')
    ]

    # Trouver la projection avec la plus grande valeur
    max_value_proj, max_proj_name = max(projections_values, key=lambda x: x[0])

    # Choisir la projection ayant la plus grande valeur
    if max_proj_name == 'Projection principale':
        max_value_proj = projections[0]
    elif max_proj_name == 'Projection perpendiculaire':
        max_value_proj = projections[1]
    elif max_proj_name == 'Projection diagonale 1':
        max_value_proj = projections[2]
    else:
        max_value_proj = projections[3]

    # Appliquer find_peaks sur la projection avec la plus grande valeur
    peaks, _ = find_peaks(max_value_proj, distance=max(5, int(len(max_value_proj) * 0.1)),
                          height=np.max(max_value_proj) * 0.3)

    # Affichage du r√©sultat
    print(f"Projection choisie : {max_proj_name}")


import cv2
import numpy as np
import matplotlib.pyplot as plt

def read_dota_annotations(txt_file):
    """Lire les annotations DOTA depuis un fichier texte."""
    annotations = []
    
    with open(txt_file, 'r') as f:
        for line in f.readlines():
            data = line.strip().split()
            # Les 8 premiers √©l√©ments correspondent aux coordonn√©es des coins du polygone
            polygon = list(map(float, data[:8]))  # x1, y1, x2, y2, x3, y3, x4, y4
            annotations.append(polygon)
    
    return annotations

def draw_dota_annotations(image, annotations):
    """Dessiner les annotations DOTA (polygones) sur l'image."""
    for polygon in annotations:
        # Convertir les coordonn√©es du polygone en format numpy array pour pouvoir dessiner
        pts = np.array(polygon).reshape((-1, 1, 2)).astype(np.int32)
        # Dessiner le polygone en rouge
        cv2.polylines(image, [pts], isClosed=True, color=(0, 0, 255), thickness=2)

def visualize_image_with_annotations(image_path, txt_file):
    """Afficher l'image avec les annotations DOTA."""
    # Charger l'image
    image = cv2.imread(image_path)
    
    # Lire les annotations DOTA depuis le fichier texte
    annotations = read_dota_annotations(txt_file)
    
    # Dessiner les annotations sur l'image
    draw_dota_annotations(image, annotations)
    
    # Convertir l'image BGR en RGB pour l'affichage avec Matplotlib
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # Afficher l'image avec les annotations
    plt.figure(figsize=(10, 10))
    plt.imshow(image_rgb)
    plt.axis('off')
    plt.show()

# Exemple d'utilisation :
image_path = 'path/to/your/image.jpg'  # Chemin vers l'image
txt_file = 'path/to/your/image.txt'    # Chemin vers le fichier d'annotations .txt

visualize_image_with_annotations(image_path, txt_file)

import os
import json
import glob
import cv2
import numpy as np

def convert_labelme_to_dota(json_path, output_txt_path):
    """ Convertit un fichier JSON LabelMe en annotation DOTA avec approximation en 4 points. """
    
    with open(json_path, 'r') as f:
        data = json.load(f)

    dota_annotations = []

    for shape in data["shapes"]:
        points = np.array(shape["points"], dtype=np.int32)  # Convertir en numpy array

        # Calculer la bo√Æte englobante (bounding box)
        x, y, w, h = cv2.boundingRect(points)

        # G√©n√©rer les 4 coins du rectangle
        bbox = [x, y, x + w, y, x + w, y + h, x, y + h]

        label = shape["label"]
        
        # Ajouter au format DOTA (x1 y1 x2 y2 x3 y3 x4 y4 label difficulty)
        dota_annotations.append(f"{' '.join(map(str, bbox))} {label} 0")

    # Sauvegarder dans un fichier .txt
    with open(output_txt_path, 'w') as f:
        f.write("\n".join(dota_annotations))

def process_dataset(json_folder, output_folder):
    """ Convertit tous les fichiers JSON LabelMe d'un dossier en format DOTA. """
    
    os.makedirs(output_folder, exist_ok=True)  # Cr√©er le dossier de sortie s'il n'existe pas

    json_files = glob.glob(os.path.join(json_folder, "*.json"))  # R√©cup√©rer tous les fichiers JSON

    for json_file in json_files:
        output_txt = os.path.join(output_folder, os.path.basename(json_file).replace(".json", ".txt"))

        convert_labelme_to_dota(json_file, output_txt)
        print(f"‚úÖ Converti : {json_file} ‚Üí {output_txt}")

# üîπ Exemple d'utilisation
json_folder = "path/to/labelme_annotations"  # Dossier contenant les JSON LabelMe
output_folder = "path/to/dota_annotations"   # Dossier o√π enregistrer les fichiers DOTA

process_dataset(json_folder, output_folder)

