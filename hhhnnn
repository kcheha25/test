import cv2
import numpy as np
import matplotlib.pyplot as plt
import pywt
from scipy.signal import find_peaks
from scipy.fftpack import fft

def rotate_and_crop(image, bbox):
    """
    Effectue une rotation et extrait la région d'intérêt (ROI) en tenant compte de l'angle.
    """
    x, y, w, h, angle_rad, _ = bbox
    x, y, w, h = map(int, [x, y, w, h])
    
    angle_deg = np.degrees(angle_rad)
    center = (x, y)
    M = cv2.getRotationMatrix2D(center, -angle_deg, 1.0)

    rotated_img = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]),
                                 flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

    x1, y1 = int(x - w / 2), int(y - h / 2)
    x2, y2 = int(x + w / 2), int(y + h / 2)

    roi = rotated_img[max(y1, 0):min(y2, image.shape[0]), max(x1, 0):min(x2, image.shape[1])]
    
    return roi

def integrate_in_orientation(image, bbox):
    """
    Projette les intensités dans la direction de l'angle de la bbox.
    """
    x, y, w, h, angle_rad, _ = bbox
    roi = rotate_and_crop(image, bbox)

    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

    angle_deg = np.degrees(angle_rad)
    direction = np.array([np.cos(angle_rad), np.sin(angle_rad)])

    rows, cols = gray_roi.shape
    projection = np.zeros(rows)

    for i in range(rows):
        for j in range(cols):
            x_proj = int(i + direction[0] * j)
            y_proj = int(j + direction[1] * i)

            if 0 <= x_proj < rows and 0 <= y_proj < cols:
                projection[i] += gray_roi[x_proj, y_proj]
    
    return projection

def count_sheets_in_bbox(image, bbox):
    """
    Applique plusieurs méthodes d'analyse sur le profil d'intensité :
    1. Détection des pics
    2. Analyse spectrale FFT
    3. Décomposition multi-niveaux (wavedec)
    4. Décomposition simple (dwt)
    """
    intensity_profile = integrate_in_orientation(image, bbox)

    # 1. Détection des pics
    peaks, _ = find_peaks(intensity_profile, distance=max(5, int(len(intensity_profile) * 0.1)), 
                          height=np.max(intensity_profile) * 0.3)

    # 2. Spectre FFT
    fft_spectrum = np.abs(fft(intensity_profile))
    fft_freqs = np.fft.fftfreq(len(intensity_profile))

    # Détection de la fréquence dominante
    peak_idx = np.argmax(fft_spectrum[1:]) + 1  # On ignore la fréquence DC (0)
    dominant_freq = abs(fft_freqs[peak_idx])

    # 3. Décomposition multi-niveaux par ondelettes de Haar
    coeffs = pywt.wavedec(intensity_profile, 'haar', level=3)
    haar_spectrum = coeffs[0]  # Approximation de bas niveau

    # 4. Décomposition simple (DWT niveau 1)
    cA, cD = pywt.dwt(intensity_profile, 'haar')

    # Affichage des résultats
    fig, axes = plt.subplots(2, 3, figsize=(18, 8))

    # (a) Profil d'intensité avec pics
    axes[0, 0].plot(intensity_profile, label="Profil d'intensité")
    axes[0, 0].scatter(peaks, intensity_profile[peaks], color='r', label="Pics détectés")
    axes[0, 0].set_title(f"Find Peaks - {len(peaks)} feuillets détectés")
    axes[0, 0].legend()

    # (b) Spectre FFT brut
    axes[0, 1].plot(fft_freqs[:len(fft_freqs)//2], fft_spectrum[:len(fft_spectrum)//2])
    axes[0, 1].set_title("Spectre FFT - Brute")

    # (c) Spectre FFT avec fréquence dominante
    axes[0, 2].plot(fft_freqs[:len(fft_freqs)//2], fft_spectrum[:len(fft_spectrum)//2], label="FFT Spectrum")
    axes[0, 2].axvline(dominant_freq, color='r', linestyle='--', label=f"Fréquence dominante: {dominant_freq:.2f}")
    axes[0, 2].set_title("Spectre FFT avec pic marqué")
    axes[0, 2].legend()

    # (d) Décomposition multi-niveaux (wavedec)
    axes[1, 0].plot(haar_spectrum)
    axes[1, 0].set_title("Spectre Haar (wavedec)")

    # (e) Décomposition simple (DWT niveau 1)
    axes[1, 1].plot(cA, label="Approximation (cA)")
    axes[1, 1].plot(cD, label="Détails (cD)", linestyle="dashed")
    axes[1, 1].set_title("DWT Niveau 1 - Approximation & Détails")
    axes[1, 1].legend()

    # (f) ROI extraite
    roi = rotate_and_crop(image, bbox)
    axes[1, 2].imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
    axes[1, 2].set_title("ROI alignée")

    plt.tight_layout()
    plt.show()

    return len(peaks)

# Chargement de l'image et exécution de MMRotate
image_path = "path_to_your_image.jpg"
image = cv2.imread(image_path)

# Résultats de l'inférence MMRotate
result = inference_detector(model, image)

# Boucle sur chaque bbox détectée
for bbox in result[0]:  
    num_sheets = count_sheets_in_bbox(image, bbox)
    print(f"Nombre estimé de feuillets dans la bbox {bbox[:4]} : {num_sheets}")

import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from sklearn.cluster import KMeans

def apply_kmeans_segmentation(roi):
    """
    Applique K-means clustering à 2 classes sur une ROI en niveaux de gris.
    """
    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    
    # Mise en forme des données pour K-means (transforme en un vecteur de pixels)
    pixels = gray_roi.reshape(-1, 1)
    
    # Application du K-means clustering
    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
    kmeans.fit(pixels)
    labels = kmeans.labels_.reshape(gray_roi.shape)  # Remettre sous forme d'image
    
    # Création d'une image couleur pour la visualisation des clusters
    segmented_img = np.zeros_like(roi)
    segmented_img[labels == 0] = [255, 0, 0]  # Bleu pour une classe
    segmented_img[labels == 1] = [0, 255, 0]  # Vert pour l'autre
    
    return segmented_img

def count_sheets_with_kmeans(image, bbox):
    """
    Compte les feuillets dans une bbox et applique K-means clustering sur la ROI.
    """
    roi = rotate_and_crop(image, bbox)
    
    # Appliquer K-means clustering
    segmented_roi = apply_kmeans_segmentation(roi)
    
    # Calcul du profil d'intensité projeté
    intensity_profile = integrate_in_orientation(image, bbox)
    
    # Détection des pics dans le profil d'intensité projeté
    peaks, _ = find_peaks(intensity_profile, distance=max(5, int(bbox[3] * 0.1)),
                          height=np.max(intensity_profile) * 0.3)
    
    # Affichage des résultats
    plt.figure(figsize=(12, 6))
    
    # Affichage du profil d'intensité projeté avec pics détectés
    plt.subplot(1, 3, 1)
    plt.plot(intensity_profile)
    plt.scatter(peaks, intensity_profile[peaks], color='r')
    plt.title(f"Profil d'intensité - {len(peaks)} feuillets détectés")
    
    # Affichage de la ROI originale
    plt.subplot(1, 3, 2)
    plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
    plt.title("ROI alignée")
    
    # Affichage de la segmentation K-means
    plt.subplot(1, 3, 3)
    plt.imshow(segmented_roi)
    plt.title("Segmentation K-means")
    
    plt.show()
    
    return len(peaks)

# Exemple d'utilisation avec une image et des bbox détectées
image_path = "path_to_your_image.jpg"
image = cv2.imread(image_path)

# Résultats de l'inférence du modèle de détection (ex: MMRotate)
result = inference_detector(model, image)

for bbox in result[0]:  
    num_sheets = count_sheets_with_kmeans(image, bbox)
    print(f"Nombre estimé de feuillets dans la bbox {bbox[:4]} : {num_sheets}")
def apply_kmeans_segmentation(roi, n_clusters=2):
    """
    Applique K-means clustering avec un nombre dynamique de classes sur une ROI en niveaux de gris.
    """
    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    
    # Mise en forme des données pour K-means (transforme en un vecteur de pixels)
    pixels = gray_roi.reshape(-1, 1)
    
    # Application du K-means clustering
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    kmeans.fit(pixels)
    labels = kmeans.labels_.reshape(gray_roi.shape)  # Remettre sous forme d'image
    
    # Générer des couleurs dynamiques pour chaque cluster
    colors = np.random.randint(0, 255, (n_clusters, 3), dtype=np.uint8)
    
    # Création d'une image couleur pour visualisation des clusters
    segmented_img = np.zeros_like(roi)
    for k in range(n_clusters):
        segmented_img[labels == k] = colors[k]
    
    return segmented_img

    import cv2
import numpy as np
import matplotlib.pyplot as plt

import os

def yolo_to_dota(yolo_file, img_width, img_height, class_names, output_dir):
    """
    Convertit un fichier d'annotations YOLO en format DOTA.
    yolo_file : Chemin vers le fichier d'annotations YOLO (.txt).
    img_width, img_height : Largeur et hauteur de l'image en pixels.
    class_names : Liste des noms de classes pour l'indexation.
    output_dir : Répertoire où les fichiers DOTA seront enregistrés.
    """
    
    with open(yolo_file, 'r') as f:
        annotations = f.readlines()

    dota_annotations = []
    
    for annotation in annotations:
        parts = annotation.strip().split()
        
        # Convertir les coordonnées de YOLO en coordonnées réelles
        class_id = int(parts[0])
        x_center = float(parts[1]) * img_width
        y_center = float(parts[2]) * img_height
        width = float(parts[3]) * img_width
        height = float(parts[4]) * img_height
        
        # Calculer les coins de la bounding box (rectangle orienté)
        x1 = x_center - width / 2
        y1 = y_center - height / 2
        x2 = x_center + width / 2
        y2 = y_center - height / 2
        x3 = x_center + width / 2
        y3 = y_center + height / 2
        x4 = x_center - width / 2
        y4 = y_center + height / 2
        
        # Formater la ligne pour DOTA
        dota_annotation = f"{x1} {y1} {x2} {y2} {x3} {y3} {x4} {y4} {class_id} 0"
        dota_annotations.append(dota_annotation)
    
    # Enregistrer les annotations DOTA dans un fichier
    output_file = os.path.join(output_dir, os.path.basename(yolo_file).replace('.txt', '.txt'))
    with open(output_file, 'w') as f:
        f.write("\n".join(dota_annotations))
    
    print(f"Conversion terminée pour {yolo_file}. Les annotations DOTA ont été enregistrées dans {output_file}.")

def convert_yolo_to_dota(yolo_dir, img_dir, class_names, output_dir):
    """
    Convertit toutes les annotations YOLO d'un répertoire en format DOTA.
    yolo_dir : Répertoire contenant les fichiers d'annotations YOLO (.txt).
    img_dir : Répertoire contenant les images (utilisé pour obtenir la taille des images).
    class_names : Liste des noms de classes.
    output_dir : Répertoire où les fichiers DOTA seront enregistrés.
    """
    
    os.makedirs(output_dir, exist_ok=True)

    for yolo_file in os.listdir(yolo_dir):
        if yolo_file.endswith('.txt'):
            img_path = os.path.join(img_dir, yolo_file.replace('.txt', '.jpg'))  # Assumer que les images sont en .jpg
            img = cv2.imread(img_path)
            img_height, img_width = img.shape[:2]
            
            yolo_to_dota(os.path.join(yolo_dir, yolo_file), img_width, img_height, class_names, output_dir)

# Exemple d'utilisation
class_names = ["plane", "car", "bus", "train"]  # Liste des classes
yolo_dir = 'path/to/yolo/annotations'
img_dir = 'path/to/images'
output_dir = 'path/to/output/dota_annotations'

convert_yolo_to_dota(yolo_dir, img_dir, class_names, output_dir)
