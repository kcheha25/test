import pandas as pd
from collections import defaultdict

# Exemple
data = {
    "pics": [
        {"12.4": ["A"], "25.3": ["B"], "55.1": ["C"]},     # Chrom 0
        {"11.1": ["A"], "26.8": ["B"], "57.7": ["C"]},     # Chrom 1 (identique √† 0)
        {"10.0": ["B"], "22.0": ["C"], "33.0": ["A"]},     # Chrom 2 (m√™me noms mais ordre diff√©rent)
        {"8.0": ["A"], "30.0": ["B"]},                     # Chrom 3 (diff√©rent)
        {"15.0": ["A"], "25.0": ["B"], "55.0": ["C"]},     # Chrom 4 (identique √† 0 et 1)
    ]
}
df = pd.DataFrame(data)

# Extraire les s√©quences ordonn√©es des noms de pics pour chaque chromatogramme
def extract_ordered_component_sequence(pic_dict):
    sorted_items = sorted(pic_dict.items(), key=lambda x: float(x[0]))  # tri√© par temps
    return tuple([v[0] for _, v in sorted_items if float(_) <= 150])  # tuple immuable

# Dictionnaire de regroupement : cl√© = s√©quence, valeur = indices
sequence_to_indices = defaultdict(list)

for idx, row in df.iterrows():
    sequence = extract_ordered_component_sequence(row["pics"])
    sequence_to_indices[sequence].append(idx)

# Affichage
print("Groupes de chromatogrammes avec m√™me s√©quence ordonn√©e de noms de composants :\n")
for seq, indices in sequence_to_indices.items():
    if len(indices) > 1:
        print(f"S√©quence {seq} ‚Üí Chromatogrammes {indices}")


import pandas as pd
from collections import defaultdict
import matplotlib.pyplot as plt
import itertools

# Exemple de donn√©es simul√©es
data = {
    "pics": [
        {"12.4": ["A"], "25.3": ["B"], "55.1": ["C"]},     # Chrom 0
        {"11.1": ["A"], "26.8": ["B"], "57.7": ["C"]},     # Chrom 1 ‚Üí m√™me s√©quence
        {"10.0": ["B"], "22.0": ["C"], "33.0": ["A"]},     # Chrom 2 ‚Üí m√™me longueur mais ordre diff√©rent
        {"8.0": ["A"], "30.0": ["B"]},                     # Chrom 3 ‚Üí 2 pics
        {"15.0": ["A"], "25.0": ["B"], "55.0": ["C"]},     # Chrom 4 ‚Üí m√™me s√©quence
    ]
}
df = pd.DataFrame(data)

# 1. Extraire les s√©quences ordonn√©es et les temps correspondants
def extract_sequence_and_times(row):
    sorted_items = sorted(row["pics"].items(), key=lambda x: float(x[0]))
    names = []
    times = []
    for time_str, val in sorted_items:
        time = float(time_str)
        if time <= 150:
            names.append(val[0])
            times.append(time)
    return tuple(names), times

# Stockage
sequence_to_chroms = defaultdict(list)
chrom_to_times = {}

for idx, row in df.iterrows():
    sequence, times = extract_sequence_and_times(row)
    if len(sequence) == len(times):  # s√©curit√©
        sequence_to_chroms[sequence].append(idx)
        chrom_to_times[idx] = times

# 2. Comparer uniquement les chromatogrammes avec EXACTEMENT la m√™me s√©quence (ordre et nombre)
for sequence, chrom_indices in sequence_to_chroms.items():
    if len(chrom_indices) < 2:
        continue

    print(f"\nS√©quence {sequence} : {chrom_indices}")

    # 3. Tracer pour chaque couple
    for i, j in itertools.combinations(chrom_indices, 2):
        x = chrom_to_times[i]
        y = chrom_to_times[j]

        if len(x) != len(y):
            continue  # on saute les tailles diff√©rentes par s√©curit√©

        plt.figure(figsize=(5, 5))
        plt.scatter(x, y, color='blue')
        for xi, yi, label in zip(x, y, sequence):
            plt.text(xi, yi, label, fontsize=9, ha='right', va='bottom')

        plt.title(f"Nuage de points : Chrom {i} vs Chrom {j}")
        plt.xlabel(f"Temps r√©tention Chrom {i}")
        plt.ylabel(f"Temps r√©tention Chrom {j}")
        plt.grid(True)
        plt.axis("equal")
        plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Supposons que df est d√©j√† charg√© avec tes donn√©es r√©elles
# Exemple : df = pd.read_json("mon_fichier.json")

# --- √âtape 1 : Extraire les temps par nom de composant ---
def get_component_to_time(row):
    component_to_time = {}
    for time_str, data in row["pics"].items():
        time = float(time_str)
        if time <= 150:
            name = data[0]
            component_to_time[name] = time
    return component_to_time

# Choisir les indices des deux chromatogrammes √† comparer
i, j = 81, 89

# S√©curit√© : v√©rifier les indices
if i not in df.index or j not in df.index:
    print(f"Les indices {i} ou {j} ne sont pas valides dans le DataFrame.")
else:
    comp_time_i = get_component_to_time(df.loc[i])
    comp_time_j = get_component_to_time(df.loc[j])

    # Intersection des noms de composants pr√©sents dans les deux chromatogrammes
    common_names = set(comp_time_i.keys()) & set(comp_time_j.keys())

    if not common_names:
        print(f"Aucun pic en commun entre les chromatogrammes {i} et {j}.")
    else:
        # Cr√©er les listes x et y √† partir des noms communs
        x = [comp_time_i[name] for name in common_names]
        y = [comp_time_j[name] for name in common_names]

        # Affichage du nuage de points
        plt.figure(figsize=(6, 6))
        plt.scatter(x, y, color='green')

        for xi, yi, label in zip(x, y, common_names):
            plt.text(xi, yi, label, fontsize=9, ha='right', va='bottom')

        plt.title(f"Nuage de points : Chrom {i} vs Chrom {j}")
        plt.xlabel(f"Temps de r√©tention Chrom {i}")
        plt.ylabel(f"Temps de r√©tention Chrom {j}")
        plt.grid(True)
        plt.axis("equal")
        plt.show()
import matplotlib.pyplot as plt 
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
import tkinter as tk
import pandas as pd
import numpy as np

data = {
    "pics": [
        {"12.4": ["A"], "25.3": ["B"], "55.1": ["A"]},
        {"22.1": ["B"], "45.2": ["C"], "80.3": ["A"]},
        {"130.4": ["C"], "140.3": ["B"], "110.0": ["A"]},
    ],
    "x": [np.linspace(0, 150, 300)] * 3,
    "y": [
        np.sin(np.linspace(0, 15, 300)) + np.random.normal(0, 0.05, 300),
        np.cos(np.linspace(0, 10, 300)) + np.random.normal(0, 0.05, 300),
        np.sin(np.linspace(0, 7, 300)) + np.random.normal(0, 0.05, 300),
    ]
}
for i in range(3, 300):
    data["x"].append(np.linspace(0, 150, 300))
    data["y"].append(np.sin(np.linspace(0, 15 + i*0.05, 300)) + np.random.normal(0, 0.05, 300))

df = pd.DataFrame(data)

root = tk.Tk()
root.title("Visualisation des chromatogrammes")

fig, ax = plt.subplots(figsize=(10, 6))
canvas = FigureCanvasTkAgg(fig, master=root)
canvas_widget = canvas.get_tk_widget()
canvas_widget.pack(fill=tk.BOTH, expand=1)
toolbar = NavigationToolbar2Tk(canvas, root)
toolbar.update()
toolbar.pack()

cmap = plt.cm.viridis
norm = plt.Normalize(vmin=0, vmax=len(df)-1)
lines = []

for i, row in df.iterrows():
    x = row["x"]
    y = row["y"]
    color = cmap(norm(i))
    line, = ax.plot(x, y, color=color, linewidth=1, picker=5)
    line.chrom_index = i + 1
    lines.append(line)

text_annotation = ax.annotate("", xy=(0,0), xytext=(15,15),
    textcoords="offset points", bbox=dict(boxstyle="round", fc="w"),
    arrowprops=dict(arrowstyle="->"))
text_annotation.set_visible(False)

def on_motion(event):
    if not event.inaxes:
        text_annotation.set_visible(False)
        canvas.draw_idle()
        return

    x_mouse, y_mouse = event.xdata, event.ydata
    tolerance = 0.1

    for line in lines:
        xdata, ydata = line.get_xdata(), line.get_ydata()
        distances = np.hypot(xdata - x_mouse, ydata - y_mouse)
        if np.min(distances) < tolerance:
            idx = np.argmin(distances)
            text_annotation.xy = (xdata[idx], ydata[idx])
            text_annotation.set_text(f"Chromatogramme {line.chrom_index}")
            text_annotation.set_visible(True)
            canvas.draw_idle()
            return

    text_annotation.set_visible(False)
    canvas.draw_idle()

canvas.mpl_connect("motion_notify_event", on_motion)

ax.set_xlabel("Temps de r√©tention")
ax.set_ylabel("Intensit√©")
ax.set_title("Superposition des chromatogrammes")
ax.grid(True)

canvas.draw()
root.mainloop()



import pandas as pd
from collections import defaultdict

# Exemple : df = pd.read_json("ton_fichier.json")

# √âtape 1 : Recenser les composants par chromatogramme
component_to_chroms = defaultdict(set)
component_to_times = defaultdict(list)

for idx, row in df.iterrows():
    for time_str, data in row["pics"].items():
        time = float(time_str)
        if time <= 150:
            comp_name = data[0]
            component_to_chroms[comp_name].add(idx)
            component_to_times[comp_name].append(time)

# √âtape 2 : Conserver uniquement les composants pr√©sents dans TOUS les chromatogrammes
total_chroms = len(df)
present_in_all = {
    comp for comp, chrom_idxs in component_to_chroms.items()
    if len(chrom_idxs) == total_chroms
}

print(f"\nüß™ Composants pr√©sents dans TOUS les {total_chroms} chromatogrammes :")
print(sorted(present_in_all))

# √âtape 3 : Construire les intervalles [min, max] pour chaque composant
component_intervals = {
    comp: (min(times), max(times)) for comp, times in component_to_times.items()
}

# √âtape 4 : V√©rifier les chevauchements d'intervalles
def overlaps(a, b):
    return not (a[1] < b[0] or b[1] < a[0])

non_overlapping = []

for comp1 in present_in_all:
    interval1 = component_intervals[comp1]
    has_overlap = False
    for comp2, interval2 in component_intervals.items():
        if comp1 == comp2:
            continue
        if overlaps(interval1, interval2):
            has_overlap = True
            break
    if not has_overlap:
        non_overlapping.append(comp1)

print("\n‚úÖ Composants pr√©sents dans tous les chromatogrammes SANS chevauchement avec d'autres :")
print(sorted(non_overlapping))

import pandas as pd
from collections import defaultdict

# Exemple : df = pd.read_json("ton_fichier.json")

# √âtape 1 : Recenser les composants par chromatogramme
component_to_chroms = defaultdict(set)
component_to_times = defaultdict(list)

for idx, row in df.iterrows():
    for time_str, data in row["pics"].items():
        time = float(time_str)
        if time <= 150:
            comp_name = data[0]
            component_to_chroms[comp_name].add(idx)
            component_to_times[comp_name].append(time)

# √âtape 2 : Composants pr√©sents dans TOUS les chromatogrammes
total_chroms = len(df)
present_in_all = {
    comp for comp, chrom_idxs in component_to_chroms.items()
    if len(chrom_idxs) == total_chroms
}

# √âtape 3 : Intervalles des composants
component_intervals = {
    comp: (min(times), max(times)) for comp, times in component_to_times.items()
}

# Fonction de chevauchement
def overlaps(a, b):
    return not (a[1] < b[0] or b[1] < a[0])

# √âtape 4 : Afficher pour chaque composant son intervalle et les chevauchements
print(f"\nüß™ Composants pr√©sents dans TOUS les {total_chroms} chromatogrammes :\n")

for comp in sorted(present_in_all):
    interval = component_intervals[comp]
    print(f"üîπ Composant : {comp}, Intervalle : {interval}")
    
    overlap_found = False
    for other_comp, other_interval in component_intervals.items():
        if comp == other_comp:
            continue
        if overlaps(interval, other_interval):
            print(f"    ‚ö†Ô∏è Chevauche avec : {other_comp}, Intervalle : {other_interval}")
            overlap_found = True

    if not overlap_found:
        print("    ‚úÖ Aucun chevauchement d√©tect√©.")
component_counts_per_chrom = defaultdict(lambda: defaultdict(int))

            component_counts_per_chrom[comp_name][idx] += 1

unique_per_chrom = {
    comp for comp in present_in_all
    if all(count == 1 for count in component_counts_per_chrom[comp].values())
}


import pandas as pd
import numpy as np
from collections import defaultdict
from sklearn.neighbors import NearestNeighbors

# Charger les donn√©es
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# √âtape 1 : extraire les temps de pics pour chaque composant
component_to_times = defaultdict(list)

for _, row in df.iterrows():
    seen_counts = defaultdict(int)  # Compteur par composant pour ce chromatogramme
    current_row_pics = list(row["pics"].items())
    current_row_pics.sort(key=lambda x: float(x[0]))  # trier par temps croissant

    for pic_time_str, data in current_row_pics:
        pic_time = float(pic_time_str)
        if pic_time <= 150:
            base_name = data[0]
            seen_counts[base_name] += 1
            comp_name = f"{base_name}_{seen_counts[base_name]}"
            component_to_times[comp_name].append(pic_time)

# √âtape 2 : calcul des moyennes de temps de pic pour chaque composant
component_mean_times = {
    comp: np.mean(times) for comp, times in component_to_times.items()
}

# üîß √âtape 3 : ajustement des moyennes selon une valeur mesur√©e pour TOLUENE
tol_value = 85.0  # <- valeur mesur√©e pour TOLUENE, √† modifier selon ton cas

if "TOLUENE" in component_mean_times:
    toluene_mean = component_mean_times["TOLUENE"]
    delta = tol_value - toluene_mean

    # Appliquer le delta √† tous les composants
    adjusted_mean_times = {
        comp: mean + delta for comp, mean in component_mean_times.items()
    }
else:
    raise ValueError("TOLUENE n'existe pas dans les composants !")

# √âtape 4 : pr√©paration pour NearestNeighbors
component_names = list(adjusted_mean_times.keys())
X = np.array([adjusted_mean_times[comp] for comp in component_names]).reshape(-1, 1) / 150.0

# Entra√Ænement
nbrs = NearestNeighbors(n_neighbors=5)
nbrs.fit(X)
for _, row in df.iterrows():
    seen_counts = defaultdict(int)  # Compteur par composant pour ce chromatogramme
    current_row_pics = list(row["pics"].items())
    current_row_pics.sort(key=lambda x: float(x[0]))  # trier par temps croissant

    for pic_time_str, data in current_row_pics:
        pic_time = float(pic_time_str)
        if pic_time <= 150:
            base_name = data[0]
            seen_counts[base_name] += 1
            comp_name = f"{base_name}_{seen_counts[base_name]}"
            component_to_times[comp_name].append(pic_time)
filtered_component_to_times = {}
for comp, times in component_to_times.items():
    times = np.array(times)
    min_val = np.min(times)
    filtered_times = times[np.abs(times - min_val) <= 1.0]
    if len(filtered_times) > 0:
        filtered_component_to_times[comp] = filtered_times.tolist()


import pandas as pd
import numpy as np
from collections import defaultdict

# Charger les donn√©es
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Dictionnaire global : distances par composant
component_distances_to_toluene = defaultdict(list)

for _, row in df.iterrows():
    seen_counts = defaultdict(int)
    comp_times = {}
    tol_time = None

    current_row_pics = list(row["pics"].items())
    current_row_pics.sort(key=lambda x: float(x[0]))

    for pic_time_str, data in current_row_pics:
        pic_time = float(pic_time_str)
        if pic_time > 150:
            continue

        base_name = data[0]
        seen_counts[base_name] += 1
        comp_name = f"{base_name}_{seen_counts[base_name]}"
        comp_times[comp_name] = pic_time

        # On prend le premier TOLUENE comme r√©f√©rence
        if base_name == "TOLUENE" and tol_time is None:
            tol_time = pic_time

    if tol_time is None:
        continue  # Aucun TOLUENE, on saute ce chromatogramme

    for comp, time in comp_times.items():
        if not comp.startswith("TOLUENE"):
            distance = abs(time - tol_time)
            component_distances_to_toluene[comp].append(distance)

# ‚úÖ Exemple : affichage des 5 premiers composants avec leurs distances
for comp, distances in list(component_distances_to_toluene.items())[:5]:
    print(f"{comp} ‚Üí {distances}")


import pandas as pd

# Charger le fichier JSON
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# √âtape 1 : Extraire tous les noms de composants uniques (sans suffixes)
all_unique_components = set()

for _, row in df.iterrows():
    for data in row["pics"].values():
        name = data[0]
        all_unique_components.add(name)

# √âtape 2 : Trouver le chromatogramme qui contient tous ces noms
for idx, row in df.iterrows():
    row_components = {data[0] for data in row["pics"].values()}
    if all_unique_components.issubset(row_components):
        print(f"‚úÖ Chromatogramme √† l'indice {idx} contient tous les composants uniques.")
        break
else:
    print("‚ùå Aucun chromatogramme ne contient tous les composants.")

import pandas as pd
import numpy as np
from collections import defaultdict

# Charger les donn√©es
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Dictionnaire global : distances par composant
component_distances_to_toluene = defaultdict(list)

for _, row in df.iterrows():
    seen_counts = defaultdict(int)
    comp_times = {}
    tol_time = None

    current_row_pics = list(row["pics"].items())
    current_row_pics.sort(key=lambda x: float(x[0]))

    for pic_time_str, data in current_row_pics:
        pic_time = float(pic_time_str)
        if pic_time > 150:
            continue

        base_name = data[0]
        seen_counts[base_name] += 1
        comp_name = f"{base_name}_{seen_counts[base_name]}"
        comp_times[comp_name] = pic_time

        # On prend le premier TOLUENE comme r√©f√©rence
        if base_name == "TOLUENE" and tol_time is None:
            tol_time = pic_time

    if tol_time is None:
        continue  # Aucun TOLUENE, on saute ce chromatogramme

    for comp, time in comp_times.items():
        if not comp.startswith("TOLUENE"):
            distance = time - tol_time  # Conserver le signe
            component_distances_to_toluene[comp].append(distance)

# Division des composants en sous-groupes si n√©cessaire
grouped_components = defaultdict(list)

for comp, distances in component_distances_to_toluene.items():
    if len(distances) <= 1:
        grouped_components[comp] = distances
        continue

    distances_sorted = sorted(distances)
    subgroups = [[distances_sorted[0]]]

    for d in distances_sorted[1:]:
        if abs(d - subgroups[-1][-1]) <= 0.2:
            subgroups[-1].append(d)
        else:
            subgroups.append([d])

    if len(subgroups) == 1:
        grouped_components[comp] = subgroups[0]
    else:
        for idx, group in enumerate(subgroups):
            suffix = chr(ord('A') + idx)  # 'A', 'B', 'C'...
            new_comp = f"{comp}_{suffix}"
            grouped_components[new_comp] = group

# `grouped_components` contient les distances regroup√©es par sous-groupes avec noms modifi√©s
import pandas as pd
import numpy as np
from collections import defaultdict

# Charger les donn√©es
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Dictionnaire global : distances par composant
component_distances_to_toluene = defaultdict(list)

for _, row in df.iterrows():
    seen_counts = defaultdict(int)
    comp_times = {}
    tol_time = None

    current_row_pics = list(row["pics"].items())
    current_row_pics.sort(key=lambda x: float(x[0]))

    for pic_time_str, data in current_row_pics:
        pic_time = float(pic_time_str)
        if pic_time > 150:
            continue

        base_name = data[0]
        seen_counts[base_name] += 1
        comp_name = f"{base_name}_{seen_counts[base_name]}"
        comp_times[comp_name] = pic_time

        # On prend le premier TOLUENE comme r√©f√©rence
        if base_name == "TOLUENE" and tol_time is None:
            tol_time = pic_time

    if tol_time is None:
        continue  # Aucun TOLUENE, on saute ce chromatogramme

    for comp, time in comp_times.items():
        if not comp.startswith("TOLUENE"):
            distance = time - tol_time  # Conserver le signe
            component_distances_to_toluene[comp].append(distance)

# √âtape 1 : sous-groupes bas√©s sur les valeurs proches
intermediate_groups = defaultdict(list)

for comp, distances in component_distances_to_toluene.items():
    if len(distances) <= 1:
        intermediate_groups[comp].append(distances)
        continue

    distances_sorted = sorted(distances)
    subgroups = [[distances_sorted[0]]]

    for d in distances_sorted[1:]:
        if abs(d - subgroups[-1][-1]) <= 0.2:
            subgroups[-1].append(d)
        else:
            subgroups.append([d])

    base_prefix = "_".join(comp.split("_")[:-1])  # ex: "BENZENE"
    for subgroup in subgroups:
        intermediate_groups[base_prefix].append(subgroup)

# √âtape 2 : regroupement des sous-groupes ayant le m√™me pr√©fixe et proches entre eux
final_grouped_components = defaultdict(list)

for prefix, subgroups in intermediate_groups.items():
    # Trier chaque sous-groupe par moyenne pour comparaison
    subgroups.sort(key=lambda g: np.mean(g))
    merged = []

    for group in subgroups:
        if not merged:
            merged.append(group)
        else:
            last_group = merged[-1]
            if abs(np.mean(group) - np.mean(last_group)) <= 0.2:
                merged[-1].extend(group)
            else:
                merged.append(group)

    # Renommage final avec suffixes A, B, ...
    for idx, group in enumerate(merged):
        suffix = chr(ord('A') + idx)
        new_name = f"{prefix}_{suffix}"
        final_grouped_components[new_name] = group

# `final_grouped_components` contient les groupes fusionn√©s avec suffixes
import pandas as pd
import numpy as np
from collections import defaultdict

# Charger les donn√©es
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Dictionnaire global : distances par composant
component_distances_to_toluene = defaultdict(list)

for _, row in df.iterrows():
    seen_counts = defaultdict(int)
    comp_times = {}
    tol_time = None

    current_row_pics = list(row["pics"].items())
    current_row_pics.sort(key=lambda x: float(x[0]))

    for pic_time_str, data in current_row_pics:
        pic_time = float(pic_time_str)
        if pic_time > 150:
            continue

        base_name = data[0]
        seen_counts[base_name] += 1
        comp_name = f"{base_name}_{seen_counts[base_name]}"
        comp_times[comp_name] = pic_time

        # On prend le premier TOLUENE comme r√©f√©rence
        if base_name == "TOLUENE" and tol_time is None:
            tol_time = pic_time

    if tol_time is None:
        continue  # Aucun TOLUENE, on saute ce chromatogramme

    for comp, time in comp_times.items():
        if not comp.startswith("TOLUENE"):
            distance = time - tol_time  # Conserver le signe
            component_distances_to_toluene[comp].append(distance)

# √âtape 1 : sous-groupes bas√©s sur les valeurs proches
intermediate_groups = defaultdict(list)

for comp, distances in component_distances_to_toluene.items():
    if len(distances) <= 1:
        intermediate_groups[comp].append(distances)
        continue

    distances_sorted = sorted(distances)
    subgroups = [[distances_sorted[0]]]

    for d in distances_sorted[1:]:
        if abs(d - subgroups[-1][-1]) <= 0.2:
            subgroups[-1].append(d)
        else:
            subgroups.append([d])

    base_prefix = "_".join(comp.split("_")[:-1])  # ex: "BENZENE"
    for subgroup in subgroups:
        intermediate_groups[base_prefix].append(subgroup)

# √âtape 2 : regroupement des sous-groupes ayant le m√™me pr√©fixe et proches entre eux
final_grouped_components = defaultdict(list)

for prefix, subgroups in intermediate_groups.items():
    # Trier chaque sous-groupe par moyenne pour comparaison
    subgroups.sort(key=lambda g: np.mean(g))
    merged = []

    for group in subgroups:
        if not merged:
            merged.append(group)
        else:
            last_group = merged[-1]
            if abs(np.mean(group) - np.mean(last_group)) <= 0.2:
                merged[-1].extend(group)
            else:
                merged.append(group)

    # Renommage final avec suffixes A, B, ...
    for idx, group in enumerate(merged):
        suffix = chr(ord('A') + idx)
        new_name = f"{prefix}_{suffix}"
        final_grouped_components[new_name] = group

# Calcul des moyennes pour chaque groupe
group_means = {name: np.mean(values) for name, values in final_grouped_components.items()}

# Affichage des r√©sultats
for name, mean_value in group_means.items():
    print(f"{name} ‚Üí Moyenne des distances : {mean_value:.3f}")
from sklearn.neighbors import NearestNeighbors
import numpy as np

# On suppose que group_means est d√©j√† d√©fini comme :
# group_means = {name: np.mean(values) for name, values in final_grouped_components.items()}

# √âtape 1 : pr√©paration des donn√©es
component_names = list(group_means.keys())
mean_values = np.array([[v] for v in group_means.values()])  # Shape (n, 1) pour sklearn

# √âtape 2 : entra√Ænement du mod√®le NearestNeighbors
nn_model = NearestNeighbors(n_neighbors=3, algorithm='auto')  # Par exemple, 3 plus proches voisins
nn_model.fit(mean_values)

# √âtape 3 : exemple d‚Äôutilisation : trouver les plus proches composants d‚Äôun donn√©
query_index = 0  # Exemple : premier composant
distances, indices = nn_model.kneighbors([mean_values[query_index]])

print(f"Composant de r√©f√©rence : {component_names[query_index]}")
for i, idx in enumerate(indices[0]):
    print(f"  Voisin {i+1} : {component_names[idx]} (distance = {distances[0][i]:.3f})")




from sklearn.neighbors import NearestCentroid
import numpy as np

X = []
y = []

for comp, values in final_grouped_components.items():
    if values:  # V√©rifie qu'il y a bien des valeurs
        mean_val = np.mean(values)
        X.append([mean_val])
        y.append(comp)

X = np.array(X)
y = np.array(y)

# Fit du classificateur
clf = NearestCentroid()
clf.fit(X, y)


new_distance = 0.75

# Pr√©diction de la classe du nouveau point (le groupe auquel appartient la distance)
predicted_group = clf.predict([[new_distance]])

# Afficher le groupe pr√©dit
print(f"La distance {new_distance} appartient au groupe : {predicted_group[0]}")


detected_peaks = []
pic_info_dict = {}

i = 3  # pour √©viter probl√®mes de d√©but de fen√™tre
while i < len(probs_full) - 3:
    if probs_full[i] > threshold:
        window = probs_full[i - 3:i + 4]
        if np.any(window > threshold):
            idx_window = np.arange(i - 3, i + 4)
            idx_max_intensity = idx_window[np.argmax(y_full[idx_window])]
            detected_peaks.append(idx_max_intensity)
            i += 4
        else:
            i += 1
    else:
        i += 1

# Convertir en temps
detected_times = np.array(x_full[detected_peaks]) * 150.0

# 1. Trouver le pic le plus proche de tol_value
tol_differences = np.abs(detected_times - tol_value)
idx_tol_peak = np.argmin(tol_differences)

# Temps du Tolu√®ne d√©tect√©
detected_tol_time = detected_times[idx_tol_peak]

# Associer ce temps au composant Tolu√®ne
pic_info_dict[detected_tol_time] = 'TOLUENE'

# 2. Pour les autres pics, calculer les distances par rapport au Tolu√®ne d√©tect√©
remaining_times = np.delete(detected_times, idx_tol_peak)

# Nouveau Tolu√®ne de r√©f√©rence pour les distances
previous_name = "TOLUENE"

for time in remaining_times:
    diff = time - detected_tol_time  # distance par rapport √† Tolu√®ne d√©tect√©
    _, indices = nbrs.kneighbors([[diff]])
    candidate_names = component_names_array[indices[0]]

    # Choisir un nom diff√©rent du pr√©c√©dent
    for name in candidate_names:
        if name != previous_name:
            selected_name = name
            break
    else:
        selected_name = candidate_names[0]

    previous_name = selected_name
    pic_info_dict[time] = selected_name

# R√©sultat final
print(pic_info_dict)


import numpy as np
import matplotlib.pyplot as plt
import tkinter as tk
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# -------- Ton code de d√©tection des pics --------

detected_peaks = []
pic_info_dict = {}

i = 3  # pour √©viter probl√®mes de d√©but de fen√™tre
while i < len(probs_full) - 3:
    if probs_full[i] > threshold:
        window = probs_full[i - 3:i + 4]
        if np.any(window > threshold):
            idx_window = np.arange(i - 3, i + 4)
            idx_max_intensity = idx_window[np.argmax(y_full[idx_window])]
            detected_peaks.append(idx_max_intensity)
            i += 4
        else:
            i += 1
    else:
        i += 1

# Convertir en temps
detected_peaks = sorted(set(detected_peaks))
detected_times = np.array(x_full[detected_peaks]) * 150.0

# Trouver le pic du Tolu√®ne
tol_differences = np.abs(detected_times - tol_value)
idx_tol_peak = np.argmin(tol_differences)
detected_tol_time = detected_times[idx_tol_peak]

# Associer le Tolu√®ne
pic_info_dict[detected_tol_time] = 'TOLUENE'

# Pour les autres pics
remaining_times = np.delete(detected_times, idx_tol_peak)

previous_name = "TOLUENE"

for time in remaining_times:
    diff = time - detected_tol_time
    _, indices = nbrs.kneighbors([[diff]])
    candidate_names = component_names_array[indices[0]]

    for name in candidate_names:
        if name != previous_name:
            selected_name = name
            break
    else:
        selected_name = candidate_names[0]

    previous_name = selected_name
    pic_info_dict[time] = selected_name

# ------- Fin de la d√©tection / Attribution --------

# Tri final des temps et noms associ√©s
sorted_times = sorted(pic_info_dict.keys())
sorted_names = [pic_info_dict[time] for time in sorted_times]

# -------- Cr√©ation interface Tkinter + Matplotlib --------

# Cr√©ation de la fen√™tre Tkinter
root = tk.Tk()
root.title("Affichage Chromatogramme avec pics d√©tect√©s")

# Cr√©ation de la figure matplotlib
fig, ax = plt.subplots(figsize=(14, 6))

# Afficher le chromatogramme
ax.plot(np.array(x_full) * 150.0, y_full, label='Chromatogramme', color='blue')

# Marquer les pics d√©tect√©s
peak_times_plot = np.array(x_full)[detected_peaks] * 150.0
peak_intensities_plot = np.array(y_full)[detected_peaks]

ax.scatter(peak_times_plot, peak_intensities_plot, color='red', label='Pics d√©tect√©s')

# Ajouter le nom de chaque pic au-dessus du pic d√©tect√©
for time, intensity, name in zip(sorted_times, peak_intensities_plot, sorted_names):
    ax.text(time, intensity + 0.02, name, rotation=90, verticalalignment='bottom', horizontalalignment='center', fontsize=8)

# Personnalisation du graphique
ax.set_xlabel('Temps de r√©tention (s)')
ax.set_ylabel('Intensit√© normalis√©e')
ax.set_title('D√©tection de pics dans le chromatogramme')
ax.grid(True)
ax.legend()
fig.tight_layout()

# Ajouter la figure dans Tkinter avec zoom possible
canvas = FigureCanvasTkAgg(fig, master=root)
canvas.draw()
canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)

# Activer les outils de zoom et d√©placement
toolbar = tk.Frame(root)
toolbar.pack()
from matplotlib.backends.backend_tkagg import NavigationToolbar2Tk
nav_toolbar = NavigationToolbar2Tk(canvas, toolbar)
nav_toolbar.update()

# Lancer la fen√™tre Tkinter
root.mainloop()
