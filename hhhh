import os
import cv2
import numpy as np
import json
import shutil
from sklearn.model_selection import train_test_split

def get_image_mask_pairs(data_dir):
    image_paths = []
    mask_paths = []
    
    for root, _, files in os.walk(data_dir):
        if 'tissue images' in root:
            for file in files:
                if file.endswith('.png'):
                    image_paths.append(os.path.join(root, file))
                    mask_paths.append(os.path.join(root.replace('tissue images', 'label masks modify'), file.replace('.png', '.tif')))
    
    return image_paths, mask_paths

def mask_to_polygons_and_rotated_bbox(mask, epsilon=1.0):
    """
    Convert a binary mask into polygons and rotated bounding boxes.
    """
    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    polygons = []
    rotated_bboxes = []
    
    for contour in contours:
        if len(contour) > 2:
            poly = contour.reshape(-1).tolist()
            if len(poly) > 4:  # Ensure valid polygon
                polygons.append(poly)
            
            # Calculate rotated bounding box
            rect = cv2.minAreaRect(contour)
            box = cv2.boxPoints(rect)
            box = np.int0(box)  # Convert to integer
            x_c, y_c = rect[0]  # Center of the box
            w, h = rect[1]  # Width and height of the box
            theta = rect[2]  # Angle of rotation
            
            # Normalize the angle to be between -90 and 90
            if w < h:
                w, h = h, w
                theta += 90
            
            rotated_bboxes.append([x_c, y_c, w, h, theta])
    
    return polygons, rotated_bboxes

def process_data(image_paths, mask_paths, output_dir):
    annotations = []
    images = []
    image_id = 0
    ann_id = 0
    
    for img_path, mask_path in zip(image_paths, mask_paths):
        image_id += 1
        img = cv2.imread(img_path)
        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
        
        # Copy image to output directory
        shutil.copy(img_path, os.path.join(output_dir, os.path.basename(img_path)))
        
        images.append({
            "id": image_id,
            "file_name": os.path.basename(img_path),
            "height": img.shape[0],
            "width": img.shape[1]
        })
        
        unique_values = np.unique(mask)
        for value in unique_values:
            if value == 0:  # Ignore background
                continue
            
            object_mask = (mask == value).astype(np.uint8) * 255
            polygons, rotated_bboxes = mask_to_polygons_and_rotated_bbox(object_mask)
            
            for poly, rotated_bbox in zip(polygons, rotated_bboxes):
                ann_id += 1
                x_c, y_c, w, h, theta = rotated_bbox
                annotations.append({
                    "id": ann_id,
                    "image_id": image_id,
                    "category_id": 1,  # Only one category: Nuclei
                    "segmentation": [poly],
                    "area": cv2.contourArea(np.array(poly).reshape(-1, 2)),
                    "bbox": [x_c, y_c, w, h, theta],  # Rotated bbox
                    "iscrowd": 0
                })
    
    coco_output = {
        "images": images,
        "annotations": annotations,
        "categories": [{"id": 1, "name": "Nuclei"}]
    }
    
    with open(os.path.join(output_dir, 'coco_annotations.json'), 'w') as f:
        json.dump(coco_output, f)

def main():
    data_dir = 'Data'
    output_dir = 'COCO_output'
    train_dir = os.path.join(output_dir, 'train')
    val_dir = os.path.join(output_dir, 'val')
    
    # Create output directories
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(val_dir, exist_ok=True)
    
    image_paths, mask_paths = get_image_mask_pairs(data_dir)
    
    # Split data into train and val
    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)
    
    # Process train and val data
    process_data(train_img_paths, train_mask_paths, train_dir)
    process_data(val_img_paths, val_mask_paths, val_dir)

if __name__ == '__main__':
    main()



import os
import cv2
import numpy as np
import json
import shutil
from sklearn.model_selection import train_test_split

def get_image_mask_pairs(data_dir):
    image_paths = []
    mask_paths = []
    
    for root, _, files in os.walk(data_dir):
        if 'tissue images' in root:
            for file in files:
                if file.endswith('.png'):
                    image_paths.append(os.path.join(root, file))
                    mask_paths.append(os.path.join(root.replace('tissue images', 'label masks modify'), file.replace('.png', '.tif')))
    
    return image_paths, mask_paths

def mask_to_polygons(mask, epsilon=1.0):
    """
    Convert the mask to polygons with a limit of 4 points (DOTA format).
    """
    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    polygons = []
    
    for contour in contours:
        if len(contour) > 2:
            # Approximation du contour pour obtenir un polygone simplifié
            epsilon_value = epsilon * cv2.arcLength(contour, True)
            approx_polygon = cv2.approxPolyDP(contour, epsilon_value, True)
            
            # Si le polygone a plus de 4 points, il sera réduit à 4
            if len(approx_polygon) > 4:
                # Assurer qu'on obtient un quadrilatère : on prend les 4 points les plus extérieurs
                rect = cv2.minAreaRect(contour)  # rectangle minimum englobant
                box = cv2.boxPoints(rect)  # Les 4 coins du rectangle
                box = np.int0(box)
                approx_polygon = box  # Mettre à jour le polygone avec les 4 coins du rectangle

            # Convertir les coordonnées du polygone en format (x1, y1, x2, y2, x3, y3, x4, y4)
            polygon = approx_polygon.reshape(-1).tolist()
            polygons.append(polygon)
    
    return polygons

def process_data(image_paths, mask_paths, output_dir, class_id=1):
    """
    Traitement des images et des masques pour les convertir en format DOTA.
    """
    annotations = []
    images = []
    image_id = 0
    ann_id = 0
    
    for img_path, mask_path in zip(image_paths, mask_paths):
        image_id += 1
        img = cv2.imread(img_path)
        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
        
        # Copier l'image dans le répertoire de sortie
        shutil.copy(img_path, os.path.join(output_dir, os.path.basename(img_path)))
        
        images.append({
            "id": image_id,
            "file_name": os.path.basename(img_path),
            "height": img.shape[0],
            "width": img.shape[1]
        })
        
        # Identifier les valeurs uniques dans le masque
        unique_values = np.unique(mask)
        for value in unique_values:
            if value == 0:  # Ignorer le fond (valeur 0)
                continue
            
            object_mask = (mask == value).astype(np.uint8) * 255
            polygons = mask_to_polygons(object_mask)
            
            for poly in polygons:
                ann_id += 1
                annotations.append({
                    "id": ann_id,
                    "image_id": image_id,
                    "category_id": class_id,  # La catégorie (ici 1 pour Nuclei)
                    "segmentation": [poly],
                    "area": cv2.contourArea(np.array(poly).reshape(-1, 2)),
                    "bbox": list(cv2.boundingRect(np.array(poly).reshape(-1, 2))),
                    "iscrowd": 0
                })
    
    # Générer le fichier d'annotations en format DOTA
    dota_output = []
    for ann in annotations:
        poly = ann['segmentation'][0]
        # Format DOTA : A[0:8]: Polygone en 8 coordonnées, A[8]: Catégorie, A[9]: Difficulté
        # Assurer que le polygone a bien 8 points, même si moins de 4 sont présents
        if len(poly) < 8:
            poly += [0] * (8 - len(poly))  # Compléter avec des zéros si moins de 8 points

        # Afficher les coordonnées sous forme correcte dans le fichier .txt
        poly_str = " ".join([str(int(coord)) for coord in poly])
        dota_output.append(f"{poly_str} {ann['category_id']} 0")
    
    # Sauvegarder les annotations DOTA dans un fichier .txt
    with open(os.path.join(output_dir, 'dota_annotations.txt'), 'w') as f:
        for line in dota_output:
            f.write(line + '\n')

    # Sauvegarder les informations d'images
    with open(os.path.join(output_dir, 'dota_images_info.json'), 'w') as f:
        json.dump(images, f)
    
    print(f"Annotations DOTA et images sauvegardées dans {output_dir}")

def main():
    data_dir = 'Data'
    output_dir = 'DOTA_output'
    train_dir = os.path.join(output_dir, 'train')
    val_dir = os.path.join(output_dir, 'val')
    
    # Créer les répertoires de sortie
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(val_dir, exist_ok=True)
    
    image_paths, mask_paths = get_image_mask_pairs(data_dir)
    
    # Diviser les données en ensembles d'entraînement et de validation
    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)
    
    # Traiter les données d'entraînement et de validation
    process_data(train_img_paths, train_mask_paths, train_dir)
    process_data(val_img_paths, val_mask_paths, val_dir)

if __name__ == '__main__':
    main()



from shapely.geometry import Polygon

def pairwise_iou_rotated(boxes1, boxes2):
    """
    Calcule l'IoU entre deux ensembles de boîtes orientées.

    Arguments :
        boxes1 : Tensor[N, 5] (x_center, y_center, width, height, angle en degrés)
        boxes2 : Tensor[M, 5] (x_center, y_center, width, height, angle en degrés)

    Returns :
        iou_matrix : Tensor[N, M] avec les IoU entre chaque paire de boîtes.
    """
    iou_matrix = []
    for box1 in boxes1:
        poly1 = get_polygon(box1)
        ious = []
        for box2 in boxes2:
            poly2 = get_polygon(box2)
            inter = poly1.intersection(poly2).area
            union = poly1.union(poly2).area
            ious.append(inter / union if union > 0 else 0)
        iou_matrix.append(ious)
    return torch.tensor(iou_matrix, dtype=torch.float32)

def get_polygon(box):
    """
    Convertit une boîte (x_center, y_center, width, height, angle) en un polygone Shapely.
    """
    xc, yc, w, h, angle = box
    angle_rad = -angle * (3.14159265359 / 180)  # Conversion en radians
    c, s = torch.cos(angle_rad), torch.sin(angle_rad)
    corners = [
        [w / 2, h / 2],
        [-w / 2, h / 2],
        [-w / 2, -h / 2],
        [w / 2, -h / 2]
    ]
    rotated_corners = [
        (xc + c * x - s * y, yc + s * x + c * y)
        for x, y in corners
    ]
    return Polygon(rotated_corners)
pip uninstall detectron2 -y
pip install 'detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html'
