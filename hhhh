import os
import cv2
import numpy as np
import json
import shutil
from sklearn.model_selection import train_test_split

def get_image_mask_pairs(data_dir):
    image_paths = []
    mask_paths = []
    
    for root, _, files in os.walk(data_dir):
        if 'tissue images' in root:
            for file in files:
                if file.endswith('.png'):
                    image_paths.append(os.path.join(root, file))
                    mask_paths.append(os.path.join(root.replace('tissue images', 'label masks modify'), file.replace('.png', '.tif')))
    
    return image_paths, mask_paths

def mask_to_polygons_and_rotated_bbox(mask, epsilon=1.0):
    """
    Convert a binary mask into polygons and rotated bounding boxes.
    """
    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    polygons = []
    rotated_bboxes = []
    
    for contour in contours:
        if len(contour) > 2:
            poly = contour.reshape(-1).tolist()
            if len(poly) > 4:  # Ensure valid polygon
                polygons.append(poly)
            
            # Calculate rotated bounding box
            rect = cv2.minAreaRect(contour)
            box = cv2.boxPoints(rect)
            box = np.int0(box)  # Convert to integer
            x_c, y_c = rect[0]  # Center of the box
            w, h = rect[1]  # Width and height of the box
            theta = rect[2]  # Angle of rotation
            
            # Normalize the angle to be between -90 and 90
            if w < h:
                w, h = h, w
                theta += 90
            
            rotated_bboxes.append([x_c, y_c, w, h, theta])
    
    return polygons, rotated_bboxes

def process_data(image_paths, mask_paths, output_dir):
    annotations = []
    images = []
    image_id = 0
    ann_id = 0
    
    for img_path, mask_path in zip(image_paths, mask_paths):
        image_id += 1
        img = cv2.imread(img_path)
        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
        
        # Copy image to output directory
        shutil.copy(img_path, os.path.join(output_dir, os.path.basename(img_path)))
        
        images.append({
            "id": image_id,
            "file_name": os.path.basename(img_path),
            "height": img.shape[0],
            "width": img.shape[1]
        })
        
        unique_values = np.unique(mask)
        for value in unique_values:
            if value == 0:  # Ignore background
                continue
            
            object_mask = (mask == value).astype(np.uint8) * 255
            polygons, rotated_bboxes = mask_to_polygons_and_rotated_bbox(object_mask)
            
            for poly, rotated_bbox in zip(polygons, rotated_bboxes):
                ann_id += 1
                x_c, y_c, w, h, theta = rotated_bbox
                annotations.append({
                    "id": ann_id,
                    "image_id": image_id,
                    "category_id": 1,  # Only one category: Nuclei
                    "segmentation": [poly],
                    "area": cv2.contourArea(np.array(poly).reshape(-1, 2)),
                    "bbox": [x_c, y_c, w, h, theta],  # Rotated bbox
                    "iscrowd": 0
                })
    
    coco_output = {
        "images": images,
        "annotations": annotations,
        "categories": [{"id": 1, "name": "Nuclei"}]
    }
    
    with open(os.path.join(output_dir, 'coco_annotations.json'), 'w') as f:
        json.dump(coco_output, f)

def main():
    data_dir = 'Data'
    output_dir = 'COCO_output'
    train_dir = os.path.join(output_dir, 'train')
    val_dir = os.path.join(output_dir, 'val')
    
    # Create output directories
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(val_dir, exist_ok=True)
    
    image_paths, mask_paths = get_image_mask_pairs(data_dir)
    
    # Split data into train and val
    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)
    
    # Process train and val data
    process_data(train_img_paths, train_mask_paths, train_dir)
    process_data(val_img_paths, val_mask_paths, val_dir)

if __name__ == '__main__':
    main()



import os
import cv2
import numpy as np
import shutil
from sklearn.model_selection import train_test_split

def get_image_mask_pairs(data_dir):
    image_paths = []
    mask_paths = []
    
    for root, _, files in os.walk(data_dir):
        if 'tissue images' in root:
            for file in files:
                if file.endswith('.png'):
                    image_paths.append(os.path.join(root, file))
                    mask_paths.append(os.path.join(root.replace('tissue images', 'label masks modify'), file.replace('.png', '.tif')))
    
    return image_paths, mask_paths

def mask_to_polygons(mask, epsilon=1.0):
    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    polygons = []
    for contour in contours:
        if len(contour) > 2:
            # Get the bounding rectangle for each contour (4 points: x1, y1, x2, y2)
            x, y, w, h = cv2.boundingRect(contour)
            # Add the 4 corners of the bounding box as the polygon
            polygons.append([x, y, x + w, y, x + w, y + h, x, y + h])
    return polygons

def process_data(image_paths, mask_paths, output_dir):
    annotations_dir = os.path.join(output_dir, 'annotations')
    os.makedirs(annotations_dir, exist_ok=True)
    
    image_id = 0
    ann_id = 0
    
    for img_path, mask_path in zip(image_paths, mask_paths):
        image_id += 1
        img = cv2.imread(img_path)
        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
        
        # Copy image to output directory
        shutil.copy(img_path, os.path.join(output_dir, 'images', os.path.basename(img_path)))
        
        # Prepare DOTA annotation format
        annotation_lines = []
        
        unique_values = np.unique(mask)
        for value in unique_values:
            if value == 0:  # Ignore background
                continue
            
            object_mask = (mask == value).astype(np.uint8) * 255
            polygons = mask_to_polygons(object_mask)
            
            for poly in polygons:
                # Get the 8 coordinates of the polygon (x1, y1, x2, y2, ...)
                coords = np.array(poly).reshape(-1)
                assert len(coords) == 8, f"Expected 8 coordinates, got {len(coords)}"
                
                # Define the annotation format for DOTA
                annotation_line = ' '.join(map(str, coords)) + ' plane 0'  # Assuming all objects are "plane" and difficulty 0
                annotation_lines.append(annotation_line)
        
        # Write the annotations to a txt file
        annotation_file = os.path.join(annotations_dir, f'{image_id}.txt')
        with open(annotation_file, 'w') as f:
            f.write("\n".join(annotation_lines))

def main():
    data_dir = 'Data'
    output_dir = 'DOTA_output'
    
    # Create output directories
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)
    
    image_paths, mask_paths = get_image_mask_pairs(data_dir)
    
    # Split data into train and val
    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)
    
    # Process train and val data
    process_data(train_img_paths, train_mask_paths, os.path.join(output_dir, 'train'))
    process_data(val_img_paths, val_mask_paths, os.path.join(output_dir, 'val'))

if __name__ == '__main__':
    main()




from shapely.geometry import Polygon

def pairwise_iou_rotated(boxes1, boxes2):
    """
    Calcule l'IoU entre deux ensembles de boîtes orientées.

    Arguments :
        boxes1 : Tensor[N, 5] (x_center, y_center, width, height, angle en degrés)
        boxes2 : Tensor[M, 5] (x_center, y_center, width, height, angle en degrés)

    Returns :
        iou_matrix : Tensor[N, M] avec les IoU entre chaque paire de boîtes.
    """
    iou_matrix = []
    for box1 in boxes1:
        poly1 = get_polygon(box1)
        ious = []
        for box2 in boxes2:
            poly2 = get_polygon(box2)
            inter = poly1.intersection(poly2).area
            union = poly1.union(poly2).area
            ious.append(inter / union if union > 0 else 0)
        iou_matrix.append(ious)
    return torch.tensor(iou_matrix, dtype=torch.float32)

def get_polygon(box):
    """
    Convertit une boîte (x_center, y_center, width, height, angle) en un polygone Shapely.
    """
    xc, yc, w, h, angle = box
    angle_rad = -angle * (3.14159265359 / 180)  # Conversion en radians
    c, s = torch.cos(angle_rad), torch.sin(angle_rad)
    corners = [
        [w / 2, h / 2],
        [-w / 2, h / 2],
        [-w / 2, -h / 2],
        [w / 2, -h / 2]
    ]
    rotated_corners = [
        (xc + c * x - s * y, yc + s * x + c * y)
        for x, y in corners
    ]
    return Polygon(rotated_corners)
pip uninstall detectron2 -y
pip install 'detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html'
