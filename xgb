import os
import cv2
import numpy as np
import xgboost as xgb  # Importer XGBoost
from sklearn.preprocessing import StandardScaler
from skimage.feature import hog, graycomatrix, graycoprops
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from keras.preprocessing.image import ImageDataGenerator

# Fonction pour compter le nombre d'objets dans un fichier d'annotation DOTA
def count_objects_in_dota_annotation(txt_file):
    """Compter le nombre d'objets dans un fichier d'annotation DOTA."""
    with open(txt_file, 'r') as f:
        annotations = f.readlines()
    return len(annotations)

# Fonction pour extraire les caractéristiques HOG
def extract_hog_features(image):
    """Extraire les caractéristiques HOG d'une image."""
    fd, _ = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)
    return fd

# Fonction pour extraire les caractéristiques ORB
def extract_orb_features(image):
    """Extraire les descripteurs ORB d'une image."""
    orb = cv2.ORB_create(nfeatures=500)
    keypoints, descriptors = orb.detectAndCompute(image, None)
    
    if descriptors is not None:
        return descriptors.flatten()[:500]  # Limite la taille
    else:
        return np.zeros(500)  # Remplace par des zéros si aucun descripteur trouvé

# Fonction pour extraire les caractéristiques GLCM
def extract_glcm_features(image):
    """Extraire les caractéristiques GLCM d'une image."""
    glcm = graycomatrix(image, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)
    contrast = graycoprops(glcm, 'contrast')[0, 0]
    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]
    energy = graycoprops(glcm, 'energy')[0, 0]
    correlation = graycoprops(glcm, 'correlation')[0, 0]
    return np.array([contrast, homogeneity, energy, correlation])

# Appliquer des transformations sur l'image pour Data Augmentation
def augment_image(image):
    """Effectue des transformations pour augmenter les données."""
    datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=True, zoom_range=0.2)
    image = np.expand_dims(image, axis=0)  # Ajouter une dimension pour le générateur
    augmented_images = [image]
    
    for batch in datagen.flow(image, batch_size=1):
        augmented_images.append(batch[0])
        if len(augmented_images) >= 3:
            break

    return [img.squeeze() for img in augmented_images]

# Fonction pour créer les jeux de données avec augmentation et plusieurs caractéristiques
def create_dataset(image_dir, annotation_dir):
    features = []
    labels = []
    
    image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]
    
    for image_path in image_paths:
        txt_file = os.path.join(annotation_dir, os.path.basename(image_path).replace('.jpg', '.txt').replace('.png', '.txt'))
        
        if os.path.exists(txt_file):
            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
            augmented_images = augment_image(img)
            
            for aug_img in augmented_images:
                hog_features = extract_hog_features(aug_img)
                orb_features = extract_orb_features(aug_img)
                glcm_features = extract_glcm_features(aug_img)

                # Concaténer toutes les caractéristiques
                feature_vector = np.concatenate((hog_features, orb_features, glcm_features))
                features.append(feature_vector)

                # Nombre d'objets comme label
                num_objects = count_objects_in_dota_annotation(txt_file)
                labels.append(num_objects)

    return np.array(features), np.array(labels)

# Fonction pour entraîner le modèle XGBoost
def train_model(features, labels):
    """Entraîner un modèle XGBoost avec HOG + ORB + GLCM."""
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    model = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,
                             max_depth=5, alpha=10, n_estimators=100)
    model.fit(features_scaled, labels)
    
    return model, scaler

def main():
    image_dir = 'path_to_images'
    annotation_dir = 'path_to_annotations'
    
    # Création du dataset
    features, labels = create_dataset(image_dir, annotation_dir)
    
    # Séparer en données d'entraînement et de test
    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=42)

    # Entraîner le modèle
    model, scaler = train_model(features_train, labels_train)
    
    # Évaluer le modèle
    features_test_scaled = scaler.transform(features_test)
    predictions = model.predict(features_test_scaled)
    
    print(f"MAE : {mean_absolute_error(labels_test, predictions):.2f}")
    print(f"R² Score : {r2_score(labels_test, predictions):.2f}")

    # Sauvegarde du modèle
    model.save_model('xgboost_model.json')
    np.save('scaler.npy', scaler.mean_)  # Sauvegarder le scaler

def extract_orb_features(image):
    """Extraire les descripteurs ORB d'une image."""
    if not isinstance(image, np.ndarray):
        raise ValueError("L'image doit être un tableau NumPy.")
    
    if image.ndim == 3 and image.shape[2] == 1:
        image = image.squeeze(axis=2)  # Supprime la 3e dimension si (H, W, 1)
    
    if image.dtype != np.uint8:
        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    orb = cv2.ORB_create(nfeatures=500)
    keypoints, descriptors = orb.detectAndCompute(image, None)

    if descriptors is not None:
        return descriptors.flatten()[:500]  # Limiter à 500 valeurs
    else:
        return np.zeros(500)  # Retourne un vecteur de zéros si pas de descripteurs