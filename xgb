import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, BatchNormalization, ReLU
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split

# ================================
# ðŸ“Œ FONCTIONS UTILITAIRES
# ================================
def read_dota_annotations(txt_file):
    """Lit un fichier d'annotations DOTA et retourne les polygones des objets."""
    objects = []
    with open(txt_file, 'r') as f:
        lines = f.readlines()
    
    for line in lines:
        values = line.strip().split()
        if len(values) >= 8:  # DOTA a 8 coordonnÃ©es (4 points)
            x_coords = list(map(float, values[:8:2]))  # X
            y_coords = list(map(float, values[1:8:2]))  # Y
            polygon = list(zip(x_coords, y_coords))  # CrÃ©er le polygone
            objects.append(polygon)

    return objects

def generate_density_map(image, points, sigma=15):
    """GÃ©nÃ¨re une carte de densitÃ© en remplissant les objets."""
    h, w = image.shape[:2]
    density_map = np.zeros((h, w), dtype=np.float32)

    for obj in points:
        if len(obj) == 4:  # Chaque objet a 4 points (x1, y1), ..., (x4, y4)
            polygon = np.array(obj, np.int32).reshape((-1, 1, 2))
            cv2.fillPoly(density_map, [polygon], 1)  # Remplir l'objet entier

    # Appliquer un flou gaussien
    density_map = cv2.GaussianBlur(density_map, (sigma, sigma), 0)
    density_map /= density_map.sum() if density_map.sum() > 0 else 1  # Normalisation
    return density_map

# ================================
# ðŸ“Œ CHARGEMENT DES DONNÃ‰ES
# ================================
def load_data(image_dir, annotation_dir, target_size=(256, 256)):
    images = []
    density_maps = []
    
    image_paths = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]
    
    for img_name in image_paths:
        img_path = os.path.join(image_dir, img_name)
        ann_path = os.path.join(annotation_dir, img_name.replace('.jpg', '.txt').replace('.png', '.txt'))
        
        if os.path.exists(ann_path):
            # Charger et redimensionner l'image
            image = cv2.imread(img_path, cv2.IMREAD_COLOR)
            image = cv2.resize(image, target_size)
            image = image.astype(np.float32) / 255.0  # Normalisation
            images.append(image)

            # Lire les annotations et gÃ©nÃ©rer la carte de densitÃ©
            objects = read_dota_annotations(ann_path)
            density_map = generate_density_map(image, objects, sigma=10)
            density_map = cv2.resize(density_map, target_size)
            density_maps.append(density_map)

    images = np.array(images)
    density_maps = np.array(density_maps).reshape(-1, target_size[0], target_size[1], 1)  # Ajouter canal

    return images, density_maps

# ================================
# ðŸ“Œ MODÃˆLE CSRNet
# ================================
def build_csrnet(input_shape=(256, 256, 3)):
    inputs = Input(shape=input_shape)

    # Feature Extraction (Partie CNN)
    x = Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)

    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)

    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)

    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)
    x = BatchNormalization()(x)

    # DensitÃ© Estimation (Dilated CNN)
    x = Conv2D(512, (3, 3), padding='same', dilation_rate=2, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(512, (3, 3), padding='same', dilation_rate=2, activation='relu')(x)
    x = BatchNormalization()(x)

    x = Conv2D(256, (3, 3), padding='same', dilation_rate=2, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(128, (3, 3), padding='same', dilation_rate=2, activation='relu')(x)
    x = BatchNormalization()(x)

    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)
    x = BatchNormalization()(x)

    # Sortie
    output = Conv2D(1, (1, 1), padding='same', activation='relu')(x)

    model = Model(inputs, output)
    model.compile(optimizer='adam', loss='mse')
    return model

# ================================
# ðŸ“Œ ENTRAÃŽNEMENT DU MODÃˆLE
# ================================
def train_csrnet(image_dir, annotation_dir, epochs=10, batch_size=8):
    # Charger les donnÃ©es
    X, Y = load_data(image_dir, annotation_dir)
    
    # SÃ©parer en train et test
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

    # Construire le modÃ¨le
    model = build_csrnet()
    model.summary()

    # EntraÃ®ner le modÃ¨le
    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test))

    # Sauvegarde du modÃ¨le
    model.save('csrnet_model.h5')
    print("ðŸ“Œ ModÃ¨le entraÃ®nÃ© et sauvegardÃ©.")

# ================================
# ðŸ“Œ LANCEMENT DE L'ENTRAÃŽNEMENT
# ================================
if __name__ == "__main__":
    image_dir = "path_to_images"
    annotation_dir = "path_to_annotations"
    
    train_csrnet(image_dir, annotation_dir)
