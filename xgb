import os
import cv2
import numpy as np
import tensorflow as tf
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate
from keras.applications import DenseNet121
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from skimage.feature import hog, graycomatrix, graycoprops

# ðŸ”¹ Fonction pour extraire HOG
def extract_hog_features(image):
    fd, _ = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)
    return fd

# ðŸ”¹ Fonction pour extraire ORB
def extract_orb_features(image, max_features=500):
    orb = cv2.ORB_create(nfeatures=max_features)
    keypoints, descriptors = orb.detectAndCompute(image, None)
    if descriptors is None:
        descriptors = np.zeros((max_features, 32), dtype=np.uint8)
    if descriptors.shape[0] < max_features:
        padding = np.zeros((max_features - descriptors.shape[0], 32), dtype=np.uint8)
        descriptors = np.vstack((descriptors, padding))
    return descriptors.flatten()

# ðŸ”¹ Fonction pour extraire GLCM
def extract_glcm_features(image):
    image = (image * 255).astype(np.uint8) if image.dtype != np.uint8 else image
    glcm = graycomatrix(image, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)
    return np.array([
        graycoprops(glcm, 'contrast')[0, 0],
        graycoprops(glcm, 'homogeneity')[0, 0],
        graycoprops(glcm, 'energy')[0, 0],
        graycoprops(glcm, 'correlation')[0, 0]
    ])

# ðŸ”¹ Fonction pour extraire Hu Moments
def extract_hu_moments(image):
    moments = cv2.moments(image)
    hu_moments = cv2.HuMoments(moments)
    return hu_moments.flatten()

# ðŸ”¹ Fonction pour l'augmentation de donnÃ©es
def augment_image(image):
    datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=True, zoom_range=0.2)
    image = np.expand_dims(image, axis=(0, -1))
    augmented_images = [image]
    
    for batch in datagen.flow(image, batch_size=1):
        augmented_images.append(batch[0])
        if len(augmented_images) >= 3:
            break

    return [img.squeeze() for img in augmented_images]

# ðŸ”¹ CrÃ©ation du dataset
def create_dataset(image_dir, annotation_dir):
    features_cnn = []
    features_manual = []
    labels = []
    
    image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]
    
    for image_path in image_paths:
        txt_file = os.path.join(annotation_dir, os.path.basename(image_path).replace('.jpg', '.txt').replace('.png', '.txt'))
        
        if os.path.exists(txt_file):
            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
            augmented_images = augment_image(img)
            
            for aug_img in augmented_images:
                aug_img = aug_img.astype(np.float32) / 255.0
                
                # Adapter pour DenseNet (RGB, 128x128)
                resized_img = cv2.resize(aug_img, (128, 128))
                resized_img = np.expand_dims(resized_img, axis=-1)
                resized_img = np.repeat(resized_img, 3, axis=-1)
                
                features_cnn.append(resized_img)
                
                # ðŸ”¥ Extraire les caractÃ©ristiques manuelles
                hog_features = extract_hog_features(aug_img)
                orb_features = extract_orb_features(aug_img)
                glcm_features = extract_glcm_features(aug_img)
                hu_moments = extract_hu_moments(aug_img)
                
                # ConcatÃ©ner toutes les caractÃ©ristiques
                manual_features = np.concatenate([hog_features, orb_features, glcm_features, hu_moments])
                features_manual.append(manual_features)
                
                # Ajouter le label (nombre d'objets)
                with open(txt_file, 'r') as f:
                    num_objects = len(f.readlines())
                labels.append(num_objects)

    return np.array(features_cnn), np.array(features_manual), np.array(labels)

# ðŸ”¹ CrÃ©ation du modÃ¨le combinÃ©
def create_combined_model(input_shape_cnn, input_shape_manual):
    # Feature extractor CNN (DenseNet)
    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape_cnn)
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    cnn_output = Dense(256, activation='relu')(x)
    
    # Feature extractor manuel (MLP)
    input_manual = Input(shape=(input_shape_manual,))
    manual_output = Dense(256, activation='relu')(input_manual)
    
    # Fusion des deux
    merged = Concatenate()([cnn_output, manual_output])
    final_output = Dense(1, activation='linear')(merged)  # Sortie rÃ©gression
    
    # ModÃ¨le final
    model = Model(inputs=[base_model.input, input_manual], outputs=final_output)
    
    for layer in base_model.layers:
        layer.trainable = False  # Geler les poids du CNN
    
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# ðŸ”¹ Fonction principale
def main():
    image_dir = 'path_to_images'
    annotation_dir = 'path_to_annotations'
    
    # Chargement des donnÃ©es
    X_cnn, X_manual, y = create_dataset(image_dir, annotation_dir)
    
    # VÃ©rification des formes
    print(f"Shape CNN: {X_cnn.shape}")       # Doit Ãªtre (N, 128, 128, 3)
    print(f"Shape Manual: {X_manual.shape}") # Doit Ãªtre (N, nb_features)
    
    # SÃ©paration en train/test
    X_cnn_train, X_cnn_test, X_manual_train, X_manual_test, y_train, y_test = train_test_split(
        X_cnn, X_manual, y, test_size=0.2, random_state=42
    )

    # CrÃ©ation et entraÃ®nement du modÃ¨le
    model = create_combined_model((128, 128, 3), X_manual.shape[1])
    model.fit([X_cnn_train, X_manual_train], y_train, epochs=10, batch_size=16, validation_split=0.1)

    # PrÃ©dictions et Ã©valuation
    predictions = model.predict([X_cnn_test, X_manual_test])
    
    print(f"MAE : {mean_absolute_error(y_test, predictions):.2f}")
    print(f"RÂ² Score : {r2_score(y_test, predictions):.2f}")

    model.save('combined_model.h5')

if __name__ == '__main__':
    main()
