DÃ©velopper un modÃ¨le capable de dÃ©tecter les pics dans les chromatogrammes et dâ€™identifier les composants associÃ©s.

Adaptation du modÃ¨le IPA pour la localisation des pics dans les chromatogrammes

Attribution des composants via lâ€™algorithme Nearest Neighbors

Ã€ ma disposition, j'avais un ensemble de 453 chromatogrammes. Un premier nettoyage des donnÃ©es a Ã©tÃ© nÃ©cessaire : 133 chromatogrammes ne comportaient pas d'annotations de pics et ont donc Ã©tÃ© supprimÃ©s, ce qui a rÃ©duit le jeu Ã  320 chromatogrammes exploitables. Ensuite, le signal de chaque chromatogramme a Ã©tÃ© tronquÃ© pour ne conserver que les points dont le temps de rÃ©tention est infÃ©rieur ou Ã©gal Ã  150, ce qui a permis de passer dâ€™environ 71 000 Ã  45 000 points par chromatogramme. Afin de faciliter lâ€™apprentissage, chaque chromatogramme a Ã©tÃ© dÃ©coupÃ© en segments de 1 000 points, donnant ainsi 45 segments par chromatogramme. Les donnÃ©es ont Ã©tÃ© normalisÃ©es en temps, mais non en intensitÃ©, car la normalisation des intensitÃ©s rÃ©duisait la visibilitÃ© des pics de faible intensitÃ©. Au total, 14 400 segments ont Ã©tÃ© gÃ©nÃ©rÃ©s pour l'entraÃ®nement. Chaque point dâ€™un segment est reprÃ©sentÃ© par deux valeurs (temps, intensitÃ©), et pour lâ€™Ã©tiquetage, une classification binaire a Ã©tÃ© mise en place : les points correspondant aux pics sont annotÃ©s avec la valeur 1, les autres avec la valeur 0.

ğŸ”„ PrÃ©traitement des donnÃ©es
Jeu initial :
ğŸ“Š 453 chromatogrammes

Nettoyage :
âŒ Suppression de 133 sans annotations
âœ… 320 chromatogrammes restants

Tronquage du signal :
â±ï¸ Garde les points avec temps â‰¤ 150
â¡ï¸ RÃ©duction de ~71 000 Ã  ~45 000 points

Segmentation :
âœ‚ï¸ DÃ©coupe en segments de 1 000 points
â¡ï¸ 45 segments par chromatogramme
ğŸ§© Total : 14 400 segments

Normalisation :
âœ… Temps normalisÃ©
âŒ IntensitÃ© non normalisÃ©e (prÃ©servation des pics faibles)

Ã‰tiquetage (labels) :
ğŸŸ¢ 1 si le point est un pic
âšª 0 sinon
â¡ï¸ Classification binaire point par point


branche 1 : ComplexitÃ©: Faible (opÃ©rations simples) Capturer les caractÃ©ristiques globales
branche 2: ComplexitÃ©: ModÃ©rÃ©e But: Capturer les relations locales Ã  rÃ©solution moyenne
bracnhe 3 : ComplexitÃ©: Ã‰levÃ©e But: ModÃ©liser des motifs complexes Ã  longue portÃ©e 
branche 4 : ComplexitÃ©: TrÃ¨s faible  But: Fournir une transformation linÃ©aire simple Maintenir l'information originale Ã‰viter la perte d'information des branches complexes

Chaque x_t est un vecteur d'entrÃ©e Ã  l'Ã©tape de temps t
Traite des sÃ©quences temporelles oÃ¹ chaque pas de temps a une relation avec ses voisins
ComposÃ©e de deux couches LSTM parallÃ¨les:
LSTM avant (Forward): Traite la sÃ©quence du passÃ© vers le futur (t-1 â†’ t â†’ t+1)
LSTM arriÃ¨re (Backward): Traite la sÃ©quence du futur vers le passÃ© (t+1 â†’ t â†’ t-1)
Produit la prÃ©diction/sortie pour chaque pas de temps
Le LSTM seul prÃ©sente deux faiblesses majeures :
Perte d'information progressive dans les longues sÃ©quences
DifficultÃ© Ã  capturer les dÃ©pendances Ã  trÃ¨s longue distance
c'est pour cela j'ai ajoute un couche attention qui pÃ¨se l'importance relative de chaque Ã©lÃ©ment d'entrÃ©e et Focalise les ressources computationnelles sur les Ã©lÃ©ments pertinents
#####################################################################################################################

Lâ€™architecture IPA repose sur quatre branches parallÃ¨les, chacune ayant un rÃ´le spÃ©cifique dans lâ€™extraction des caractÃ©ristiques du signal.
Branche 1 : faible complexitÃ©, avec des opÃ©rations simples comme le max-pooling, permettant de capturer les caractÃ©ristiques globales du signal.
Branche 2 : complexitÃ© modÃ©rÃ©e, vise Ã  extraire des relations locales Ã  rÃ©solution moyenne, grÃ¢ce Ã  une combinaison de convolutions.
Branche 3 : la plus complexe, composÃ©e de plusieurs couches convolutionnelles, permet de modÃ©liser des motifs complexes Ã  longue portÃ©e.
Branche 4 : trÃ¨s simple, effectue une transformation linÃ©aire pour prÃ©server l'information originale et Ã©viter les pertes dues aux autres branches plus complexes.

AprÃ¨s concatÃ©nation des sorties de ces quatre branches, un BiLSTM est ajoutÃ© pour traiter la sÃ©quence temporelle :
il prend en entrÃ©e les caractÃ©ristiques de chaque point (chaque 
ğ‘¥
ğ‘¡
x 
t
â€‹
  Ã©tant un vecteur Ã  l'instant 
ğ‘¡
t).
Le BiLSTM est composÃ© de deux LSTM parallÃ¨les : un avant (passÃ© â†’ futur) et un arriÃ¨re (futur â†’ passÃ©), permettant de modÃ©liser les dÃ©pendances dans les deux directions. Cependant, seul, le LSTM peut perdre de l'information sur les longues sÃ©quences et peine Ã  capturer les dÃ©pendances Ã  trÃ¨s longue distance.

Pour pallier ces limites, une couche dâ€™attention est ajoutÃ©e afin de pondÃ©rer lâ€™importance relative de chaque point de la sÃ©quence, permettant au modÃ¨le de focaliser son attention sur les Ã©lÃ©ments pertinents pour une meilleure prÃ©diction.

#############################################################

La Focal Loss binaire, introduite par Lin et al. (2017), est :

FL
(
ğ‘
ğ‘¡
)
=
âˆ’
ğ›¼
ğ‘¡
â‹…
(
1
âˆ’
ğ‘
ğ‘¡
)
ğ›¾
â‹…
log
â¡
(
ğ‘
ğ‘¡
)
FL(p 
t
â€‹
 )=âˆ’Î± 
t
â€‹
 â‹…(1âˆ’p 
t
â€‹
 ) 
Î³
 â‹…log(p 
t
â€‹
 )
ğŸ§© OÃ¹ :
ğ‘
ğ‘¡
p 
t
â€‹
  est la probabilitÃ© prÃ©dite pour la classe correcte (celle donnÃ©e par le label) :

ğ‘
ğ‘¡
=
{
ğ‘
siÂ 
ğ‘¦
=
1
1
âˆ’
ğ‘
siÂ 
ğ‘¦
=
0
p 
t
â€‹
 ={ 
p
1âˆ’p
â€‹
  
siÂ y=1
siÂ y=0
â€‹
 
log
â¡
(
ğ‘
ğ‘¡
)
log(p 
t
â€‹
 ) est la perte classique (entropie croisÃ©e).

(
1
âˆ’
ğ‘
ğ‘¡
)
ğ›¾
(1âˆ’p 
t
â€‹
 ) 
Î³
  est le modulateur qui rÃ©duit lâ€™impact des prÃ©dictions correctes :

Si 
ğ‘
ğ‘¡
p 
t
â€‹
  est proche de 1 (prÃ©diction correcte), alors 
(
1
âˆ’
ğ‘
ğ‘¡
)
ğ›¾
(1âˆ’p 
t
â€‹
 ) 
Î³
  est proche de 0.

Si 
ğ‘
ğ‘¡
p 
t
â€‹
  est proche de 0 (mauvaise prÃ©diction), le terme est proche de 1.

ğ›¾
â‰¥
0
Î³â‰¥0 est lâ€™exposant de focalisation :

ContrÃ´le Ã  quel point on ignore les exemples faciles.

Plus 
ğ›¾
Î³ est grand, plus on se concentre sur les exemples mal classÃ©s.

ğ›¼
ğ‘¡
âˆˆ
[
0
,
1
]
Î± 
t
â€‹
 âˆˆ[0,1] est un poids pour chaque classe :

ğ›¼
ğ‘¡
=
{
ğ›¼
siÂ 
ğ‘¦
=
1
1
âˆ’
ğ›¼
siÂ 
ğ‘¦
=
0
Î± 
t
â€‹
 ={ 
Î±
1âˆ’Î±
â€‹
  
siÂ y=1
siÂ y=0
â€‹

RÃ©cupÃ©rer le temps de rÃ©tention de chaque pic dÃ©tectÃ© par IPA 
Collecter les temps de rÃ©tention de tous les pics en notre possession.
EntraÃ®ner un NearestNeighbors sur ces temps de rÃ©tention
Recherche avec NearestNeighbors
RÃ©cupÃ©rer lâ€™indice du plus proche voisin dans les donnÃ©es dâ€™entraÃ®nement.
Assigner au pic IPA le nom du composant du plus proche voisin.