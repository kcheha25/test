import numpy as np
import tensorflow as tf
import math
from sklearn.model_selection import train_test_split
import pandas as pd

class ChromatogramLabelEncoder:
    def __init__(self, signal_length=71840):
        self.signal_length = signal_length
        self.signal = np.linspace(0, signal_length, num=signal_length)  # L'axe du temps pour le signal

    def encode(self, peaks_data):
        """
        peaks_data: Dictionnaire {position_pic: [composant, borne_gauche, borne_droite]}
        Retourne: array de shape (signal_length, 4) [prob, loc_norm, left_norm, right_norm]
        """
        labels = np.zeros((self.signal_length, 4))
        
        for rt_str, (_, left_bound, right_bound) in peaks_data.items():
            # Conversion de la clé (position) en float
            try:
                rt = float(rt_str)
            except ValueError:
                continue  # Ignore les entrées non convertibles
                
            # Trouver l'indice le plus proche pour la position du pic dans le signal
            closest_idx = np.argmin(np.abs(self.signal - rt))
            
            # Normaliser la position par rapport à la longueur du signal
            loc_norm = rt / self.signal_length
            
            # Normaliser les bornes [0,1] par rapport au signal complet
            left_norm = float(left_bound) / self.signal_length
            right_norm = float(right_bound) / self.signal_length
            
            # Mettre à jour le tableau des labels pour le pic
            labels[closest_idx, 0] = 1.0  # Probabilité
            labels[closest_idx, 1] = loc_norm  # Position relative
            labels[closest_idx, 2] = left_norm  # Borne gauche normalisée
            labels[closest_idx, 3] = right_norm  # Borne droite normalisée
            
        return labels

class ChromatogramDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, df, label_encoder, batch_size=32, shuffle=False):
        self.df = df
        self.label_encoder = label_encoder
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indices = np.arange(len(df))
        self.on_epoch_end()

    def __len__(self):
        return math.ceil(len(self.df) / self.batch_size)

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indices)

    def _preprocess(self, x, y=None):
        """Normalisation du signal chromatographique"""
        x = np.array(x, dtype=np.float32)
        max_val = np.max(x) + 1e-8  # Éviter la division par zéro
        x_norm = x[:, None] / max_val  # Shape (71840, 1)
        
        if y is not None:
            return x_norm, y.astype(np.float32)
        return x_norm

    def __getitem__(self, index):
        batch_indices = self.indices[index*self.batch_size : (index+1)*self.batch_size]
        
        x_batch = []
        y_batch = []
        
        for idx in batch_indices:
            row = self.df.iloc[idx]
            
            # Récupérer les données brutes
            chromatogram = row['y']
            peaks_data = row['pics']
            
            # Encodage des labels
            y = self.label_encoder.encode(peaks_data)
            
            # Prétraitement
            x, y = self._preprocess(chromatogram, y)
            
            x_batch.append(x)
            y_batch.append(y)
            
        return np.array(x_batch), np.array(y_batch)

# -----------------------------------------------------------
# Exemple d'utilisation
# -----------------------------------------------------------
if __name__ == "__main__":
    # 1. Charger les données
    df = pd.read_json("chromatogrammes.json")
    df = df[df['x'].apply(len) == 71840]  # Filtrer par longueur
    
    # 2. Initialiser les composants
    label_encoder = ChromatogramLabelEncoder()
    
    # 3. Split train/test
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
    
    # 4. Créer les générateurs
    train_gen = ChromatogramDataGenerator(
        train_df, label_encoder, batch_size=32, shuffle=True
    )
    test_gen = ChromatogramDataGenerator(
        test_df, label_encoder, batch_size=32, shuffle=False
    )
    
    # 5. Exemple de batch
    x_batch, y_batch = train_gen[0]
    print(f"Batch X shape: {x_batch.shape}")  # (32, 71840, 1)
    print(f"Batch y shape: {y_batch.shape}")  # (32, 71840, 4)
