import numpy as np
import tensorflow as tf
import math
from sklearn.model_selection import train_test_split
import pandas as pd

class ChromatogramLabelEncoder:
    def __init__(self, num_windows=256, signal_length=71840):
        self.num_windows = num_windows
        self.signal_length = signal_length
        self.window_size = signal_length / num_windows  # ≈280.625 points/fenêtre
        self.window_borders = np.linspace(0, signal_length, num_windows + 1)
        self.window_centers = self.window_borders[:-1] + self.window_size/2

    def encode(self, peaks_data):
        """
        peaks_data: Dictionnaire {position_pic: [composant, borne_gauche, borne_droite]}
        Retourne: array de shape (num_windows, 4) [prob, loc_norm, left_norm, right_norm]
        """
        labels = np.zeros((self.num_windows, 4))
        
        for rt_str, (_, left_bound, right_bound) in peaks_data.items():
            # Conversion de la clé (position) en float
            try:
                rt = float(rt_str)
            except ValueError:
                continue  # Ignore les entrées non convertibles
                
            # Trouver l'index de la fenêtre
            window_idx = np.searchsorted(self.window_borders, rt) - 1
            window_idx = np.clip(window_idx, 0, self.num_windows - 1)
            
            # Calculer la position relative dans la fenêtre [0,1]
            window_start = self.window_borders[window_idx]
            loc_in_window = (rt - window_start) / self.window_size
            
            # Normaliser les bornes [0,1] par rapport au signal complet
            left_norm = float(left_bound) / self.signal_length
            right_norm = float(right_bound) / self.signal_length
            
            labels[window_idx, 0] = 1.0  # Probabilité
            labels[window_idx, 1] = loc_in_window  # Position relative
            labels[window_idx, 2] = left_norm  # Borne gauche normalisée
            labels[window_idx, 3] = right_norm  # Borne droite normalisée
            
        return labels

    def remove_collisions(self, peaks_data):
        """Supprime les pics dans la même fenêtre"""
        filtered_peaks = {}
        occupied_windows = set()
        
        for rt_str in sorted(peaks_data.keys()):
            try:
                rt = float(rt_str)
            except ValueError:
                continue
                
            window_idx = np.searchsorted(self.window_borders, rt) - 1
            if window_idx not in occupied_windows:
                filtered_peaks[rt_str] = peaks_data[rt_str]
                occupied_windows.add(window_idx)
                
        return filtered_peaks

class ChromatogramDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, df, label_encoder, batch_size=32, shuffle=False):
        self.df = df
        self.label_encoder = label_encoder
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indices = np.arange(len(df))
        self.on_epoch_end()

    def __len__(self):
        return math.ceil(len(self.df) / self.batch_size)

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indices)

    def _preprocess(self, x, y=None):
        """Normalisation du signal chromatographique"""
        x = np.array(x, dtype=np.float32)
        max_val = np.max(x) + 1e-8  # Éviter la division par zéro
        x_norm = x[:, None] / max_val  # Shape (71840, 1)
        
        if y is not None:
            return x_norm, y.astype(np.float32)
        return x_norm

    def __getitem__(self, index):
        batch_indices = self.indices[index*self.batch_size : (index+1)*self.batch_size]
        
        x_batch = []
        y_batch = []
        
        for idx in batch_indices:
            row = self.df.iloc[idx]
            
            # Récupérer les données brutes
            chromatogram = row['y']
            peaks_data = row['pics']
            
            # Nettoyer les collisions
            filtered_peaks = self.label_encoder.remove_collisions(peaks_data)
            
            # Encodage des labels
            y = self.label_encoder.encode(filtered_peaks)
            
            # Prétraitement
            x, y = self._preprocess(chromatogram, y)
            
            x_batch.append(x)
            y_batch.append(y)
            
        return np.array(x_batch), np.array(y_batch)

# -----------------------------------------------------------
# Exemple d'utilisation
# -----------------------------------------------------------
if __name__ == "__main__":
    # 1. Charger les données
    df = pd.read_json("chromatogrammes.json")
    df = df[df['x'].apply(len) == 71840]  # Filtrer par longueur
    
    # 2. Initialiser les composants
    label_encoder = ChromatogramLabelEncoder(num_windows=256)
    
    # 3. Split train/test
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
    
    # 4. Créer les générateurs
    train_gen = ChromatogramDataGenerator(
        train_df, label_encoder, batch_size=32, shuffle=True
    )
    test_gen = ChromatogramDataGenerator(
        test_df, label_encoder, batch_size=32, shuffle=False
    )
    
    # 5. Exemple de batch
    x_batch, y_batch = train_gen[0]
    print(f"Batch X shape: {x_batch.shape}")  # (32, 71840, 1)
    print(f"Batch y shape: {y_batch.shape}")  # (32, 256, 4)