import numpy as np
import pandas as pd
import tensorflow as tf
import math

class DataGenerator(tf.keras.utils.Sequence):

    def __init__(
        self,
        indices,
        df,
        batch_size=32,
        window_size=256,
        shuffle=False
    ):
        self.indices = indices
        self.df = df
        self.batch_size = batch_size
        self.window_size = window_size
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        return math.ceil(len(self.indices) / self.batch_size)

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indices)

    @staticmethod
    def _preprocess(x, y=None):
        x = x[:, None]
        max_val = x.max()
        if y is not None:
            y[:, -1] /= max_val
            y[:, -1] *= 600  # scale area to a 600 second long run
            return x / max_val, y
        return x / max_val

    def __getitem__(self, index):

        batch_indices = self.indices[
            index * self.batch_size: (1 + index) * self.batch_size
        ]

        x_batch, y_batch = [], []
        for idx in batch_indices:
            row = self.df.iloc[idx]
            chromatogram_x = np.array(row["x"])
            chromatogram_y = np.array(row["y"])

            # Extraire les informations des pics
            heights, bounds, components = [], [], []
            for valeur_pic, data in row["pics"].items():
                borne_avant = data[1]
                borne_apres = data[2]
                # Calcul de l'aire sous la courbe
                area = np.trapz(chromatogram_y[int(borne_avant):int(borne_apres)])
                
                # Trouver l'index correspondant au temps de valeur_pic
                pic_idx = np.argmin(np.abs(chromatogram_x - valeur_pic))  # Trouver l'index le plus proche

                heights.append(chromatogram_y[pic_idx])  # Utiliser pic_idx au lieu de valeur_pic
                bounds.append((borne_avant, borne_apres))
                components.append(valeur_pic)

            # Cr√©ation de X et Y pour chaque fen√™tre
            for start_idx in range(0, len(chromatogram_x) - self.window_size + 1, self.window_size):
                end_idx = start_idx + self.window_size
                window_x = chromatogram_x[start_idx:end_idx]
                window_y = chromatogram_y[start_idx:end_idx]
                
                # Initialisation de Y (probabilit√© de pic, localisation, aire sous la courbe)
                y = np.zeros((self.window_size, 4))  # 4: probabilit√©, localisation, aire, (0)
                
                # Pour chaque pic, remplir les informations correspondantes dans Y
                for h, (borne_avant, borne_apres), pic in zip(heights, bounds, components):
                    # Localisation du pic dans la fen√™tre (en terme de l'index local)
                    local_loc = np.argmin(np.abs(window_x - pic))
                    # Probabilit√© d'avoir un pic √† cet endroit
                    prob = 1.0
                    y[local_loc, 0] = prob  # probabilit√©
                    y[local_loc, 1] = pic   # localisation du pic
                    y[local_loc, 2] = area  # aire sous la courbe
                    # Optionnel : la 4√®me colonne pourrait √™tre des informations suppl√©mentaires
                    y[local_loc, 3] = 0     # (par exemple, 0 si on ne souhaite pas l'utiliser)
                
                x_batch.append(window_x)
                y_batch.append(y)

        # Retourner les batchs pr√©trait√©s
        return np.array(x_batch), np.array(y_batch)


# Exemple d'utilisation du g√©n√©rateur

# üîπ Charger les donn√©es JSON en DataFrame
file_path = "chromatogrammes.json"  # Remplace par ton fichier r√©el
df = pd.read_json(file_path)

# üîπ Suppression des chromatogrammes sans pics
df = df.dropna(subset=['pics'])

# üîπ Suppression des chromatogrammes qui ne font pas exactement 71 840 points
df = df[df["x"].apply(len) == 71840]

# üîπ Initialisation du g√©n√©rateur de donn√©es
indices = np.arange(len(df))  # indices pour l'ensemble des donn√©es
batch_size = 32
data_generator = DataGenerator(indices=indices, df=df, batch_size=batch_size, window_size=256, shuffle=True)

# üîπ Acc√©der aux donn√©es du g√©n√©rateur (par exemple, lors de l'entra√Ænement)
for x_batch, y_batch in data_generator:
    print(x_batch.shape, y_batch.shape)  # Afficher les dimensions de X et Y
    break  # Ne prend qu'un seul batch pour l'exemple
