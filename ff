import cv2
import numpy as np

# 1. Charger l’image en niveaux de gris
img = cv2.imread('bille.png', cv2.IMREAD_GRAYSCALE)

# 2. Flouter légèrement
blur = cv2.GaussianBlur(img, (5, 5), 0)

# 3. Seuillage avec Otsu (bille claire = blanc, fond = noir)
_, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

# 4. Inverser : la bille devient noire, fond = blanc (facilite le remplissage)
binary_inv = cv2.bitwise_not(binary)

# 5. Remplir les zones connectées au fond (flood fill)
floodfill = binary_inv.copy()
h, w = floodfill.shape[:2]
mask = np.zeros((h + 2, w + 2), np.uint8)

# Remplir depuis un pixel du fond (coin par ex.)
cv2.floodFill(floodfill, mask, (0, 0), 255)

# 6. Trou noir = fond, on récupère la bille entière : inversion + OU logique
bille_filled = cv2.bitwise_not(floodfill) | binary_inv

# 7. Détection des contours sur l’image nettoyée
contours, _ = cv2.findContours(bille_filled, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 8. Filtrer contours avec taille a >= 100
filtered = [cnt for cnt in contours if cnt.shape[0] >= 100]

# 9. Sélection des 1 ou 2 plus gros
selected = sorted(filtered, key=cv2.contourArea, reverse=True)[:2]
output = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

for c in selected:
    # Créer un masque vide pour le contour
    mask = np.zeros_like(img)
    cv2.drawContours(mask, [c], -1, 255, thickness=1)

    # Dilater le masque (élargissement du contour)
    dilated = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (21, 21)))  # ≈10 px de rayon
    dilated = cv2.subtract(dilated, mask)  # Garde uniquement la bordure externe

    # Appliquer le contour élargi en bleu
    output[dilated > 0] = (255, 0, 0)  # Bleu

# 12. Dessiner les contours d’origine en rouge
for c in selected:
    cv2.drawContours(output, [c], -1, (0, 0, 255), 2)  # Rouge
cv2.imshow("Bille avec trous latéraux détectée", output)
cv2.waitKey(0)
cv2.destroyAllWindows()


import os
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog

# === Paramètres ===
image_path = "chemin/vers/image_complete.png"
patch_size = (512, 350)      # taille de base du patch
resized_size = (512, 400)    # taille du patch après redimensionnement
overlap = 50                 # recouvrement entre patchs

# === Initialiser le modèle Detectron2 ===
cfg = get_cfg()
cfg.merge_from_file("chemin/vers/config.yaml")
cfg.MODEL.WEIGHTS = "chemin/vers/model_final.pth"
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)
metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])

# === Charger l'image complète ===
image = Image.open(image_path).convert("RGB")
width, height = image.size
full_image_np = np.array(image)
output_image = full_image_np.copy()  # copie pour superposer les prédictions

# === Générer les patchs et lancer l'inférence ===
patch_id = 0
pw, ph = patch_size
rw, rh = resized_size

for y in range(0, height, ph - overlap):
    for x in range(0, width, pw - overlap):
        # Définir dynamiquement la taille du patch en fonction de patch_id
        if patch_id == 0:
            crop_w, crop_h = pw, ph
        elif patch_id == 1:
            crop_w, crop_h = pw + overlap, ph
        elif patch_id == 2:
            crop_w, crop_h = pw, ph + overlap
        else:
            crop_w, crop_h = pw + overlap, ph + overlap

        # Empêcher le dépassement de l'image
        crop_w = min(crop_w, width - x)
        crop_h = min(crop_h, height - y)

        # Extraction et redimensionnement du patch
        patch = image.crop((x, y, x + crop_w, y + crop_h)).resize(resized_size)
        patch_np = np.array(patch)

        # Lancer l'inférence sur le patch
        outputs = predictor(patch_np)

        # Visualisation des prédictions sur le patch
        v = Visualizer(patch_np, metadata=metadata, scale=1.0, instance_mode=ColorMode.IMAGE)
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

        # Remettre à l'échelle le patch prédit vers la taille d'origine du patch (crop_w, crop_h)
        overlay = cv2.resize(out.get_image(), (crop_w, crop_h))

        # Fusionner les prédictions avec l'image de sortie (blending)
        output_image[y:y + crop_h, x:x + crop_w] = cv2.addWeighted(
            output_image[y:y + crop_h, x:x + crop_w], 0.5, overlay, 0.5, 0
        )

        patch_id += 1

# === Afficher le résultat avec Matplotlib ===
plt.figure(figsize=(10, 8))
plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))
plt.title("Image complète avec prédictions")
plt.axis('off')
plt.show()

# Pour enregistrer le résultat, tu peux utiliser cv2.imwrite :
# cv2.imwrite("image_pred_complete.png", output_image)
