import cv2
import numpy as np

# 1. Charger l’image en niveaux de gris
img = cv2.imread('bille.png', cv2.IMREAD_GRAYSCALE)

# 2. Flouter légèrement
blur = cv2.GaussianBlur(img, (15, 15), 0)

# 3. Seuillage avec Otsu (bille claire = blanc, fond = noir)
_, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)


# 7. Détection des contours sur l’image nettoyée
contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 8. Filtrer contours avec taille a >= 100
filtered = [cnt for cnt in contours if cnt.shape[0] >= 100]

# 9. Sélection des 1 ou 2 plus gros
selected = sorted(filtered, key=cv2.contourArea, reverse=True)[:2]
output = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

for c in selected:
    # Créer un masque vide pour le contour
    mask = np.zeros_like(img)
    cv2.drawContours(mask, [c], -1, 255, thickness=1)

    # Dilater le masque (élargissement du contour)
    dilated = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (30, 30)))  # ≈10 px de rayon
    dilated = cv2.subtract(dilated, mask)  # Garde uniquement la bordure externe

    # Appliquer le contour élargi en bleu
    output[dilated > 0] = (255, 0, 0)  # Bleu

# 12. Dessiner les contours d’origine en rouge
for c in selected:
    cv2.drawContours(output, [c], -1, (0, 0, 255), 2)  # Rouge
cv2.imshow("Bille avec trous latéraux détectée", output)
cv2.waitKey(0)
cv2.destroyAllWindows()


import os
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog

# === Paramètres ===
image_path = "chemin/vers/image_complete.png"
patch_size = (512, 350)      # taille de base du patch
resized_size = (512, 400)    # taille du patch après redimensionnement
overlap = 50                 # recouvrement entre patchs

# === Initialiser le modèle Detectron2 ===
cfg = get_cfg()
cfg.merge_from_file("chemin/vers/config.yaml")
cfg.MODEL.WEIGHTS = "chemin/vers/model_final.pth"
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)
metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])

# === Charger l'image complète ===
image = Image.open(image_path).convert("RGB")
width, height = image.size
full_image_np = np.array(image)
output_image = full_image_np.copy()  # copie pour superposer les prédictions

# === Générer les patchs et lancer l'inférence ===
patch_id = 0
pw, ph = patch_size
rw, rh = resized_size

for y in range(0, height, ph - overlap):
    for x in range(0, width, pw - overlap):
        # Définir dynamiquement la taille du patch en fonction de patch_id
        if patch_id == 0:
            crop_w, crop_h = pw, ph
        elif patch_id == 1:
            crop_w, crop_h = pw + overlap, ph
        elif patch_id == 2:
            crop_w, crop_h = pw, ph + overlap
        else:
            crop_w, crop_h = pw + overlap, ph + overlap

        # Empêcher le dépassement de l'image
        crop_w = min(crop_w, width - x)
        crop_h = min(crop_h, height - y)

        # Extraction et redimensionnement du patch
        patch = image.crop((x, y, x + crop_w, y + crop_h)).resize(resized_size)
        patch_np = np.array(patch)

        # Lancer l'inférence sur le patch
        outputs = predictor(patch_np)

        # Visualisation des prédictions sur le patch
        v = Visualizer(patch_np, metadata=metadata, scale=1.0, instance_mode=ColorMode.IMAGE)
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

        # Remettre à l'échelle le patch prédit vers la taille d'origine du patch (crop_w, crop_h)
        overlay = cv2.resize(out.get_image(), (crop_w, crop_h))

        # Fusionner les prédictions avec l'image de sortie (blending)
        output_image[y:y + crop_h, x:x + crop_w] = cv2.addWeighted(
            output_image[y:y + crop_h, x:x + crop_w], 0.5, overlay, 0.5, 0
        )

        patch_id += 1

# === Afficher le résultat avec Matplotlib ===
plt.figure(figsize=(10, 8))
plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))
plt.title("Image complète avec prédictions")
plt.axis('off')
plt.show()

# Pour enregistrer le résultat, tu peux utiliser cv2.imwrite :
# cv2.imwrite("image_pred_complete.png", output_image)


import os
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog

# === Paramètres ===
image_path = "chemin/vers/image_complete.png"  # À modifier
config_path = "chemin/vers/config.yaml"         # À modifier
weights_path = "chemin/vers/model_final.pth"    # À modifier

patch_size = (512, 350)
resized_size = (512, 400)
overlap = 50

# === Initialisation du modèle Detectron2 ===
cfg = get_cfg()
cfg.merge_from_file(config_path)
cfg.MODEL.WEIGHTS = weights_path
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)
metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])

# === Charger l’image ===
image = Image.open(image_path).convert("RGB")
width, height = image.size
full_image_np = np.array(image)
output_image = full_image_np.copy()

# Masque pour objets pris en compte
considered_objects_mask = np.zeros((height, width), dtype=np.uint8)
class_map = np.full((height, width), fill_value=255, dtype=np.uint8)  # 255 = fond

# === Découpage en patchs et inférence ===
patch_id = 0
pw, ph = patch_size

for y in range(0, height, ph - overlap):
    for x in range(0, width, pw - overlap):
        crop_w = min(pw + (overlap if x + pw < width else 0), width - x)
        crop_h = min(ph + (overlap if y + ph < height else 0), height - y)

        patch = image.crop((x, y, x + crop_w, y + crop_h)).resize(resized_size)
        patch_np = np.array(patch)

        outputs = predictor(patch_np)
        instances = outputs["instances"].to("cpu")

        for i in range(len(instances)):
            class_id = int(instances.pred_classes[i])
            mask = instances.pred_masks[i].numpy().astype(np.uint8) * 255
            mask_resized = cv2.resize(mask, (crop_w, crop_h), interpolation=cv2.INTER_NEAREST)

            # Position de l’objet dans l’image complète
            y1, y2 = y, y + crop_h
            x1, x2 = x, x + crop_w

            # Fusion sur class_map
            class_map[y1:y2, x1:x2][mask_resized > 127] = class_id

# === Détection des contours de la bille ===
img_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
blur = cv2.GaussianBlur(img_gray, (15, 15), 0)
_, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# Prendre les 2 plus gros contours
filtered = [cnt for cnt in contours if cnt.shape[0] >= 100]
selected = sorted(filtered, key=cv2.contourArea, reverse=True)[:2]

# Masque original + masque dilaté (pour inclure objets touchants les bords)
bille_mask = np.zeros_like(img_gray, dtype=np.uint8)
bille_dilated_mask = np.zeros_like(img_gray, dtype=np.uint8)

for c in selected:
    temp_mask = np.zeros_like(img_gray, dtype=np.uint8)
    cv2.drawContours(temp_mask, [c], -1, 255, thickness=-1)
    bille_mask = cv2.bitwise_or(bille_mask, temp_mask)
    dilated = cv2.dilate(temp_mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (61, 61)))  # ≈ 30 px
    bille_dilated_mask = cv2.bitwise_or(bille_dilated_mask, dilated)

# === Sélectionner uniquement les objets touchant la bille (ou bord) ===
considered_objects_mask[:] = 0
final_class_map = np.full_like(class_map, fill_value=255)

for class_id in [0, 1, 2]:
    mask = (class_map == class_id).astype(np.uint8)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)

    for i in range(1, num_labels):  # 0 = fond
        component_mask = (labels == i).astype(np.uint8)
        overlap = np.logical_and(component_mask, bille_dilated_mask).any()

        if overlap:
            final_class_map[component_mask == 1] = class_id
            considered_objects_mask[component_mask == 1] = 255

# === Calcul du pourcentage d’occupation par classe ===
total_pixels = np.sum(bille_dilated_mask > 0)
fractions = {}

for class_id in [0, 1, 2]:
    pixels = np.sum((final_class_map == class_id) & (considered_objects_mask > 0))
    fractions[class_id] = round(100 * pixels / total_pixels, 2) if total_pixels else 0

# === Affichage des résultats ===
print("Fraction d’occupation (objets touchant ou dans bille élargie) :")
for cid, perc in fractions.items():
    print(f"  Classe {cid} : {perc} %")

# === Affichages visuels ===
# 1. Image avec contours de billes
image_with_contours = output_image.copy()
for c in selected:
    cv2.drawContours(image_with_contours, [c], -1, (0, 255, 255), 2)

# 2. Masque des bordures dilatées
plt.figure(figsize=(10, 6))
plt.imshow(bille_dilated_mask, cmap='gray')
plt.title("Masque dilaté des billes (zone d'inclusion)")
plt.axis("off")
plt.show()

# 3. Image des objets pris en compte
objects_image = full_image_np.copy()
objects_image[considered_objects_mask == 0] = 0  # Masquer le fond
for c in selected:
    cv2.drawContours(objects_image, [c], -1, (255, 255, 0), 2)

plt.figure(figsize=(10, 6))
plt.imshow(cv2.cvtColor(objects_image, cv2.COLOR_BGR2RGB))
plt.title("Objets pris en compte avec bordure de la bille")
plt.axis("off")
plt.show()

# 4. Image avec toutes les prédictions et contours
plt.figure(figsize=(12, 8))
plt.imshow(cv2.cvtColor(image_with_contours, cv2.COLOR_BGR2RGB))
plt.title("Image complète avec prédictions + contours de bille")
plt.axis("off")
plt.show()


# === Interface pour dessiner les polygones à la main ===
drawing = False
polygon_points = []
all_polygons = []

def draw_polygon(event, x, y, flags, param):
    global drawing, polygon_points, all_polygons

    if event == cv2.EVENT_LBUTTONDOWN:
        polygon_points.append((x, y))

    elif event == cv2.EVENT_RBUTTONDOWN:
        if len(polygon_points) >= 3:
            all_polygons.append(polygon_points[:])
            polygon_points = []

# Affichage de l'image et dessin
temp_image = output_image.copy()
cv2.namedWindow("Dessine les polygones (clic gauche: points, clic droit: fermer)")
cv2.setMouseCallback("Dessine les polygones (clic gauche: points, clic droit: fermer)", draw_polygon)

while True:
    img_copy = temp_image.copy()
    for poly in all_polygons:
        cv2.polylines(img_copy, [np.array(poly, dtype=np.int32)], isClosed=True, color=(0, 255, 0), thickness=2)
    if polygon_points:
        cv2.polylines(img_copy, [np.array(polygon_points, dtype=np.int32)], isClosed=False, color=(255, 0, 0), thickness=1)

    cv2.imshow("Dessine les polygones (clic gauche: points, clic droit: fermer)", img_copy)
    key = cv2.waitKey(10)
    if key == 13:  # ENTER pour terminer
        break

cv2.destroyAllWindows()

# === Création du masque à partir des polygones dessinés ===
zone_mask = np.zeros((height, width), dtype=np.uint8)
for poly in all_polygons:
    cv2.fillPoly(zone_mask, [np.array(poly, dtype=np.int32)], 255)


# === Calcul du pourcentage d’occupation par classe dans les polygones dessinés ===
total_pixels = np.sum(zone_mask > 0)
fractions = {}

for class_id in [0, 1, 2]:
    pixels = np.sum((final_class_map == class_id) & (zone_mask > 0))
    fractions[class_id] = round(100 * pixels / total_pixels, 2) if total_pixels else 0

# === Affichage des résultats ===
print("Fraction d’occupation (à l’intérieur des polygones dessinés) :")
for cid, perc in fractions.items():
    print(f"  Classe {cid} : {perc} %")


import tkinter as tk
from PIL import ImageTk

polygon_points = []
all_polygons = []
zone_mask = np.zeros((height, width), dtype=np.uint8)

def on_click(event):
    x, y = event.x, event.y
    polygon_points.append((x, y))
    r = 2
    canvas.create_oval(x - r, y - r, x + r, y + r, fill='red')

def close_polygon():
    global polygon_points
    if len(polygon_points) >= 3:
        all_polygons.append(polygon_points[:])
        canvas.create_polygon(polygon_points, outline='green', fill='', width=2)
        polygon_points = []

def finish():
    root.destroy()

# === Créer interface Tkinter ===
root = tk.Tk()
root.title("Dessine les polygones (clic: points, bouton: fermer)")

# Convertir image pour Tkinter
image_tk = ImageTk.PhotoImage(Image.fromarray(output_image))

canvas = tk.Canvas(root, width=width, height=height)
canvas.pack()
canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)
canvas.bind("<Button-1>", on_click)

# Boutons
btn_frame = tk.Frame(root)
btn_frame.pack()
tk.Button(btn_frame, text="Fermer polygone", command=close_polygon).pack(side=tk.LEFT, padx=10)
tk.Button(btn_frame, text="Terminer", command=finish).pack(side=tk.RIGHT, padx=10)

root.mainloop()

# === Création du masque à partir des polygones dessinés ===
zone_mask = np.zeros((height, width), dtype=np.uint8)
for poly in all_polygons:
    cv2.fillPoly(zone_mask, [np.array(poly, dtype=np.int32)], 255)


# === Calcul du volume estimé par classe (en supposant sphères) ===
import math

volume_par_classe = {}
diametre_moyen = {}
nb_objets = {}

for class_id in [0, 1, 2]:
    mask = (class_map == class_id).astype(np.uint8)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)

    diam_list = []
    volumes = []

    for i in range(1, num_labels):  # i=0 = fond
        area = stats[i, cv2.CC_STAT_AREA]
        if area < 5:
            continue
        # Diamètre équivalent circulaire
        ecd = 2 * np.sqrt(area / np.pi)
        diam_list.append(ecd)

        # Volume d'une sphère : V = 4/3 * pi * (r^3)
        radius = ecd / 2
        volume = (4 / 3) * np.pi * (radius ** 3)
        volumes.append(volume)

    if diam_list:
        diametre_moyen[class_id] = np.mean(diam_list)
        volume_par_classe[class_id] = np.sum(volumes)
        nb_objets[class_id] = len(volumes)
    else:
        diametre_moyen[class_id] = 0
        volume_par_classe[class_id] = 0
        nb_objets[class_id] = 0

# === Affichage des résultats volumétriques ===
print("\nVolume estimé par classe (sphères équivalentes) :")
for cid in [0, 1, 2]:
    print(f"  Classe {cid} :")
    print(f"    - Nombre de particules : {nb_objets[cid]}")
    print(f"    - Diamètre moyen ≈ {diametre_moyen[cid]:.2f} px")
    print(f"    - Volume total estimé ≈ {volume_par_classe[cid]:.2f} px³")

# === Calcul du Vcube et L ===
# Convertir les fractions (%) en décimales
fractions_decimales = {cid: fractions[cid] / 100 for cid in [0, 1, 2]}

# Éviter division par zéro
Vcube = 0
for cid in [0, 1, 2]:
    f = fractions_decimales[cid]
    v = volume_par_classe[cid]
    if f > 0:
        Vcube += v / f

# Calcul de L = racine cubique du volume
if Vcube > 0:
    L = Vcube ** (1 / 3)
    print(f"\nVolume du cube estimé : Vcube ≈ {Vcube:.2f} px³")
    print(f"Longueur caractéristique (L) ≈ {L:.2f} px")
else:
    print("\nImpossible de calculer Vcube (aucune fraction détectée).")


Exemple numérique
Imaginons 3 phases (hors matrice):

Phase	Volume estimé 
𝑉
𝑖
V 
i
​
 	Fraction 
𝑓
𝑖
f 
i
​
 
Dense	5000	0.15
Creux	3000	0.20
Intermédiaire	1000	0.05

Calcul du volume du cube :

𝑉
cube
=
5000
0.15
+
3000
0.20
+
1000
0.05
=
33333.3
+
15000
+
20000
=
68333.3
V 
cube
​
 = 
0.15
5000
​
 + 
0.20
3000
​
 + 
0.05
1000
​
 =33333.3+15000+20000=68333.3
Calcul de 
𝐿
L :

𝐿
=
68333.3
3
≈
40.8
L= 
3
  
68333.3
​
 ≈40.8


 import numpy as np
from skimage.measure import regionprops, label
from sklearn.cluster import KMeans

# === Paramètres d'entrée ===
resolution_nm = 446  # nm/px
resolution_um = resolution_nm / 1000  # µm/px
cube_size_vox = 333

# Ces variables doivent exister à ce stade :
# final_class_map : tableau numpy 2D avec les classes (int: 0,1,2)
# zone_mask : masque binaire avec les polygones dessinés (uint8)

class_stats = {}

# === Analyse par classe (et KMeans sur 0 et 1) ===
for class_id in [0, 1, 2]:
    mask = ((final_class_map == class_id) & (zone_mask > 0)).astype(np.uint8)
    labeled = label(mask)
    props = regionprops(labeled)

    sizes_um = []
    for p in props:
        minr, minc, maxr, maxc = p.bbox
        w_um = (maxc - minc) * resolution_um
        h_um = (maxr - minr) * resolution_um
        sizes_um.append([w_um, h_um])

    sizes_um = np.array(sizes_um)
    if len(sizes_um) == 0:
        continue

    if class_id in [0, 1] and len(sizes_um) >= 2:
        kmeans = KMeans(n_clusters=2, random_state=0).fit(sizes_um)
        labels = kmeans.labels_
        for k in range(2):
            group = sizes_um[labels == k]
            if len(group) > 0:
                mean_x, mean_y = np.mean(group, axis=0)
                mean_z = (mean_x + mean_y) / 2  # Z estimé comme moyenne
                key = f"class_{class_id}_sub{k}"
                class_stats[key] = {
                    "mean_x_um": mean_x,
                    "mean_y_um": mean_y,
                    "mean_z_um": mean_z,
                    "vox_x": round(mean_x / resolution_um),
                    "vox_y": round(mean_y / resolution_um),
                    "vox_z": round(mean_z / resolution_um)
                }
    else:
        mean_x, mean_y = np.mean(sizes_um, axis=0)
        mean_z = (mean_x + mean_y) / 2
        key = f"class_{class_id}"
        class_stats[key] = {
            "mean_x_um": mean_x,
            "mean_y_um": mean_y,
            "mean_z_um": mean_z,
            "vox_x": round(mean_x / resolution_um),
            "vox_y": round(mean_y / resolution_um),
            "vox_z": round(mean_z / resolution_um)
        }

# === Résultat final ===
print("Taille moyenne des objets par classe (en µm et voxels) :")
for cls, vals in class_stats.items():
    print(f"{cls}:")
    print(f"  ↪️  µm  : (x={vals['mean_x_um']:.2f}, y={vals['mean_y_um']:.2f}, z={vals['mean_z_um']:.2f})")
    print(f"  ↪️  vox : (x={vals['vox_x']}, y={vals['vox_y']}, z={vals['vox_z']})")


import numpy as np
from skimage.measure import regionprops, label
from sklearn.cluster import KMeans

# === Paramètres d'entrée ===
resolution_nm = 446  # nm/px
resolution_um = resolution_nm / 1000  # µm/px
cube_size_vox = 333  # utilisé ailleurs si besoin

# Ces variables doivent exister à ce stade :
# final_class_map : tableau numpy 2D avec les classes (int: 0,1,2)
# zone_mask : masque binaire avec les polygones dessinés (uint8)

class_stats = {}

# === Analyse Feret par classe (et sous-classe pour 0 & 1) ===
for class_id in [0, 1, 2]:
    mask = ((final_class_map == class_id) & (zone_mask > 0)).astype(np.uint8)
    labeled = label(mask)
    props = regionprops(labeled)

    feret_features = []
    for p in props:
        if p.area < 10:
            continue
        feret_max_um = p.feret_diameter_max * resolution_um
        feret_min_um = p.minor_axis_length * resolution_um if p.minor_axis_length else feret_max_um
        feret_z_um = (feret_max_um + feret_min_um) / 2
        feret_features.append([feret_max_um, feret_min_um, feret_z_um])

    feret_features = np.array(feret_features)
    if len(feret_features) == 0:
        continue

    if class_id in [0, 1] and len(feret_features) >= 2:
        kmeans = KMeans(n_clusters=2, n_init="auto", random_state=0).fit(feret_features[:, :2])
        labels = kmeans.labels_
        for k in range(2):
            group = feret_features[labels == k]
            if len(group) > 0:
                mean_x, mean_y, mean_z = np.mean(group, axis=0)
                key = f"class_{class_id}_sub{k}"
                class_stats[key] = {
                    "mean_x_um": mean_x,
                    "mean_y_um": mean_y,
                    "mean_z_um": mean_z,
                    "vox_x": round(mean_x / resolution_um),
                    "vox_y": round(mean_y / resolution_um),
                    "vox_z": round(mean_z / resolution_um),
                    "n": len(group)
                }
    else:
        mean_x, mean_y, mean_z = np.mean(feret_features, axis=0)
        key = f"class_{class_id}"
        class_stats[key] = {
            "mean_x_um": mean_x,
            "mean_y_um": mean_y,
            "mean_z_um": mean_z,
            "vox_x": round(mean_x / resolution_um),
            "vox_y": round(mean_y / resolution_um),
            "vox_z": round(mean_z / resolution_um),
            "n": len(feret_features)
        }

# === Résultat final ===
print("📊 Taille moyenne (Feret) des objets par classe (µm et voxels) :")
for cls, vals in class_stats.items():
    print(f"{cls}:")
    print(f"  ↪️  µm  : (x={vals['mean_x_um']:.2f}, y={vals['mean_y_um']:.2f}, z={vals['mean_z_um']:.2f})")
    print(f"  ↪️  vox : (x={vals['vox_x']}, y={vals['vox_y']}, z={vals['vox_z']})")
    print(f"  ↪️  objets utilisés : {vals['n']}")


import numpy as np
from skimage.measure import regionprops, label
from sklearn.cluster import KMeans

# === Paramètres d'entrée ===
resolution_nm = 446  # nm/px
resolution_um = resolution_nm / 1000  # µm/px
cube_size_vox = 333  # utilisé ailleurs si besoin

# Ces variables doivent exister à ce stade :
# final_class_map : tableau numpy 2D avec les classes (int: 0,1,2)
# zone_mask : masque binaire avec les polygones dessinés (uint8)
# intensity_image : image 2D (grayscale ou binaire 0/255) pour mesurer intensité

class_stats = {}

# Fonction utilitaire pour vérifier si image est binaire 0/255
def is_binary_image(img):
    unique_vals = np.unique(img)
    return set(unique_vals).issubset({0, 255})

binary_mode = is_binary_image(intensity_image)

# === Analyse Feret + Intensité par classe (et sous-classe pour 0 & 1) ===
for class_id in [0, 1, 2]:
    mask = ((final_class_map == class_id) & (zone_mask > 0)).astype(np.uint8)
    labeled = label(mask)
    props = regionprops(labeled, intensity_image=intensity_image)

    feret_features = []
    intensities = []
    white_percents = []
    black_percents = []

    for p in props:
        if p.area < 10:
            continue
        feret_max_um = p.feret_diameter_max * resolution_um
        feret_min_um = p.minor_axis_length * resolution_um if p.minor_axis_length else feret_max_um
        feret_z_um = (feret_max_um + feret_min_um) / 2
        feret_features.append([feret_max_um, feret_min_um, feret_z_um])

        # Moyenne intensité
        mean_intensity = p.mean_intensity if hasattr(p, 'mean_intensity') else 0
        intensities.append(mean_intensity)

        # Si binaire, calcul % blanc et noir dans l’objet
        if binary_mode:
            pixels = p.intensity_image.flatten()
            white_percent = 100 * np.sum(pixels == 255) / len(pixels)
            black_percent = 100 * np.sum(pixels == 0) / len(pixels)
            white_percents.append(white_percent)
            black_percents.append(black_percent)

    feret_features = np.array(feret_features)
    intensities = np.array(intensities)
    white_percents = np.array(white_percents) if binary_mode else None
    black_percents = np.array(black_percents) if binary_mode else None

    if len(feret_features) == 0:
        continue

    if class_id in [0, 1] and len(feret_features) >= 2:
        kmeans = KMeans(n_clusters=2, n_init="auto", random_state=0).fit(feret_features[:, :2])
        labels = kmeans.labels_
        for k in range(2):
            group = feret_features[labels == k]
            group_intensities = intensities[labels == k]
            if binary_mode:
                group_white = white_percents[labels == k]
                group_black = black_percents[labels == k]
            if len(group) > 0:
                mean_x, mean_y, mean_z = np.mean(group, axis=0)
                mean_intensity_group = np.mean(group_intensities)
                key = f"class_{class_id}_sub{k}"
                class_stats[key] = {
                    "mean_x_um": mean_x,
                    "mean_y_um": mean_y,
                    "mean_z_um": mean_z,
                    "vox_x": round(mean_x / resolution_um),
                    "vox_y": round(mean_y / resolution_um),
                    "vox_z": round(mean_z / resolution_um),
                    "mean_intensity": mean_intensity_group,
                    "n": len(group)
                }
                if binary_mode:
                    class_stats[key]["mean_white_percent"] = np.mean(group_white)
                    class_stats[key]["mean_black_percent"] = np.mean(group_black)
    else:
        mean_x, mean_y, mean_z = np.mean(feret_features, axis=0)
        mean_intensity_all = np.mean(intensities)
        key = f"class_{class_id}"
        class_stats[key] = {
            "mean_x_um": mean_x,
            "mean_y_um": mean_y,
            "mean_z_um": mean_z,
            "vox_x": round(mean_x / resolution_um),
            "vox_y": round(mean_y / resolution_um),
            "vox_z": round(mean_z / resolution_um),
            "mean_intensity": mean_intensity_all,
            "n": len(feret_features)
        }
        if binary_mode:
            class_stats[key]["mean_white_percent"] = np.mean(white_percents)
            class_stats[key]["mean_black_percent"] = np.mean(black_percents)

# === Résultat final ===
print("📊 Taille moyenne (Feret), intensité et % blanc/noir des objets par classe (µm, voxels, intensité) :")
for cls, vals in class_stats.items():
    print(f"{cls}:")
    print(f"  ↪️  µm  : (x={vals['mean_x_um']:.2f}, y={vals['mean_y_um']:.2f}, z={vals['mean_z_um']:.2f})")
    print(f"  ↪️  vox : (x={vals['vox_x']}, y={vals['vox_y']}, z={vals['vox_z']})")
    print(f"  ↪️  intensité moyenne : {vals['mean_intensity']:.2f}")
    if binary_mode:
        print(f"  ↪️  % blanc moyen : {vals['mean_white_percent']:.2f}%")
        print(f"  ↪️  % noir moyen  : {vals['mean_black_percent']:.2f}%")
    print(f"  ↪️  objets utilisés : {vals['n']}")
