import cv2
import numpy as np

# 1. Charger l‚Äôimage en niveaux de gris
img = cv2.imread('bille.png', cv2.IMREAD_GRAYSCALE)

# 2. Flouter l√©g√®rement
blur = cv2.GaussianBlur(img, (15, 15), 0)

# 3. Seuillage avec Otsu (bille claire = blanc, fond = noir)
_, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)


# 7. D√©tection des contours sur l‚Äôimage nettoy√©e
contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 8. Filtrer contours avec taille a >= 100
filtered = [cnt for cnt in contours if cnt.shape[0] >= 100]

# 9. S√©lection des 1 ou 2 plus gros
selected = sorted(filtered, key=cv2.contourArea, reverse=True)[:2]
output = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

for c in selected:
    # Cr√©er un masque vide pour le contour
    mask = np.zeros_like(img)
    cv2.drawContours(mask, [c], -1, 255, thickness=1)

    # Dilater le masque (√©largissement du contour)
    dilated = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (30, 30)))  # ‚âà10 px de rayon
    dilated = cv2.subtract(dilated, mask)  # Garde uniquement la bordure externe

    # Appliquer le contour √©largi en bleu
    output[dilated > 0] = (255, 0, 0)  # Bleu

# 12. Dessiner les contours d‚Äôorigine en rouge
for c in selected:
    cv2.drawContours(output, [c], -1, (0, 0, 255), 2)  # Rouge
cv2.imshow("Bille avec trous lat√©raux d√©tect√©e", output)
cv2.waitKey(0)
cv2.destroyAllWindows()


import os
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog

# === Param√®tres ===
image_path = "chemin/vers/image_complete.png"
patch_size = (512, 350)      # taille de base du patch
resized_size = (512, 400)    # taille du patch apr√®s redimensionnement
overlap = 50                 # recouvrement entre patchs

# === Initialiser le mod√®le Detectron2 ===
cfg = get_cfg()
cfg.merge_from_file("chemin/vers/config.yaml")
cfg.MODEL.WEIGHTS = "chemin/vers/model_final.pth"
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)
metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])

# === Charger l'image compl√®te ===
image = Image.open(image_path).convert("RGB")
width, height = image.size
full_image_np = np.array(image)
output_image = full_image_np.copy()  # copie pour superposer les pr√©dictions

# === G√©n√©rer les patchs et lancer l'inf√©rence ===
patch_id = 0
pw, ph = patch_size
rw, rh = resized_size

for y in range(0, height, ph - overlap):
    for x in range(0, width, pw - overlap):
        # D√©finir dynamiquement la taille du patch en fonction de patch_id
        if patch_id == 0:
            crop_w, crop_h = pw, ph
        elif patch_id == 1:
            crop_w, crop_h = pw + overlap, ph
        elif patch_id == 2:
            crop_w, crop_h = pw, ph + overlap
        else:
            crop_w, crop_h = pw + overlap, ph + overlap

        # Emp√™cher le d√©passement de l'image
        crop_w = min(crop_w, width - x)
        crop_h = min(crop_h, height - y)

        # Extraction et redimensionnement du patch
        patch = image.crop((x, y, x + crop_w, y + crop_h)).resize(resized_size)
        patch_np = np.array(patch)

        # Lancer l'inf√©rence sur le patch
        outputs = predictor(patch_np)

        # Visualisation des pr√©dictions sur le patch
        v = Visualizer(patch_np, metadata=metadata, scale=1.0, instance_mode=ColorMode.IMAGE)
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

        # Remettre √† l'√©chelle le patch pr√©dit vers la taille d'origine du patch (crop_w, crop_h)
        overlay = cv2.resize(out.get_image(), (crop_w, crop_h))

        # Fusionner les pr√©dictions avec l'image de sortie (blending)
        output_image[y:y + crop_h, x:x + crop_w] = cv2.addWeighted(
            output_image[y:y + crop_h, x:x + crop_w], 0.5, overlay, 0.5, 0
        )

        patch_id += 1

# === Afficher le r√©sultat avec Matplotlib ===
plt.figure(figsize=(10, 8))
plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))
plt.title("Image compl√®te avec pr√©dictions")
plt.axis('off')
plt.show()

# Pour enregistrer le r√©sultat, tu peux utiliser cv2.imwrite :
# cv2.imwrite("image_pred_complete.png", output_image)


import os
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog

# === Param√®tres ===
image_path = "chemin/vers/image_complete.png"  # √Ä modifier
config_path = "chemin/vers/config.yaml"         # √Ä modifier
weights_path = "chemin/vers/model_final.pth"    # √Ä modifier

patch_size = (512, 350)
resized_size = (512, 400)
overlap = 50

# === Initialisation du mod√®le Detectron2 ===
cfg = get_cfg()
cfg.merge_from_file(config_path)
cfg.MODEL.WEIGHTS = weights_path
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)
metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])

# === Charger l‚Äôimage ===
image = Image.open(image_path).convert("RGB")
width, height = image.size
full_image_np = np.array(image)
output_image = full_image_np.copy()

# Masque pour objets pris en compte
considered_objects_mask = np.zeros((height, width), dtype=np.uint8)
class_map = np.full((height, width), fill_value=255, dtype=np.uint8)  # 255 = fond

# === D√©coupage en patchs et inf√©rence ===
patch_id = 0
pw, ph = patch_size

for y in range(0, height, ph - overlap):
    for x in range(0, width, pw - overlap):
        crop_w = min(pw + (overlap if x + pw < width else 0), width - x)
        crop_h = min(ph + (overlap if y + ph < height else 0), height - y)

        patch = image.crop((x, y, x + crop_w, y + crop_h)).resize(resized_size)
        patch_np = np.array(patch)

        outputs = predictor(patch_np)
        instances = outputs["instances"].to("cpu")

        for i in range(len(instances)):
            class_id = int(instances.pred_classes[i])
            mask = instances.pred_masks[i].numpy().astype(np.uint8) * 255
            mask_resized = cv2.resize(mask, (crop_w, crop_h), interpolation=cv2.INTER_NEAREST)

            # Position de l‚Äôobjet dans l‚Äôimage compl√®te
            y1, y2 = y, y + crop_h
            x1, x2 = x, x + crop_w

            # Fusion sur class_map
            class_map[y1:y2, x1:x2][mask_resized > 127] = class_id

# === D√©tection des contours de la bille ===
img_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
blur = cv2.GaussianBlur(img_gray, (15, 15), 0)
_, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# Prendre les 2 plus gros contours
filtered = [cnt for cnt in contours if cnt.shape[0] >= 100]
selected = sorted(filtered, key=cv2.contourArea, reverse=True)[:2]

# Masque original + masque dilat√© (pour inclure objets touchants les bords)
bille_mask = np.zeros_like(img_gray, dtype=np.uint8)
bille_dilated_mask = np.zeros_like(img_gray, dtype=np.uint8)

for c in selected:
    temp_mask = np.zeros_like(img_gray, dtype=np.uint8)
    cv2.drawContours(temp_mask, [c], -1, 255, thickness=-1)
    bille_mask = cv2.bitwise_or(bille_mask, temp_mask)
    dilated = cv2.dilate(temp_mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (61, 61)))  # ‚âà 30 px
    bille_dilated_mask = cv2.bitwise_or(bille_dilated_mask, dilated)

# === S√©lectionner uniquement les objets touchant la bille (ou bord) ===
considered_objects_mask[:] = 0
final_class_map = np.full_like(class_map, fill_value=255)

for class_id in [0, 1, 2]:
    mask = (class_map == class_id).astype(np.uint8)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)

    for i in range(1, num_labels):  # 0 = fond
        component_mask = (labels == i).astype(np.uint8)
        overlap = np.logical_and(component_mask, bille_dilated_mask).any()

        if overlap:
            final_class_map[component_mask == 1] = class_id
            considered_objects_mask[component_mask == 1] = 255

# === Calcul du pourcentage d‚Äôoccupation par classe ===
total_pixels = np.sum(bille_dilated_mask > 0)
fractions = {}

for class_id in [0, 1, 2]:
    pixels = np.sum((final_class_map == class_id) & (considered_objects_mask > 0))
    fractions[class_id] = round(100 * pixels / total_pixels, 2) if total_pixels else 0

# === Affichage des r√©sultats ===
print("Fraction d‚Äôoccupation (objets touchant ou dans bille √©largie) :")
for cid, perc in fractions.items():
    print(f"  Classe {cid} : {perc} %")

# === Affichages visuels ===
# 1. Image avec contours de billes
image_with_contours = output_image.copy()
for c in selected:
    cv2.drawContours(image_with_contours, [c], -1, (0, 255, 255), 2)

# 2. Masque des bordures dilat√©es
plt.figure(figsize=(10, 6))
plt.imshow(bille_dilated_mask, cmap='gray')
plt.title("Masque dilat√© des billes (zone d'inclusion)")
plt.axis("off")
plt.show()

# 3. Image des objets pris en compte
objects_image = full_image_np.copy()
objects_image[considered_objects_mask == 0] = 0  # Masquer le fond
for c in selected:
    cv2.drawContours(objects_image, [c], -1, (255, 255, 0), 2)

plt.figure(figsize=(10, 6))
plt.imshow(cv2.cvtColor(objects_image, cv2.COLOR_BGR2RGB))
plt.title("Objets pris en compte avec bordure de la bille")
plt.axis("off")
plt.show()

# 4. Image avec toutes les pr√©dictions et contours
plt.figure(figsize=(12, 8))
plt.imshow(cv2.cvtColor(image_with_contours, cv2.COLOR_BGR2RGB))
plt.title("Image compl√®te avec pr√©dictions + contours de bille")
plt.axis("off")
plt.show()


# === Interface pour dessiner les polygones √† la main ===
drawing = False
polygon_points = []
all_polygons = []

def draw_polygon(event, x, y, flags, param):
    global drawing, polygon_points, all_polygons

    if event == cv2.EVENT_LBUTTONDOWN:
        polygon_points.append((x, y))

    elif event == cv2.EVENT_RBUTTONDOWN:
        if len(polygon_points) >= 3:
            all_polygons.append(polygon_points[:])
            polygon_points = []

# Affichage de l'image et dessin
temp_image = output_image.copy()
cv2.namedWindow("Dessine les polygones (clic gauche: points, clic droit: fermer)")
cv2.setMouseCallback("Dessine les polygones (clic gauche: points, clic droit: fermer)", draw_polygon)

while True:
    img_copy = temp_image.copy()
    for poly in all_polygons:
        cv2.polylines(img_copy, [np.array(poly, dtype=np.int32)], isClosed=True, color=(0, 255, 0), thickness=2)
    if polygon_points:
        cv2.polylines(img_copy, [np.array(polygon_points, dtype=np.int32)], isClosed=False, color=(255, 0, 0), thickness=1)

    cv2.imshow("Dessine les polygones (clic gauche: points, clic droit: fermer)", img_copy)
    key = cv2.waitKey(10)
    if key == 13:  # ENTER pour terminer
        break

cv2.destroyAllWindows()

# === Cr√©ation du masque √† partir des polygones dessin√©s ===
zone_mask = np.zeros((height, width), dtype=np.uint8)
for poly in all_polygons:
    cv2.fillPoly(zone_mask, [np.array(poly, dtype=np.int32)], 255)


# === Calcul du pourcentage d‚Äôoccupation par classe dans les polygones dessin√©s ===
total_pixels = np.sum(zone_mask > 0)
fractions = {}

for class_id in [0, 1, 2]:
    pixels = np.sum((final_class_map == class_id) & (zone_mask > 0))
    fractions[class_id] = round(100 * pixels / total_pixels, 2) if total_pixels else 0

# === Affichage des r√©sultats ===
print("Fraction d‚Äôoccupation (√† l‚Äôint√©rieur des polygones dessin√©s) :")
for cid, perc in fractions.items():
    print(f"  Classe {cid} : {perc} %")


import tkinter as tk
from PIL import ImageTk

polygon_points = []
all_polygons = []
zone_mask = np.zeros((height, width), dtype=np.uint8)

def on_click(event):
    x, y = event.x, event.y
    polygon_points.append((x, y))
    r = 2
    canvas.create_oval(x - r, y - r, x + r, y + r, fill='red')

def close_polygon():
    global polygon_points
    if len(polygon_points) >= 3:
        all_polygons.append(polygon_points[:])
        canvas.create_polygon(polygon_points, outline='green', fill='', width=2)
        polygon_points = []

def finish():
    root.destroy()

# === Cr√©er interface Tkinter ===
root = tk.Tk()
root.title("Dessine les polygones (clic: points, bouton: fermer)")

# Convertir image pour Tkinter
image_tk = ImageTk.PhotoImage(Image.fromarray(output_image))

canvas = tk.Canvas(root, width=width, height=height)
canvas.pack()
canvas.create_image(0, 0, anchor=tk.NW, image=image_tk)
canvas.bind("<Button-1>", on_click)

# Boutons
btn_frame = tk.Frame(root)
btn_frame.pack()
tk.Button(btn_frame, text="Fermer polygone", command=close_polygon).pack(side=tk.LEFT, padx=10)
tk.Button(btn_frame, text="Terminer", command=finish).pack(side=tk.RIGHT, padx=10)

root.mainloop()

# === Cr√©ation du masque √† partir des polygones dessin√©s ===
zone_mask = np.zeros((height, width), dtype=np.uint8)
for poly in all_polygons:
    cv2.fillPoly(zone_mask, [np.array(poly, dtype=np.int32)], 255)


# === Calcul du volume estim√© par classe (en supposant sph√®res) ===
import math

volume_par_classe = {}
diametre_moyen = {}
nb_objets = {}

for class_id in [0, 1, 2]:
    mask = (class_map == class_id).astype(np.uint8)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)

    diam_list = []
    volumes = []

    for i in range(1, num_labels):  # i=0 = fond
        area = stats[i, cv2.CC_STAT_AREA]
        if area < 5:
            continue
        # Diam√®tre √©quivalent circulaire
        ecd = 2 * np.sqrt(area / np.pi)
        diam_list.append(ecd)

        # Volume d'une sph√®re : V = 4/3 * pi * (r^3)
        radius = ecd / 2
        volume = (4 / 3) * np.pi * (radius ** 3)
        volumes.append(volume)

    if diam_list:
        diametre_moyen[class_id] = np.mean(diam_list)
        volume_par_classe[class_id] = np.sum(volumes)
        nb_objets[class_id] = len(volumes)
    else:
        diametre_moyen[class_id] = 0
        volume_par_classe[class_id] = 0
        nb_objets[class_id] = 0

# === Affichage des r√©sultats volum√©triques ===
print("\nVolume estim√© par classe (sph√®res √©quivalentes) :")
for cid in [0, 1, 2]:
    print(f"  Classe {cid} :")
    print(f"    - Nombre de particules : {nb_objets[cid]}")
    print(f"    - Diam√®tre moyen ‚âà {diametre_moyen[cid]:.2f} px")
    print(f"    - Volume total estim√© ‚âà {volume_par_classe[cid]:.2f} px¬≥")

# === Calcul du Vcube et L ===
# Convertir les fractions (%) en d√©cimales
fractions_decimales = {cid: fractions[cid] / 100 for cid in [0, 1, 2]}

# √âviter division par z√©ro
Vcube = 0
for cid in [0, 1, 2]:
    f = fractions_decimales[cid]
    v = volume_par_classe[cid]
    if f > 0:
        Vcube += v / f

# Calcul de L = racine cubique du volume
if Vcube > 0:
    L = Vcube ** (1 / 3)
    print(f"\nVolume du cube estim√© : Vcube ‚âà {Vcube:.2f} px¬≥")
    print(f"Longueur caract√©ristique (L) ‚âà {L:.2f} px")
else:
    print("\nImpossible de calculer Vcube (aucune fraction d√©tect√©e).")


Exemple num√©rique
Imaginons 3 phases (hors matrice):

Phase	Volume estim√© 
ùëâ
ùëñ
V 
i
‚Äã
 	Fraction 
ùëì
ùëñ
f 
i
‚Äã
 
Dense	5000	0.15
Creux	3000	0.20
Interm√©diaire	1000	0.05

Calcul du volume du cube :

ùëâ
cube
=
5000
0.15
+
3000
0.20
+
1000
0.05
=
33333.3
+
15000
+
20000
=
68333.3
V 
cube
‚Äã
 = 
0.15
5000
‚Äã
 + 
0.20
3000
‚Äã
 + 
0.05
1000
‚Äã
 =33333.3+15000+20000=68333.3
Calcul de 
ùêø
L :

ùêø
=
68333.3
3
‚âà
40.8
L= 
3
  
68333.3
‚Äã
 ‚âà40.8


 import numpy as np
from skimage.measure import regionprops, label
from sklearn.cluster import KMeans

# === Param√®tres d'entr√©e ===
resolution_nm = 446  # nm/px
resolution_um = resolution_nm / 1000  # ¬µm/px
cube_size_vox = 333

# Ces variables doivent exister √† ce stade :
# final_class_map : tableau numpy 2D avec les classes (int: 0,1,2)
# zone_mask : masque binaire avec les polygones dessin√©s (uint8)

class_stats = {}

# === Analyse par classe (et KMeans sur 0 et 1) ===
for class_id in [0, 1, 2]:
    mask = ((final_class_map == class_id) & (zone_mask > 0)).astype(np.uint8)
    labeled = label(mask)
    props = regionprops(labeled)

    sizes_um = []
    for p in props:
        minr, minc, maxr, maxc = p.bbox
        w_um = (maxc - minc) * resolution_um
        h_um = (maxr - minr) * resolution_um
        sizes_um.append([w_um, h_um])

    sizes_um = np.array(sizes_um)
    if len(sizes_um) == 0:
        continue

    if class_id in [0, 1] and len(sizes_um) >= 2:
        kmeans = KMeans(n_clusters=2, random_state=0).fit(sizes_um)
        labels = kmeans.labels_
        for k in range(2):
            group = sizes_um[labels == k]
            if len(group) > 0:
                mean_x, mean_y = np.mean(group, axis=0)
                mean_z = (mean_x + mean_y) / 2  # Z estim√© comme moyenne
                key = f"class_{class_id}_sub{k}"
                class_stats[key] = {
                    "mean_x_um": mean_x,
                    "mean_y_um": mean_y,
                    "mean_z_um": mean_z,
                    "vox_x": round(mean_x / resolution_um),
                    "vox_y": round(mean_y / resolution_um),
                    "vox_z": round(mean_z / resolution_um)
                }
    else:
        mean_x, mean_y = np.mean(sizes_um, axis=0)
        mean_z = (mean_x + mean_y) / 2
        key = f"class_{class_id}"
        class_stats[key] = {
            "mean_x_um": mean_x,
            "mean_y_um": mean_y,
            "mean_z_um": mean_z,
            "vox_x": round(mean_x / resolution_um),
            "vox_y": round(mean_y / resolution_um),
            "vox_z": round(mean_z / resolution_um)
        }

# === R√©sultat final ===
print("Taille moyenne des objets par classe (en ¬µm et voxels) :")
for cls, vals in class_stats.items():
    print(f"{cls}:")
    print(f"  ‚Ü™Ô∏è  ¬µm  : (x={vals['mean_x_um']:.2f}, y={vals['mean_y_um']:.2f}, z={vals['mean_z_um']:.2f})")
    print(f"  ‚Ü™Ô∏è  vox : (x={vals['vox_x']}, y={vals['vox_y']}, z={vals['vox_z']})")


import numpy as np
from skimage.measure import regionprops, label
from sklearn.cluster import KMeans

# === Param√®tres d'entr√©e ===
resolution_nm = 446  # nm/px
resolution_um = resolution_nm / 1000  # ¬µm/px
cube_size_vox = 333  # utilis√© ailleurs si besoin

# Ces variables doivent exister √† ce stade :
# final_class_map : tableau numpy 2D avec les classes (int: 0,1,2)
# zone_mask : masque binaire avec les polygones dessin√©s (uint8)

class_stats = {}

# === Analyse Feret par classe (et sous-classe pour 0 & 1) ===
for class_id in [0, 1, 2]:
    mask = ((final_class_map == class_id) & (zone_mask > 0)).astype(np.uint8)
    labeled = label(mask)
    props = regionprops(labeled)

    feret_features = []
    for p in props:
        if p.area < 10:
            continue
        feret_max_um = p.feret_diameter_max * resolution_um
        feret_min_um = p.minor_axis_length * resolution_um if p.minor_axis_length else feret_max_um
        feret_z_um = (feret_max_um + feret_min_um) / 2
        feret_features.append([feret_max_um, feret_min_um, feret_z_um])

    feret_features = np.array(feret_features)
    if len(feret_features) == 0:
        continue

    if class_id in [0, 1] and len(feret_features) >= 2:
        kmeans = KMeans(n_clusters=2, n_init="auto", random_state=0).fit(feret_features[:, :2])
        labels = kmeans.labels_
        for k in range(2):
            group = feret_features[labels == k]
            if len(group) > 0:
                mean_x, mean_y, mean_z = np.mean(group, axis=0)
                key = f"class_{class_id}_sub{k}"
                class_stats[key] = {
                    "mean_x_um": mean_x,
                    "mean_y_um": mean_y,
                    "mean_z_um": mean_z,
                    "vox_x": round(mean_x / resolution_um),
                    "vox_y": round(mean_y / resolution_um),
                    "vox_z": round(mean_z / resolution_um),
                    "n": len(group)
                }
    else:
        mean_x, mean_y, mean_z = np.mean(feret_features, axis=0)
        key = f"class_{class_id}"
        class_stats[key] = {
            "mean_x_um": mean_x,
            "mean_y_um": mean_y,
            "mean_z_um": mean_z,
            "vox_x": round(mean_x / resolution_um),
            "vox_y": round(mean_y / resolution_um),
            "vox_z": round(mean_z / resolution_um),
            "n": len(feret_features)
        }

# === R√©sultat final ===
print("üìä Taille moyenne (Feret) des objets par classe (¬µm et voxels) :")
for cls, vals in class_stats.items():
    print(f"{cls}:")
    print(f"  ‚Ü™Ô∏è  ¬µm  : (x={vals['mean_x_um']:.2f}, y={vals['mean_y_um']:.2f}, z={vals['mean_z_um']:.2f})")
    print(f"  ‚Ü™Ô∏è  vox : (x={vals['vox_x']}, y={vals['vox_y']}, z={vals['vox_z']})")
    print(f"  ‚Ü™Ô∏è  objets utilis√©s : {vals['n']}")


import numpy as np
from skimage.measure import regionprops, label
from sklearn.cluster import KMeans

# === Param√®tres d'entr√©e ===
resolution_nm = 446  # nm/px
resolution_um = resolution_nm / 1000  # ¬µm/px
cube_size_vox = 333  # utilis√© ailleurs si besoin

# Ces variables doivent exister √† ce stade :
# final_class_map : tableau numpy 2D avec les classes (int: 0,1,2)
# zone_mask : masque binaire avec les polygones dessin√©s (uint8)
# intensity_image : image 2D (grayscale ou binaire 0/255) pour mesurer intensit√©

class_stats = {}

# Fonction utilitaire pour v√©rifier si image est binaire 0/255
def is_binary_image(img):
    unique_vals = np.unique(img)
    return set(unique_vals).issubset({0, 255})

binary_mode = is_binary_image(intensity_image)

# === Analyse Feret + Intensit√© par classe (et sous-classe pour 0 & 1) ===
for class_id in [0, 1, 2]:
    mask = ((final_class_map == class_id) & (zone_mask > 0)).astype(np.uint8)
    labeled = label(mask)
    props = regionprops(labeled, intensity_image=intensity_image)

    feret_features = []
    intensities = []
    white_percents = []
    black_percents = []

    for p in props:
        if p.area < 10:
            continue
        feret_max_um = p.feret_diameter_max * resolution_um
        feret_min_um = p.minor_axis_length * resolution_um if p.minor_axis_length else feret_max_um
        feret_z_um = (feret_max_um + feret_min_um) / 2
        feret_features.append([feret_max_um, feret_min_um, feret_z_um])

        # Moyenne intensit√©
        mean_intensity = p.mean_intensity if hasattr(p, 'mean_intensity') else 0
        intensities.append(mean_intensity)

        # Si binaire, calcul % blanc et noir dans l‚Äôobjet
        if binary_mode:
            pixels = p.intensity_image.flatten()
            white_percent = 100 * np.sum(pixels == 255) / len(pixels)
            black_percent = 100 * np.sum(pixels == 0) / len(pixels)
            white_percents.append(white_percent)
            black_percents.append(black_percent)

    feret_features = np.array(feret_features)
    intensities = np.array(intensities)
    white_percents = np.array(white_percents) if binary_mode else None
    black_percents = np.array(black_percents) if binary_mode else None

    if len(feret_features) == 0:
        continue

    if class_id in [0, 1] and len(feret_features) >= 2:
        kmeans = KMeans(n_clusters=2, n_init="auto", random_state=0).fit(feret_features[:, :2])
        labels = kmeans.labels_
        for k in range(2):
            group = feret_features[labels == k]
            group_intensities = intensities[labels == k]
            if binary_mode:
                group_white = white_percents[labels == k]
                group_black = black_percents[labels == k]
            if len(group) > 0:
                mean_x, mean_y, mean_z = np.mean(group, axis=0)
                mean_intensity_group = np.mean(group_intensities)
                key = f"class_{class_id}_sub{k}"
                class_stats[key] = {
                    "mean_x_um": mean_x,
                    "mean_y_um": mean_y,
                    "mean_z_um": mean_z,
                    "vox_x": round(mean_x / resolution_um),
                    "vox_y": round(mean_y / resolution_um),
                    "vox_z": round(mean_z / resolution_um),
                    "mean_intensity": mean_intensity_group,
                    "n": len(group)
                }
                if binary_mode:
                    class_stats[key]["mean_white_percent"] = np.mean(group_white)
                    class_stats[key]["mean_black_percent"] = np.mean(group_black)
    else:
        mean_x, mean_y, mean_z = np.mean(feret_features, axis=0)
        mean_intensity_all = np.mean(intensities)
        key = f"class_{class_id}"
        class_stats[key] = {
            "mean_x_um": mean_x,
            "mean_y_um": mean_y,
            "mean_z_um": mean_z,
            "vox_x": round(mean_x / resolution_um),
            "vox_y": round(mean_y / resolution_um),
            "vox_z": round(mean_z / resolution_um),
            "mean_intensity": mean_intensity_all,
            "n": len(feret_features)
        }
        if binary_mode:
            class_stats[key]["mean_white_percent"] = np.mean(white_percents)
            class_stats[key]["mean_black_percent"] = np.mean(black_percents)

# === R√©sultat final ===
print("üìä Taille moyenne (Feret), intensit√© et % blanc/noir des objets par classe (¬µm, voxels, intensit√©) :")
for cls, vals in class_stats.items():
    print(f"{cls}:")
    print(f"  ‚Ü™Ô∏è  ¬µm  : (x={vals['mean_x_um']:.2f}, y={vals['mean_y_um']:.2f}, z={vals['mean_z_um']:.2f})")
    print(f"  ‚Ü™Ô∏è  vox : (x={vals['vox_x']}, y={vals['vox_y']}, z={vals['vox_z']})")
    print(f"  ‚Ü™Ô∏è  intensit√© moyenne : {vals['mean_intensity']:.2f}")
    if binary_mode:
        print(f"  ‚Ü™Ô∏è  % blanc moyen : {vals['mean_white_percent']:.2f}%")
        print(f"  ‚Ü™Ô∏è  % noir moyen  : {vals['mean_black_percent']:.2f}%")
    print(f"  ‚Ü™Ô∏è  objets utilis√©s : {vals['n']}")
