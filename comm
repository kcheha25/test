Voici une version d√©taill√©e et bien comment√©e de votre code TensorFlow. J'ai ajout√© des explications ligne par ligne pour chaque classe personnalis√©e :

---

### üìå `CustomLoss` ‚Äî Fonction de perte personnalis√©e avec pond√©ration de classe

```python
class CustomLoss(tf.keras.losses.Loss):
    def __init__(self, n_splits, weight_prob=1.0, weight_hinge=1.0, weight_class_1=5.0, weight_class_0=1.0, **kwargs):
        super().__init__(**kwargs)
        self.n_splits = n_splits  # (Non utilis√© ici, mais probablement utile dans un autre contexte, ex: k-fold)
        self.weight_prob = weight_prob  # Poids de la perte de probabilit√© (BCE ou Focal)
        self.weight_class_1 = weight_class_1  # Poids appliqu√© aux √©chantillons de classe 1
        self.weight_class_0 = weight_class_0  # Poids appliqu√© aux √©chantillons de classe 0

    def call(self, y_true, y_pred):
        # Conversion des √©tiquettes et des pr√©dictions en float32
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.cast(y_pred, tf.float32)

        # Calcul de la perte de type Binary Focal Crossentropy avec √©quilibrage des classes
        prob_loss = tf.keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True, alpha=0.8)(y_true, y_pred)

        # Cr√©ation d'un vecteur de poids bas√© sur les classes : classe 1 => poids fort, classe 0 => poids faible
        weights = tf.where(y_true == 1, self.weight_class_1, self.weight_class_0)

        # Application du poids global √† la loss
        total_loss = self.weight_prob * prob_loss

        # Application des poids de classes au total de la perte
        weighted_loss = total_loss * weights

        return weighted_loss
```

---

### üìå `CustomAUC` ‚Äî AUC personnalis√©e avec pond√©ration de la classe 1

```python
class CustomAUC(tf.keras.metrics.AUC):
    def __init__(self, beta=5.0, name="weighted_auc", **kwargs):
        super().__init__(name=name, **kwargs)
        self.beta = beta  # Poids appliqu√© aux √©chantillons de classe 1

    def update_state(self, y_true, y_pred, sample_weight=None):
        # Cr√©ation d'un vecteur de poids : beta pour les positifs, 1.0 pour les n√©gatifs
        weights = tf.where(y_true == 1, self.beta, 1.0)

        # Mise √† jour de la m√©trique AUC avec ces poids
        super().update_state(y_true, y_pred, sample_weight=weights)
```

---

### üìå `CustomAccuracy` ‚Äî Pr√©cision binaire pond√©r√©e

```python
class CustomAccuracy(tf.keras.metrics.BinaryAccuracy):
    def __init__(self, beta=2.0, name="weighted_binary_accuracy", **kwargs):
        super().__init__(name=name, **kwargs)
        self.beta = beta  # Poids pour les exemples de classe 1

    def update_state(self, y_true, y_pred, sample_weight=None):
        # Attribuer un poids beta √† la classe 1 et 1.0 √† la classe 0
        weights = tf.where(y_true == 1, self.beta, 1.0)

        # Mise √† jour de la pr√©cision en tenant compte de la pond√©ration
        super().update_state(y_true, y_pred, sample_weight=weights)
```

---

### üìå `CustomF1Score` ‚Äî F1-score pond√©r√© (approximation personnalis√©e)

```python
class CustomF1Score(tf.keras.metrics.Metric):
    def __init__(self, beta=2.0, name="weighted_f1_score", **kwargs):
        super().__init__(name=name, **kwargs)
        self.beta = beta  # Poids de la classe 1
        self.correct = self.add_weight(name="correct", initializer="zeros")  # Nombre de pr√©dictions correctes pond√©r√©es
        self.total = self.add_weight(name="total", initializer="zeros")  # Total pond√©r√©

    def update_state(self, y_true, y_pred, sample_weight=None):
        # Binarisation des pr√©dictions avec un seuil de 0.7 (plus strict que 0.5)
        y_pred = tf.cast(y_pred > 0.7, tf.float32)

        # Pond√©ration des classes : beta pour classe 1, sinon 1
        weights = tf.where(y_true == 1, self.beta, 1.0)

        # Comptage des pr√©dictions correctes pond√©r√©es
        correct_preds = tf.cast(tf.equal(y_true, y_pred), tf.float32) * weights
        self.correct.assign_add(tf.reduce_sum(correct_preds))
        self.total.assign_add(tf.reduce_sum(weights))

    def result(self):
        # Calcul d'une forme simplifi√©e du F1-score pond√©r√©
        precision = self.correct / (self.total + tf.keras.backend.epsilon())
        recall = self.correct / (tf.reduce_sum(self.total) + tf.keras.backend.epsilon())

        # Formule du F1-score : 2 * (P * R) / (P + R)
        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())
```

---

### ‚úÖ Remarques g√©n√©rales :

* Les m√©triques sont adapt√©es pour les probl√®mes d√©s√©quilibr√©s, o√π la classe positive (1) est sous-repr√©sent√©e.
* La classe `CustomF1Score` utilise une approximation du F1 score qui pourrait √™tre am√©lior√©e avec un calcul plus explicite de TP, FP, FN.
* L‚Äôattribut `n_splits` dans `CustomLoss` semble inutilis√© ici ‚Äî √† retirer ou documenter.

Souhaitez-vous une version plus rigoureuse du F1-score (avec vrais TP/FP/FN) ?
