import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# ðŸ”¹ Fonction pour calculer la diagonale d'une bbox et la convertir en nm
def compute_bbox_diagonal(bbox, resolution=0.0657):
    x, y, w, h, *_ = bbox
    diagonal_pixels = np.sqrt(w**2 + h**2)
    diagonal_nm = diagonal_pixels * resolution
    return diagonal_nm

# ðŸ”¹ Fonction pour gÃ©nÃ©rer les donnÃ©es Excel pour une image donnÃ©e
def process_image_bboxes(image_name, bboxes, output_dir):
    lengths_nm = [compute_bbox_diagonal(bbox) for bbox in bboxes]
    feuille_counts = [1 for _ in bboxes]  # Si chaque BBox reprÃ©sente un feuillet

    total_feuillets = len(bboxes)
    total_length = sum(lengths_nm)
    nb_empilements = count_empilements(bboxes)  # Ã€ dÃ©finir selon ta logique

    # ðŸ”¹ CrÃ©ation du DataFrame pour Excel
    data = {
        "Index BBox": list(range(len(bboxes))),
        "Nombre de feuillets": feuille_counts,
        "Longueur moyenne (nm)": lengths_nm,
    }

    df = pd.DataFrame(data)
    summary = pd.DataFrame({
        "Total feuillets": [total_feuillets],
        "Total longueur (nm)": [total_length],
        "Nombre empilements": [nb_empilements]
    })

    # ðŸ”¹ Enregistrement dans un fichier Excel
    output_path = os.path.join(output_dir, f"{os.path.splitext(image_name)[0]}.xlsx")
    with pd.ExcelWriter(output_path) as writer:
        summary.to_excel(writer, sheet_name="RÃ©sumÃ©", index=False)
        df.to_excel(writer, sheet_name="DÃ©tails par BBox", index=False)

# ðŸ”¹ Exemple de fonction pour compter les empilements (logique Ã  adapter)
def count_empilements(bboxes):
    # Exemple : considÃ¨re comme un empilement si des BBoxes se superposent
    count = 0
    for i, bbox1 in enumerate(bboxes):
        x1, y1, w1, h1 = bbox1[:4]
        for j, bbox2 in enumerate(bboxes):
            if i >= j:
                continue
            x2, y2, w2, h2 = bbox2[:4]
            if (
                x1 < x2 + w2 and x1 + w1 > x2 and
                y1 < y2 + h2 and y1 + h1 > y2
            ):
                count += 1
                break
    return count

# ðŸ”¹ Parcours du dossier dâ€™images et traitement
def process_folder(folder_path, bbox_data_per_image, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    for image_file in os.listdir(folder_path):
        if image_file.lower().endswith((".png", ".jpg", ".jpeg", ".tiff")):
            image_path = os.path.join(folder_path, image_file)
            # Ici on rÃ©cupÃ¨re les BBoxes associÃ©es Ã  l'image
            bboxes = bbox_data_per_image.get(image_file, [])
            process_image_bboxes(image_file, bboxes, output_dir)

# ðŸ”¹ Exemple de structure pour bbox_data_per_image (Ã  adapter selon ta source)
# Chaque BBox est une liste : [x, y, w, h]
bbox_data_per_image = {
    "image1.jpg": [[10, 20, 30, 40], [50, 60, 20, 30]],
    "image2.jpg": [[15, 25, 35, 45], [100, 150, 50, 70]],
    # etc.
}

# ðŸ”¹ Utilisation
input_folder = "chemin/vers/dossier_images"
output_folder = "chemin/vers/sortie_excel"
process_folder(input_folder, bbox_data_per_image, output_folder)




import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.measure import regionprops, label
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo

# === Conversion pixels â†’ nanomÃ¨tres ===
PIXEL_TO_NM = 7.774  # nm / pixel

# === Configuration du modÃ¨le Detectron2 ===
def setup_predictor(weights_path):
    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file(
        "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"
    ))
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
    cfg.MODEL.WEIGHTS = weights_path
    cfg.MODEL.DEVICE = "cuda"  # ou "cpu"
    return DefaultPredictor(cfg)

# === Fonction pour l'analyse morphologique ===
def analyze_masks(masks):
    diameters_nm = []
    perimeters_nm = []
    feret_ratios = []

    for i in range(masks.shape[0]):
        mask = masks[i].cpu().numpy().astype(np.uint8)
        labeled = label(mask)
        props = regionprops(labeled)

        for prop in props:
            perimeter_px = prop.perimeter
            equiv_diameter_px = prop.equivalent_diameter
            feret_diam_max_px = prop.major_axis_length
            feret_diam_min_px = prop.minor_axis_length

            # Convertir en nm
            diameter_nm = equiv_diameter_px * PIXEL_TO_NM
            perimeter_nm = perimeter_px * PIXEL_TO_NM
            feret_ratio = feret_diam_min_px / feret_diam_max_px if feret_diam_max_px > 0 else 0

            diameters_nm.append(diameter_nm)
            perimeters_nm.append(perimeter_nm)
            feret_ratios.append(feret_ratio)

    return diameters_nm, perimeters_nm, feret_ratios

# === Fonction pour afficher les histogrammes ===
def plot_histogram(data, title, xlabel):
    plt.figure()
    plt.hist(data, bins=20, edgecolor='black', alpha=0.7)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel("Nombre d'objets")
    plt.grid(True)
    plt.show()

# === Main ===
def main(image_path, weights_path):
    predictor = setup_predictor(weights_path)

    image = cv2.imread(image_path)
    outputs = predictor(image)

    if "instances" not in outputs or len(outputs["instances"]) == 0:
        print("Aucun objet dÃ©tectÃ©.")
        return

    masks = outputs["instances"].pred_masks
    diameters_nm, perimeters_nm, feret_ratios = analyze_masks(masks)

    # Affichage des histogrammes en nm
    plot_histogram(diameters_nm, "Histogramme des diamÃ¨tres Ã©quivalents", "DiamÃ¨tre moyen (nm)")
    plot_histogram(perimeters_nm, "Histogramme des pÃ©rimÃ¨tres", "PÃ©rimÃ¨tre (nm)")
    plot_histogram(feret_ratios, "Histogramme des rapports Feret min / max", "Rapport (min / max)")

# === Exemple d'utilisation ===
if __name__ == "__main__":
    image_path = "chemin/vers/image.jpg"
    weights_path = "chemin/vers/model_final.pth"  # ModÃ¨le entraÃ®nÃ© Detectron2
    main(image_path, weights_path)


import pandas as pd
import numpy as np
from collections import defaultdict
import itertools

# === Ã‰tape 1 : Lecture Excel et dÃ©tection des paires ayant le mÃªme temps ===
excel_path = "composants_ref.xlsx"
df_excel = pd.read_excel(excel_path)

# Nettoyer les noms (sans suffixes)
df_excel['Composant'] = df_excel['Composant'].astype(str).str.strip().str.upper()

# Trouver les paires ayant exactement le mÃªme temps
time_groups = df_excel.groupby('Temps de rÃ©tention')['Composant'].apply(list)
duplicate_time_pairs = []

for comps in time_groups:
    if len(comps) > 1:
        duplicate_time_pairs.extend(list(itertools.combinations(comps, 2)))

# === Ã‰tape 2 : Lecture JSON et extraction des composants par chromatogramme ===
json_path = "chromatogrammes.json"
df_json = pd.read_json(json_path).dropna(subset=['pics'])

# Pour stocker les composants et leurs temps par chromatogramme
all_chromatograms = []

for _, row in df_json.iterrows():
    current_components = []
    sorted_pics = sorted(row['pics'].items(), key=lambda x: float(x[0]))

    for time_str, data in sorted_pics:
        time = float(time_str)
        if time <= 150:
            comp_name = str(data[0]).strip().upper()
            current_components.append((comp_name, time))

    all_chromatograms.append(current_components)

# === Ã‰tape 3 : Analyse de lâ€™ordre dâ€™apparition des paires ===
pair_results = defaultdict(lambda: {"a_precedes_b": 0, "b_precedes_a": 0, "times": []})

for comp_a, comp_b in duplicate_time_pairs:
    for chrom in all_chromatograms:
        names_in_chrom = [c[0] for c in chrom]
        if comp_a in names_in_chrom and comp_b in names_in_chrom:
            idx_a = names_in_chrom.index(comp_a)
            idx_b = names_in_chrom.index(comp_b)
            time_a = chrom[idx_a][1]
            time_b = chrom[idx_b][1]

            if idx_a < idx_b:
                pair_results[(comp_a, comp_b)]["a_precedes_b"] += 1
            else:
                pair_results[(comp_a, comp_b)]["b_precedes_a"] += 1

            pair_results[(comp_a, comp_b)]["times"].append((time_a, time_b))

# === Ã‰tape 4 : Affichage des rÃ©sultats ===
for (comp_a, comp_b), info in pair_results.items():
    print(f"ðŸ§ª Paire : {comp_a} / {comp_b}")
    print(f"   âž¤ {comp_a} prÃ©cÃ¨de {comp_b} : {info['a_precedes_b']} fois")
    print(f"   âž¤ {comp_b} prÃ©cÃ¨de {comp_a} : {info['b_precedes_a']} fois")
    print(f"   âž¤ Temps observÃ©s :")
    for t_a, t_b in info["times"]:
        print(f"     - {comp_a} : {t_a:.2f} | {comp_b} : {t_b:.2f}")
    print("-" * 50)
