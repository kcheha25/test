import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# üîπ Fonction pour calculer la diagonale d'une bbox et la convertir en nm
def compute_bbox_diagonal(bbox, resolution=0.0657):
    x, y, w, h, *_ = bbox
    diagonal_pixels = np.sqrt(w**2 + h**2)
    diagonal_nm = diagonal_pixels * resolution
    return diagonal_nm

# üîπ Fonction pour g√©n√©rer les donn√©es Excel pour une image donn√©e
def process_image_bboxes(image_name, bboxes, output_dir):
    lengths_nm = [compute_bbox_diagonal(bbox) for bbox in bboxes]
    feuille_counts = [1 for _ in bboxes]  # Si chaque BBox repr√©sente un feuillet

    total_feuillets = len(bboxes)
    total_length = sum(lengths_nm)
    nb_empilements = count_empilements(bboxes)  # √Ä d√©finir selon ta logique

    # üîπ Cr√©ation du DataFrame pour Excel
    data = {
        "Index BBox": list(range(len(bboxes))),
        "Nombre de feuillets": feuille_counts,
        "Longueur moyenne (nm)": lengths_nm,
    }

    df = pd.DataFrame(data)
    summary = pd.DataFrame({
        "Total feuillets": [total_feuillets],
        "Total longueur (nm)": [total_length],
        "Nombre empilements": [nb_empilements]
    })

    # üîπ Enregistrement dans un fichier Excel
    output_path = os.path.join(output_dir, f"{os.path.splitext(image_name)[0]}.xlsx")
    with pd.ExcelWriter(output_path) as writer:
        summary.to_excel(writer, sheet_name="R√©sum√©", index=False)
        df.to_excel(writer, sheet_name="D√©tails par BBox", index=False)

# üîπ Exemple de fonction pour compter les empilements (logique √† adapter)
def count_empilements(bboxes):
    # Exemple : consid√®re comme un empilement si des BBoxes se superposent
    count = 0
    for i, bbox1 in enumerate(bboxes):
        x1, y1, w1, h1 = bbox1[:4]
        for j, bbox2 in enumerate(bboxes):
            if i >= j:
                continue
            x2, y2, w2, h2 = bbox2[:4]
            if (
                x1 < x2 + w2 and x1 + w1 > x2 and
                y1 < y2 + h2 and y1 + h1 > y2
            ):
                count += 1
                break
    return count

# üîπ Parcours du dossier d‚Äôimages et traitement
def process_folder(folder_path, bbox_data_per_image, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    for image_file in os.listdir(folder_path):
        if image_file.lower().endswith((".png", ".jpg", ".jpeg", ".tiff")):
            image_path = os.path.join(folder_path, image_file)
            # Ici on r√©cup√®re les BBoxes associ√©es √† l'image
            bboxes = bbox_data_per_image.get(image_file, [])
            process_image_bboxes(image_file, bboxes, output_dir)

# üîπ Exemple de structure pour bbox_data_per_image (√† adapter selon ta source)
# Chaque BBox est une liste : [x, y, w, h]
bbox_data_per_image = {
    "image1.jpg": [[10, 20, 30, 40], [50, 60, 20, 30]],
    "image2.jpg": [[15, 25, 35, 45], [100, 150, 50, 70]],
    # etc.
}

# üîπ Utilisation
input_folder = "chemin/vers/dossier_images"
output_folder = "chemin/vers/sortie_excel"
process_folder(input_folder, bbox_data_per_image, output_folder)




import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.measure import regionprops, label
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo

# === Conversion pixels ‚Üí nanom√®tres ===
PIXEL_TO_NM = 7.774  # nm / pixel

# === Configuration du mod√®le Detectron2 ===
def setup_predictor(weights_path):
    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file(
        "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"
    ))
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
    cfg.MODEL.WEIGHTS = weights_path
    cfg.MODEL.DEVICE = "cuda"  # ou "cpu"
    return DefaultPredictor(cfg)

# === Fonction pour l'analyse morphologique ===
def analyze_masks(masks):
    diameters_nm = []
    perimeters_nm = []
    feret_ratios = []

    for i in range(masks.shape[0]):
        mask = masks[i].cpu().numpy().astype(np.uint8)
        labeled = label(mask)
        props = regionprops(labeled)

        for prop in props:
            perimeter_px = prop.perimeter
            equiv_diameter_px = prop.equivalent_diameter
            feret_diam_max_px = prop.major_axis_length
            feret_diam_min_px = prop.minor_axis_length

            # Convertir en nm
            diameter_nm = equiv_diameter_px * PIXEL_TO_NM
            perimeter_nm = perimeter_px * PIXEL_TO_NM
            feret_ratio = feret_diam_min_px / feret_diam_max_px if feret_diam_max_px > 0 else 0

            diameters_nm.append(diameter_nm)
            perimeters_nm.append(perimeter_nm)
            feret_ratios.append(feret_ratio)

    return diameters_nm, perimeters_nm, feret_ratios

# === Fonction pour afficher les histogrammes ===
def plot_histogram(data, title, xlabel):
    plt.figure()
    plt.hist(data, bins=20, edgecolor='black', alpha=0.7)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel("Nombre d'objets")
    plt.grid(True)
    plt.show()

# === Main ===
def main(image_path, weights_path):
    predictor = setup_predictor(weights_path)

    image = cv2.imread(image_path)
    outputs = predictor(image)

    if "instances" not in outputs or len(outputs["instances"]) == 0:
        print("Aucun objet d√©tect√©.")
        return

    masks = outputs["instances"].pred_masks
    diameters_nm, perimeters_nm, feret_ratios = analyze_masks(masks)

    # Affichage des histogrammes en nm
    plot_histogram(diameters_nm, "Histogramme des diam√®tres √©quivalents", "Diam√®tre moyen (nm)")
    plot_histogram(perimeters_nm, "Histogramme des p√©rim√®tres", "P√©rim√®tre (nm)")
    plot_histogram(feret_ratios, "Histogramme des rapports Feret min / max", "Rapport (min / max)")

# === Exemple d'utilisation ===
if __name__ == "__main__":
    image_path = "chemin/vers/image.jpg"
    weights_path = "chemin/vers/model_final.pth"  # Mod√®le entra√Æn√© Detectron2
    main(image_path, weights_path)


import pandas as pd
import numpy as np
from collections import defaultdict
import itertools

# === √âtape 1 : Lecture Excel et d√©tection des paires ayant le m√™me temps ===
excel_path = "composants_ref.xlsx"
df_excel = pd.read_excel(excel_path)

# Nettoyer les noms (sans suffixes)
df_excel['Composant'] = df_excel['Composant'].astype(str).str.strip().str.upper()

# Trouver les paires ayant exactement le m√™me temps
time_groups = df_excel.groupby('Temps de r√©tention')['Composant'].apply(list)
duplicate_time_pairs = []

for comps in time_groups:
    if len(comps) > 1:
        duplicate_time_pairs.extend(list(itertools.combinations(comps, 2)))

# === √âtape 2 : Lecture JSON et extraction des composants par chromatogramme ===
json_path = "chromatogrammes.json"
df_json = pd.read_json(json_path).dropna(subset=['pics'])

# Pour stocker les composants et leurs temps par chromatogramme
all_chromatograms = []

for _, row in df_json.iterrows():
    current_components = []
    sorted_pics = sorted(row['pics'].items(), key=lambda x: float(x[0]))

    for time_str, data in sorted_pics:
        time = float(time_str)
        if time <= 150:
            comp_name = str(data[0]).strip().upper()
            current_components.append((comp_name, time))

    all_chromatograms.append(current_components)

# === √âtape 3 : Analyse de l‚Äôordre d‚Äôapparition des paires ===
pair_results = defaultdict(lambda: {"a_precedes_b": 0, "b_precedes_a": 0, "times": []})

for comp_a, comp_b in duplicate_time_pairs:
    for chrom in all_chromatograms:
        names_in_chrom = [c[0] for c in chrom]
        if comp_a in names_in_chrom and comp_b in names_in_chrom:
            idx_a = names_in_chrom.index(comp_a)
            idx_b = names_in_chrom.index(comp_b)
            time_a = chrom[idx_a][1]
            time_b = chrom[idx_b][1]

            if idx_a < idx_b:
                pair_results[(comp_a, comp_b)]["a_precedes_b"] += 1
            else:
                pair_results[(comp_a, comp_b)]["b_precedes_a"] += 1

            pair_results[(comp_a, comp_b)]["times"].append((time_a, time_b))

# === √âtape 4 : Affichage des r√©sultats ===
for (comp_a, comp_b), info in pair_results.items():
    print(f"üß™ Paire : {comp_a} / {comp_b}")
    print(f"   ‚û§ {comp_a} pr√©c√®de {comp_b} : {info['a_precedes_b']} fois")
    print(f"   ‚û§ {comp_b} pr√©c√®de {comp_a} : {info['b_precedes_a']} fois")
    print(f"   ‚û§ Temps observ√©s :")
    for t_a, t_b in info["times"]:
        print(f"     - {comp_a} : {t_a:.2f} | {comp_b} : {t_b:.2f}")
    print("-" * 50)


import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.measure import regionprops, label
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo

# === Conversion pixels ‚Üí nanom√®tres ===
PIXEL_TO_NM = 7.774  # nm / pixel

# === Configuration du mod√®le Detectron2 ===
def setup_predictor(weights_path):
    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file(
        "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"
    ))
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
    cfg.MODEL.WEIGHTS = weights_path
    cfg.MODEL.DEVICE = "cuda"  # ou "cpu"
    return DefaultPredictor(cfg)

# === Fonction pour l'analyse morphologique ===
def analyze_masks(masks):
    diameters_nm = []
    perimeters_nm = []
    feret_ratios = []

    for i in range(masks.shape[0]):
        mask = masks[i].cpu().numpy().astype(np.uint8)
        labeled = label(mask)
        props = regionprops(labeled)

        for prop in props:
            perimeter_px = prop.perimeter
            equiv_diameter_px = prop.equivalent_diameter
            feret_diam_max_px = prop.major_axis_length
            feret_diam_min_px = prop.minor_axis_length

            # Convertir en nm
            diameter_nm = equiv_diameter_px * PIXEL_TO_NM
            perimeter_nm = perimeter_px * PIXEL_TO_NM
            feret_ratio = feret_diam_min_px / feret_diam_max_px if feret_diam_max_px > 0 else 0

            diameters_nm.append(diameter_nm)
            perimeters_nm.append(perimeter_nm)
            feret_ratios.append(feret_ratio)

    return diameters_nm, perimeters_nm, feret_ratios

# === Fonction pour afficher les histogrammes ===
def plot_histogram(data, title, xlabel):
    plt.figure()
    plt.hist(data, bins=20, edgecolor='black', alpha=0.7)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel("Nombre d'objets")
    plt.grid(True)
    plt.show()

# === Main ===
def main(image_path, weights_path):
    predictor = setup_predictor(weights_path)

    image = cv2.imread(image_path)
    outputs = predictor(image)

    if "instances" not in outputs or len(outputs["instances"]) == 0:
        print("Aucun objet d√©tect√©.")
        return

    masks = outputs["instances"].pred_masks
    diameters_nm, perimeters_nm, feret_ratios = analyze_masks(masks)

    # Affichage des histogrammes en nm
    plot_histogram(diameters_nm, "Histogramme des diam√®tres √©quivalents", "Diam√®tre moyen (nm)")
    plot_histogram(perimeters_nm, "Histogramme des p√©rim√®tres", "P√©rim√®tre (nm)")
    plot_histogram(feret_ratios, "Histogramme des rapports Feret min / max", "Rapport (min / max)")

# === Exemple d'utilisation ===
if __name__ == "__main__":
    image_path = "chemin/vers/image.jpg"
    weights_path = "chemin/vers/model_final.pth"  # Mod√®le entra√Æn√© Detectron2
    main(image_path, weights_path)



import cv2
import numpy as np

def calculer_taux_vide_et_cristaux(mask_path):
    # Charger l'image binaire en niveaux de gris
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if mask is None:
        raise ValueError(f"Image non trouv√©e : {mask_path}")

    # Assurer que les pixels sont bien binaires (0 et 255)
    _, mask_bin = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)

    # Nombre total de pixels
    total_pixels = mask_bin.size

    # Nombre de pixels blancs (cristaux) et noirs (vide)
    white_pixels = np.sum(mask_bin == 255)
    black_pixels = np.sum(mask_bin == 0)

    taux_cristaux = white_pixels / total_pixels
    taux_vide = black_pixels / total_pixels

    print(f"Taux de cristaux (pixels blancs) : {taux_cristaux * 100:.2f} %")
    print(f"Taux de vide (pixels noirs)     : {taux_vide * 100:.2f} %")

    return taux_vide, taux_cristaux

# === Exemple d'utilisation ===
if __name__ == "__main__":
    chemin_masque = "chemin/vers/masque_binaire.png"
    calculer_taux_vide_et_cristaux(chemin_masque)



import os
import xml.etree.ElementTree as ET

def voc_to_dota(xml_folder, output_folder, difficulty=0):
    """
    Convertit des fichiers XML VOC (LabelImg) en format DOTA.
    
    :param xml_folder: Dossier contenant les fichiers XML.
    :param output_folder: Dossier o√π enregistrer les fichiers DOTA .txt.
    :param difficulty: Niveau de difficult√© DOTA (0 = facile par d√©faut).
    """
    os.makedirs(output_folder, exist_ok=True)
    
    for xml_file in os.listdir(xml_folder):
        if not xml_file.endswith('.xml'):
            continue

        xml_path = os.path.join(xml_folder, xml_file)
        tree = ET.parse(xml_path)
        root = tree.getroot()

        image_filename = root.find('filename').text
        image_name = os.path.splitext(image_filename)[0]
        txt_path = os.path.join(output_folder, image_name + '.txt')

        with open(txt_path, 'w') as f_out:
            for obj in root.findall('object'):
                name = obj.find('name').text
                bndbox = obj.find('bndbox')
                xmin = float(bndbox.find('xmin').text)
                ymin = float(bndbox.find('ymin').text)
                xmax = float(bndbox.find('xmax').text)
                ymax = float(bndbox.find('ymax').text)

                # Conversion HBB ‚Üí OBB (sans rotation)
                # x1, y1: top-left
                # x2, y2: top-right
                # x3, y3: bottom-right
                # x4, y4: bottom-left
                x1, y1 = xmin, ymin
                x2, y2 = xmax, ymin
                x3, y3 = xmax, ymax
                x4, y4 = xmin, ymax

                # Format DOTA
                line = f"{x1:.1f} {y1:.1f} {x2:.1f} {y2:.1f} {x3:.1f} {y3:.1f} {x4:.1f} {y4:.1f} {name} {difficulty}\n"
                f_out.write(line)

    print(f"[‚úì] Conversion termin√©e. R√©sultats enregistr√©s dans : {output_folder}")

voc_folder = 'annotations_xml/'     # dossier contenant les .xml g√©n√©r√©s par LabelImg
dota_output = 'dota_annfiles/'      # dossier de sortie .txt format DOTA

voc_to_dota(voc_folder, dota_output)


import os
import json

def convert_labelme_to_dota(json_folder, output_folder, difficulty=0):
    os.makedirs(output_folder, exist_ok=True)

    for json_file in os.listdir(json_folder):
        if not json_file.endswith('.json'):
            continue

        json_path = os.path.join(json_folder, json_file)
        with open(json_path, 'r') as f:
            data = json.load(f)

        img_name = os.path.splitext(json_file)[0]
        txt_path = os.path.join(output_folder, img_name + '.txt')

        with open(txt_path, 'w') as f_out:
            for shape in data['shapes']:
                label = shape['label']
                points = shape['points']

                # On ne garde que les polygones avec 4 points
                if len(points) != 4:
                    print(f"[!] Ignor√© : {json_file}, objet '{label}' n'a pas 4 points")
                    continue

                # Flatten les coordonn√©es
                coords = [f"{x:.1f} {y:.1f}" for x, y in points]
                coords_str = " ".join(coords)

                # √âcrire en format DOTA
                line = f"{coords_str} {label} {difficulty}\n"
                f_out.write(line)

    print(f"[‚úì] Conversion termin√©e. Annotations DOTA enregistr√©es dans : {output_folder}")

labelme_json_folder = 'annotations_labelme/'
dota_output_folder = 'dota_annfiles/'

convert_labelme_to_dota(labelme_json_folder, dota_output_folder)
