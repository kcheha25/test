import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras import Model, initializers
from tensorflow.keras.regularizers import L2
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization, Dense, LeakyReLU, Input

# üîπ Charger les donn√©es JSON en DataFrame
file_path = "chromatogrammes.json"  # Remplace par ton fichier r√©el
df = pd.read_json(file_path)

# üîπ Suppression des chromatogrammes sans pics
df = df.dropna(subset=['pics'])

# üîπ Suppression des chromatogrammes qui ne font pas exactement 71 840 points
df = df[df["x"].apply(len) == 71840]

# üîπ Cr√©ation de X avec 2 colonnes (temps de r√©tention et intensit√©) sous forme 2D
X = np.array([np.column_stack((row["x"], row["y"])) for _, row in df.iterrows()])

# üîπ Pr√©paration des labels y pour tous les pics (hauteur, bornes d'int√©gration, nom du composant)
y_height = []
y_bounds = []
y_component = []

for _, row in df.iterrows():
    for pic_key, pic_data in row["pics"].items():
        # Donn√©es des pics : [nom_composant, borne_avant, borne_apres]
        nom_composant, borne_avant, borne_apres = pic_data
        
        # Hauteur du pic : Prenons ici la valeur de l'intensit√© maximale pour simplifier
        pic_data_x = np.array(row["x"])
        pic_data_y = np.array(row["y"])
        
        # Trouver l'indice de la borne du pic
        indices_borne_avant = np.where(pic_data_x >= borne_avant)[0]
        indices_borne_apres = np.where(pic_data_x <= borne_apres)[0]
        
        # Si les bornes existent dans le chromatogramme
        if len(indices_borne_avant) > 0 and len(indices_borne_apres) > 0:
            pic_segment_x = pic_data_x[indices_borne_avant[0]:indices_borne_apres[-1]+1]
            pic_segment_y = pic_data_y[indices_borne_avant[0]:indices_borne_apres[-1]+1]
            
            # Hauteur du pic : maximum d'intensit√© dans cette r√©gion
            pic_height = np.max(pic_segment_y)
        else:
            pic_height = 0
        
        # Stockage des labels pour ce pic
        y_height.append(pic_height)
        y_bounds.append([borne_avant, borne_apres])
        
        # Pour le nom du composant, on utilise un encodeur de labels
        label_encoder = LabelEncoder()
        y_component.append(label_encoder.fit_transform([nom_composant])[0])

# üîπ Conversion des listes en arrays numpy
y_height = np.array(y_height)
y_bounds = np.array(y_bounds)
y_component = np.array(y_component)

# üîπ Split des donn√©es en train et test
X_train, X_test, y_height_train, y_height_test, y_bounds_train, y_bounds_test, y_component_train, y_component_test = train_test_split(
    X, y_height, y_bounds, y_component, test_size=0.2, random_state=42)

# üîπ D√©finir le mod√®le avec les LSTM
class IPA_LSTM_Variable(tf.keras.Model):
    def __init__(self, seed_value, regularization_factor, dropout_rate=0.2, lstm_units=64):
        super(IPA_LSTM_Variable, self).__init__()
        
        # Partie IPA pour extraire les caract√©ristiques
        self.stem = tf.keras.Sequential([
            BasicConv1D(filters=16, kernel_size=3, strides=2, kernel_regularizer=L2(regularization_factor), kernel_initializer=initializers.HeNormal(seed_value)),
            BasicConv1D(filters=16, kernel_size=3, kernel_regularizer=L2(regularization_factor), kernel_initializer=initializers.HeNormal(seed_value)),
            BasicConv1D(filters=16, kernel_size=3, kernel_regularizer=L2(regularization_factor), kernel_initializer=initializers.HeNormal(seed_value)),
        ])
        
        self.module_35x35 = Module_35x35(in_channels=32, regularization_factor=regularization_factor, seed_value=seed_value)
        self.flatten = Flatten()
        self.dropout = Dropout(rate=dropout_rate)
        
        # LSTM pour g√©rer les s√©quences de longueur variable
        self.lstm = layers.LSTM(lstm_units, return_sequences=True)
        
        # Sortie pour les diff√©rentes informations sur les pics
        self.height_regressor = Dense(1)  # Pr√©diction de la hauteur du pic
        self.bounds_regressor = Dense(2)  # Pr√©diction des bornes (avant, apr√®s)
        self.component_classifier = Dense(1)  # Pr√©diction du composant (r√©gression ou classification)

    def call(self, x):
        out = self.stem(x)
        out = self.module_35x35(out)
        out = self.flatten(out)
        out = self.dropout(out)
        
        # Sortie LSTM pour g√©n√©rer les infos des pics
        out = self.lstm(out)
        
        height_output = self.height_regressor(out)  # Hauteur du pic
        bounds_output = self.bounds_regressor(out)  # Bornes d'int√©gration (avant, apr√®s)
        component_output = self.component_classifier(out)  # Nom du composant

        return height_output, bounds_output, component_output

# Cr√©ation de l'instance du mod√®le
model = IPA_LSTM_Variable(seed_value=1, regularization_factor=0.0095)

# Compilation du mod√®le
model.compile(optimizer='adam',
              loss={'height_output': 'mse', 
                    'bounds_output': 'mse', 
                    'component_output': 'categorical_crossentropy'},
              metrics={'height_output': 'mae', 
                       'bounds_output': 'mae', 
                       'component_output': 'accuracy'})

# Entra√Ænement
history = model.fit(X_train, 
                    {'height_output': y_height_train, 
                     'bounds_output': y_bounds_train, 
                     'component_output': y_component_train}, 
                    epochs=50, 
                    batch_size=32)
