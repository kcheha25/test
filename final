import cv2
import numpy as np
from PIL import Image
from collections import defaultdict
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg

# ========================
# Fonction calcul T0 T1 T2
# ========================
def calc_tensors_from_mask(mask, d=5):
    mask = mask.astype(np.uint8)
    H, W = mask.shape
    ys, xs = np.nonzero(mask)
    if len(xs) == 0:
        return 0, np.zeros(3), np.zeros((3, 3))

    xO = xs.mean()
    yO = ys.mean()
    y_min = ys.min()
    y_max = ys.max()
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    contour_points = set(tuple(pt[0]) for c in contours for pt in c)

    T0 = 0.0
    T1 = np.zeros(3)
    T2 = np.zeros((3, 3))

    max_offset = max(yO - y_min, y_max - yO)
    max_steps = int(np.ceil(max_offset / d))
    y_offsets, directions = [], []

    for i in range(1, max_steps + 1):
        for sign in [1, -1]:
            y_candidate = int(round(yO + sign * i * d))
            if y_candidate < y_min or y_candidate > y_max:
                continue
            if i % 2 == 1:
                direction = 'right' if sign == 1 else 'left'
            else:
                direction = 'left' if sign == 1 else 'right'
            y_offsets.append(sign * i * d)
            directions.append(direction)

    for offset, direction in zip(y_offsets, directions):
        y = int(round(yO + offset))
        if y < 0 or y >= H:
            continue

        intersections = []
        if direction == 'right':
            for x in range(int(np.ceil(xO)) + 1, W):
                if (x, y) in contour_points:
                    intersections.append((x, y))
        else:
            for x in range(int(np.floor(xO)) - 1, -1, -1):
                if (x, y) in contour_points:
                    intersections.append((x, y))

        if not intersections:
            continue

        intersections_sorted = sorted(
            intersections,
            key=lambda p: np.hypot(p[0] - xO, p[1] - yO),
            reverse=True
        )

        sign = 1
        for (x_int, y_int) in intersections_sorted:
            xr = x_int - xO
            yr = y_int - yO
            g0 = np.pi * d * xr ** 2
            g1 = np.array([0, np.pi * d * xr ** 2 * yr, 0])
            g2 = np.array([
                [np.pi / 8 * d * xr ** 4, 0, 0],
                [0, np.pi / 2 * d * xr ** 2 * yr ** 2, 0],
                [0, 0, np.pi / 8 * d * xr ** 4]
            ])
            T0 += sign * g0
            T1 += sign * g1
            T2 += sign * g2
            sign *= -1

    return T0, T1, T2

def calculate_semi_axes(T0, T1, T2):
    """Calcule les longueurs des demi-axes à partir des tenseurs centrés."""
    # 1. Centrage du tenseur T2 pour éliminer l'effet de position
    T2_centered = T2 - np.outer(T1, T1) / (2 * T0)

    # 2. Diagonalisation
    eigenvalues, eigenvectors = np.linalg.eigh(T2_centered)

    # 3. Constante pour d=3
    kappa_3 = 4 * np.pi / 3
    factor = (2 * (3 + 2) / kappa_3) ** (1/(3 + 2))  # (10 / (4π/3))^(1/5)

    # Valeurs propres triées
    lambda1, lambda2, lambda3 = eigenvalues

    # Demi-axes
    a1 = factor * (lambda1 ** 0.4) / ((lambda2 * lambda3) ** 0.1)
    a2 = factor * (lambda2 ** 0.4) / ((lambda1 * lambda3) ** 0.1)
    a3 = factor * (lambda3 ** 0.4) / ((lambda1 * lambda2) ** 0.1)

    return np.array([a1, a2, a3]), eigenvectors

def extract_area(mask):
    return np.count_nonzero(mask)

def subclass_label(cls, part):
    return f"{cls}_{part}"

# ============================
# Paramètres Detectron2 & data
# ============================
image_path = "chemin/vers/ton_image.png" 
config_path = "chemin/vers/config.yaml"
weights_path = "chemin/vers/model_final.pth"

patch_size = (512, 350)
resized_size = (512, 400)
overlap = 50

# Init modèle
cfg = get_cfg()
cfg.merge_from_file(config_path)
cfg.MODEL.WEIGHTS = weights_path
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)

# Variables d'accumulation
global_results = defaultdict(lambda: {"T0": [], "T1": [], "T2": []})
count_per_class = defaultdict(int)
count_subclass = defaultdict(int)
area_per_class = defaultdict(int)
area_subclass = defaultdict(int)

# === Lecture image ===
image = Image.open(image_path).convert("RGB")
width, height = image.size

# Cartes pour fusion
class_map = np.full((height, width), fill_value=255, dtype=np.uint8)
score_map = np.zeros((height, width), dtype=np.float32)
masks_all = []
pred_classes_all = []

pw, ph = patch_size
for y in range(0, height, ph - overlap):
    for x in range(0, width, pw - overlap):
        crop_w = min(pw + (overlap if x + pw < width else 0), width - x)
        crop_h = min(ph + (overlap if y + ph < height else 0), height - y)

        patch = image.crop((x, y, x + crop_w, y + crop_h)).resize(resized_size)
        patch_np = np.array(patch)

        outputs = predictor(patch_np)
        instances = outputs["instances"].to("cpu")

        for i in range(len(instances)):
            class_id = int(instances.pred_classes[i])
            score = float(instances.scores[i])
            mask = instances.pred_masks[i].numpy().astype(np.uint8) * 255
            mask_resized = cv2.resize(mask, (crop_w, crop_h), interpolation=cv2.INTER_NEAREST)

            y1, y2 = y, y + crop_h
            x1, x2 = x, x + crop_w
            mask_pixels = mask_resized > 127
            update_pixels = mask_pixels & (score > score_map[y1:y2, x1:x2])

            class_map[y1:y2, x1:x2][update_pixels] = class_id
            score_map[y1:y2, x1:x2][update_pixels] = score

            full_mask = np.zeros((height, width), dtype=np.uint8)
            full_mask[y1:y2, x1:x2][mask_pixels] = 1
            masks_all.append(full_mask)
            pred_classes_all.append(class_id)

# ==== Calcul T0/T1/T2 par classe et sous-classe ====
indices_0 = [i for i, c in enumerate(pred_classes_all) if c == 0]
indices_1 = [i for i, c in enumerate(pred_classes_all) if c == 1]
indices_2 = [i for i, c in enumerate(pred_classes_all) if c == 2]

areas_0 = np.array([extract_area(masks_all[i]) for i in indices_0])
areas_1 = np.array([extract_area(masks_all[i]) for i in indices_1])

median_0 = np.median(areas_0) if len(areas_0) > 0 else 0
median_1 = np.median(areas_1) if len(areas_1) > 0 else 0

# Classe 0
for i, idx in enumerate(indices_0):
    part = 1 if areas_0[i] <= median_0 else 2
    label = subclass_label(0, part)
    T0, T1, T2 = calc_tensors_from_mask(masks_all[idx])
    global_results[label]["T0"].append(T0)
    global_results[label]["T1"].append(T1)
    global_results[label]["T2"].append(T2)
    area_per_class[0] += areas_0[i]
    area_subclass[label] += areas_0[i]
    count_per_class[0] += 1
    count_subclass[label] += 1

# Classe 1
for i, idx in enumerate(indices_1):
    part = 1 if areas_1[i] <= median_1 else 2
    label = subclass_label(1, part)
    T0, T1, T2 = calc_tensors_from_mask(masks_all[idx])
    global_results[label]["T0"].append(T0)
    global_results[label]["T1"].append(T1)
    global_results[label]["T2"].append(T2)
    area_per_class[1] += areas_1[i]
    area_subclass[label] += areas_1[i]
    count_per_class[1] += 1
    count_subclass[label] += 1

# Classe 2
for idx in indices_2:
    label = "2"
    T0, T1, T2 = calc_tensors_from_mask(masks_all[idx])
    global_results[label]["T0"].append(T0)
    global_results[label]["T1"].append(T1)
    global_results[label]["T2"].append(T2)
    area = extract_area(masks_all[idx])
    area_per_class[2] += area
    area_subclass[label] += area
    count_per_class[2] += 1

# ============================
# Moyennes finales et pourcentages
# ============================
mean_results = {
    label: {
        "T0": np.mean(vals["T0"]) if vals["T0"] else 0,
        "T1": np.mean(vals["T1"], axis=0) if vals["T1"] else np.zeros(3),
        "T2": np.mean(vals["T2"], axis=0) if vals["T2"] else np.zeros((3, 3))
    }
    for label, vals in global_results.items()
}
for label in mean_results:
    T0 = mean_results[label]["T0"]
    T1 = mean_results[label]["T1"]
    T2 = mean_results[label]["T2"]
    
    # Calcul des semi-axes pour cette classe
    semi_axes, eigenvectors = calculate_semi_axes(T0, T1, T2)
    
    # Ajout des résultats
    mean_results[label]["semi_axes"] = semi_axes
    mean_results[label]["eigenvectors"] = eigenvectors
    
percentages = {}
if count_per_class[0] > 0:
    percentages["0_1"] = 100 * count_subclass["0_1"] / count_per_class[0]
    percentages["0_2"] = 100 * count_subclass["0_2"] / count_per_class[0]
if count_per_class[1] > 0:
    percentages["1_1"] = 100 * count_subclass["1_1"] / count_per_class[1]
    percentages["1_2"] = 100 * count_subclass["1_2"] / count_per_class[1]

percentages_area = {}
if area_per_class[0] > 0:
    percentages_area["0_1"] = 100 * area_subclass["0_1"] / area_per_class[0]
    percentages_area["0_2"] = 100 * area_subclass["0_2"] / area_per_class[0]
if area_per_class[1] > 0:
    percentages_area["1_1"] = 100 * area_subclass["1_1"] / area_per_class[1]
    percentages_area["1_2"] = 100 * area_subclass["1_2"] / area_per_class[1]


print("=== Moyennes T0/T1/T2 et semi-axes calculés par classe ===")
for label, vals in mean_results.items():
    print(f"\nClasse {label}:")
    print(f"T0 moyen: {vals['T0']}")
    print(f"T1 moyen: {vals['T1']}")
    print(f"T2 moyen:\n{vals['T2']}")
    print(f"Demi-axes calculés: {vals['semi_axes']}")
    print(f"Directions principales:\n{vals['eigenvectors']}")

print("\n=== Pourcentages par sous-classe (nombre d'objets) ===")
for label, perc in percentages.items():
    print(f"{label}: {perc:.2f} %")

print("\n=== Pourcentages par surface occupée ===")
for label, perc in percentages_area.items():
    print(f"{label}: {perc:.2f} %")



################################################

# ============================
# Moyennes finales et calcul des semi-axes
# ============================
mean_results = {
    label: {
        "T0": np.mean(vals["T0"]) if vals["T0"] else 0,
        "T1": np.mean(vals["T1"], axis=0) if vals["T1"] else np.zeros(3),
        "T2": np.mean(vals["T2"], axis=0) if vals["T2"] else np.zeros((3, 3)),
        # Suppression des moyennes de semi-axes existantes
    }
    for label, vals in global_results.items()
}

# Calcul des semi-axes à partir des tenseurs moyens
for label in mean_results:
    T0 = mean_results[label]["T0"]
    T1 = mean_results[label]["T1"]
    T2 = mean_results[label]["T2"]
    
    # Calcul des semi-axes pour cette classe
    semi_axes, eigenvectors = calculate_semi_axes(T0, T1, T2)
    
    # Ajout des résultats
    mean_results[label]["semi_axes"] = semi_axes
    mean_results[label]["eigenvectors"] = eigenvectors

# Le reste du code (pourcentages etc.) reste inchangé
percentages = {}
if count_per_class[0] > 0:
    percentages["0_1"] = 100 * count_subclass["0_1"] / count_per_class[0]
    percentages["0_2"] = 100 * count_subclass["0_2"] / count_per_class[0]
if count_per_class[1] > 0:
    percentages["1_1"] = 100 * count_subclass["1_1"] / count_per_class[1]
    percentages["1_2"] = 100 * count_subclass["1_2"] / count_per_class[1]

percentages_area = {}
if area_per_class[0] > 0:
    percentages_area["0_1"] = 100 * area_subclass["0_1"] / area_per_class[0]
    percentages_area["0_2"] = 100 * area_subclass["0_2"] / area_per_class[0]
if area_per_class[1] > 0:
    percentages_area["1_1"] = 100 * area_subclass["1_1"] / area_per_class[1]
    percentages_area["1_2"] = 100 * area_subclass["1_2"] / area_per_class[1]

print("=== Moyennes T0/T1/T2 et semi-axes calculés par classe ===")
for label, vals in mean_results.items():
    print(f"\nClasse {label}:")
    print(f"T0 moyen: {vals['T0']}")
    print(f"T1 moyen: {vals['T1']}")
    print(f"T2 moyen:\n{vals['T2']}")
    print(f"Demi-axes calculés: {vals['semi_axes']}")
    print(f"Directions principales:\n{vals['eigenvectors']}")

print("\n=== Pourcentages par sous-classe (nombre d'objets) ===")
for label, perc in percentages.items():
    print(f"{label}: {perc:.2f} %")

print("\n=== Pourcentages par surface occupée ===")
for label, perc in percentages_area.items():
    print(f"{label}: {perc:.2f} %")


# ============================
# Volume par classe et calcul du cube
# ============================

# Volume total par classe (somme des T0)
volume_par_classe = {cid: 0.0 for cid in [0, 1, 2]}
for label, vals in global_results.items():
    if label.startswith("0"):
        volume_par_classe[0] += sum(vals["T0"])
    elif label.startswith("1"):
        volume_par_classe[1] += sum(vals["T0"])
    elif label == "2":
        volume_par_classe[2] += sum(vals["T0"])

# Fractions en décimal (par ex. fractions = {0: 30, 1: 50, 2: 20})
fractions = {0: 30, 1: 50, 2: 20}  # <-- à adapter selon ton cas
fractions_decimales = {cid: fractions[cid] / 100 for cid in [0, 1, 2]}

# Calcul du volume du cube estimé
Vcube = 0
for cid in [0, 1, 2]:
    f = fractions_decimales[cid]
    v = volume_par_classe[cid]
    if f > 0:
        Vcube += v / f

# Longueur caractéristique
if Vcube > 0:
    L = Vcube ** (1 / 3)
    print(f"\n=== Estimation du volume global ===")
    print(f"Volume du cube estimé : Vcube ≈ {Vcube:.2f} px³")
    print(f"Longueur caractéristique (L) ≈ {L:.2f} px")
else:
    print("\nImpossible de calculer Vcube (aucune fraction détectée).")



from sklearn.cluster import KMeans

# ============================
# KMeans sur intensité des pixels pour la classe 2
# ============================
gray_image = np.array(image.convert("L"))  # image en niveaux de gris

proportions_cluster0 = []
proportions_cluster1 = []

for idx in indices_2:
    mask = masks_all[idx].astype(bool)  # masque binaire de l'objet
    pixels = gray_image[mask]

    if pixels.size == 0:
        continue

    # Reshape en vecteur colonne pour KMeans
    pixels_reshaped = pixels.reshape(-1, 1)

    # Appliquer KMeans avec 2 clusters
    kmeans = KMeans(n_clusters=2, n_init=10, random_state=0)
    labels = kmeans.fit_predict(pixels_reshaped)

    # Calcul proportion de chaque cluster
    cluster0_ratio = np.sum(labels == 0) / pixels.size * 100
    cluster1_ratio = np.sum(labels == 1) / pixels.size * 100

    proportions_cluster0.append(cluster0_ratio)
    proportions_cluster1.append(cluster1_ratio)

if proportions_cluster0 and proportions_cluster1:
    mean_cluster0 = np.mean(proportions_cluster0)
    mean_cluster1 = np.mean(proportions_cluster1)
    print("\n=== KMeans intensité pixels pour la classe 2 ===")
    print(f"Proportion moyenne cluster 0 : {mean_cluster0:.2f} %")
    print(f"Proportion moyenne cluster 1 : {mean_cluster1:.2f} %")
else:
    print("\nAucun objet détecté pour la classe 2 (pas de KMeans possible).")


import matplotlib.pyplot as plt

# ============================
# Visualisation objets classe 2 avec clusters KMeans colorés
# ============================

gray_image = np.array(image.convert("L"))  # image en niveaux de gris

for obj_id, idx in enumerate(indices_2, start=1):
    mask = masks_all[idx].astype(bool)  # masque binaire de l'objet
    pixels = gray_image[mask]

    if pixels.size == 0:
        continue

    # Reshape en vecteur colonne pour KMeans
    pixels_reshaped = pixels.reshape(-1, 1)

    # Appliquer KMeans avec 2 clusters
    kmeans = KMeans(n_clusters=2, n_init=10, random_state=0)
    labels = kmeans.fit_predict(pixels_reshaped)

    # Trier clusters par intensité (0 = sombre, 1 = clair)
    centers = kmeans.cluster_centers_.flatten()
    order = np.argsort(centers)  
    labels_sorted = np.array([order[label] for label in labels])

    # Créer une image RGB pour visualisation
    cluster_img = np.zeros((*mask.shape, 3), dtype=np.uint8)

    # Colorier chaque cluster (0 = rouge, 1 = bleu)
    cluster_img[mask] = np.where(
        labels_sorted[:, None] == 0,
        [255, 0, 0],   # rouge
        [0, 0, 255]    # bleu
    )

    # Afficher l'objet
    plt.figure(figsize=(4, 4))
    plt.imshow(cluster_img)
    plt.title(f"Objet {obj_id} (classe 2)")
    plt.axis("off")
    plt.show()


import os
import cv2
import numpy as np
from skimage.measure import regionprops, label
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo


def calc_tensors_from_mask(mask, d=5):
    mask = mask.astype(np.uint8)
    H, W = mask.shape
    ys, xs = np.nonzero(mask)
    if len(xs) == 0:
        return 0, np.zeros(3), np.zeros((3, 3))

    xO = xs.mean()
    yO = ys.mean()
    y_min = ys.min()
    y_max = ys.max()
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    contour_points = set(tuple(pt[0]) for c in contours for pt in c)

    T0 = 0.0
    T1 = np.zeros(3)
    T2 = np.zeros((3, 3))

    max_offset = max(yO - y_min, y_max - yO)
    max_steps = int(np.ceil(max_offset / d))
    y_offsets, directions = [], []

    for i in range(1, max_steps + 1):
        for sign in [1, -1]:
            y_candidate = int(round(yO + sign * i * d))
            if y_candidate < y_min or y_candidate > y_max:
                continue
            if i % 2 == 1:
                direction = 'right' if sign == 1 else 'left'
            else:
                direction = 'left' if sign == 1 else 'right'
            y_offsets.append(sign * i * d)
            directions.append(direction)

    for offset, direction in zip(y_offsets, directions):
        y = int(round(yO + offset))
        if y < 0 or y >= H:
            continue

        intersections = []
        if direction == 'right':
            for x in range(int(np.ceil(xO)) + 1, W):
                if (x, y) in contour_points:
                    intersections.append((x, y))
        else:
            for x in range(int(np.floor(xO)) - 1, -1, -1):
                if (x, y) in contour_points:
                    intersections.append((x, y))

        if not intersections:
            continue

        intersections_sorted = sorted(
            intersections,
            key=lambda p: np.hypot(p[0] - xO, p[1] - yO),
            reverse=True
        )

        sign = 1
        for (x_int, y_int) in intersections_sorted:
            xr = x_int - xO
            yr = y_int - yO
            g0 = np.pi * d * xr ** 2
            g1 = np.array([0, np.pi * d * xr ** 2 * yr, 0])
            g2 = np.array([
                [np.pi / 8 * d * xr ** 4, 0, 0],
                [0, np.pi / 2 * d * xr ** 2 * yr ** 2, 0],
                [0, 0, np.pi / 8 * d * xr ** 4]
            ])
            T0 += sign * g0
            T1 += sign * g1
            T2 += sign * g2
            sign *= -1

    return T0, T1, T2


def calculate_semi_axes(T0, T1, T2):
    T2_centered = T2 - np.outer(T1, T1) / (2 * T0)
    eigenvalues, eigenvectors = np.linalg.eigh(T2_centered)

    kappa_3 = 4 * np.pi / 3
    factor = (2 * (3 + 2) / kappa_3) ** (1/(3 + 2))

    lambda1, lambda2, lambda3 = eigenvalues
    a1 = factor * (lambda1 ** 0.4) / ((lambda2 * lambda3) ** 0.1)
    a2 = factor * (lambda2 ** 0.4) / ((lambda1 * lambda3) ** 0.1)
    a3 = factor * (lambda3 ** 0.4) / ((lambda1 * lambda2) ** 0.1)

    return np.array([a1, a2, a3]), eigenvectors



IMAGE_FOLDER = "images_input"
MODEL_CONFIG = "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"
MODEL_WEIGHTS = "model_final.pth" 
RESOLUTION = 7.443  # nm/pixel
DIAMETER_THRESHOLD = 200  # nm

# ========================
# Initialisation Detectron2
# ========================
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(MODEL_CONFIG))
cfg.MODEL.WEIGHTS = MODEL_WEIGHTS
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)

# ========================
# Accumulateurs globaux
# ========================
T0_all, T1_all, T2_all = [], [], []
diameters_px, diameters_nm = [], []

# ========================
# Parcours des images
# ========================
for fname in os.listdir(IMAGE_FOLDER):
    if not fname.lower().endswith((".png", ".jpg", ".jpeg", ".tif", ".tiff")):
        continue

    image_path = os.path.join(IMAGE_FOLDER, fname)
    image = cv2.imread(image_path)

    outputs = predictor(image)
    instances = outputs["instances"].to("cpu")
    masks = instances.pred_masks.numpy()

    for mask in masks:
        # Calculer diamètre avec regionprops
        labeled_mask = label(mask)
        props = regionprops(labeled_mask)
        if not props:
            continue

        diameter_px = props[0].equivalent_diameter
        diameter_nm = diameter_px * RESOLUTION

        diameters_px.append(diameter_px)
        diameters_nm.append(diameter_nm)

        if diameter_nm > DIAMETER_THRESHOLD:
            T0, T1, T2 = calc_tensors_from_mask(mask)
            T0_all.append(T0)
            T1_all.append(T1)
            T2_all.append(T2)

# ========================
# Moyennes globales
# ========================
if len(T0_all) > 0:
    T0_mean = np.mean(T0_all)
    T1_mean = np.mean(T1_all, axis=0)
    T2_mean = np.mean(T2_all, axis=0)

    semi_axes, eigvecs = calculate_semi_axes(T0_mean, T1_mean, T2_mean)

    diameter_mean_px = np.mean(diameters_px) if diameters_px else None
    diameter_mean_nm = np.mean(diameters_nm) if diameters_nm else None

    print("✅ Demi-axes moyens :", semi_axes)
    print("📏 Diamètre moyen (px) :", diameter_mean_px)
    print("📏 Diamètre moyen (nm) :", diameter_mean_nm)
else:
    semi_axes = None
    print("⚠️ Aucun objet > 200 nm trouvé.")


if len(T0_all) > 0:
    T0_mean = np.mean(T0_all)
    T1_mean = np.mean(T1_all, axis=0)
    T2_mean = np.mean(T2_all, axis=0)

    semi_axes_px, eigvecs = calculate_semi_axes(T0_mean, T1_mean, T2_mean)
    semi_axes_nm = semi_axes_px * RESOLUTION  # conversion en nm

    diameter_mean_px = np.mean(diameters_px) if diameters_px else None
    diameter_mean_nm = np.mean(diameters_nm) if diameters_nm else None

    # ------------------------------
    # Conversion pour 250×
    # ------------------------------
    magnification_ref = 15000
    magnification_target = 250
    scale = magnification_target / magnification_ref  # = 1/60

    # Nouvelle résolution en nm/px
    resolution_ref = RESOLUTION  # nm/px à 15000×
    resolution_target = resolution_ref / scale  # nm/px à 250×

    # Diamètre moyen en pixels à 250×
    diameter_mean_px_250 = diameter_mean_px * scale if diameter_mean_px else None
    # Diamètre moyen en nm ne change pas
    diameter_mean_nm_250 = diameter_mean_nm  

    # Semi-axes en pixels à 250×
    semi_axes_px_250 = semi_axes_px * scale
    # Semi-axes en nm restent identiques
    semi_axes_nm_250 = semi_axes_nm  

    # ------------------------------
    # Affichage résultats
    # ------------------------------
    print("✅ Demi-axes moyens (px @15000×) :", semi_axes_px)
    print("✅ Demi-axes moyens (nm @15000×) :", semi_axes_nm)
    print("📏 Diamètre moyen (px @15000×) :", diameter_mean_px)
    print("📏 Diamètre moyen (nm @15000×) :", diameter_mean_nm)

    print("📏 Diamètre moyen (px @250×) :", diameter_mean_px_250)
    print("📏 Diamètre moyen (nm @250×) :", diameter_mean_nm_250)
    print("🔹 Semi-axes (px @250×) :", semi_axes_px_250)
    print("🔹 Semi-axes (nm @250×) :", semi_axes_nm_250)

else:
    semi_axes = None
    print("⚠️ Aucun objet > 200 nm trouvé.")


Dans ce contexte en pleine évolution technologique, l’alternance s’est déroulée au sein de l’entreprise IFP Énergies nouvelles. Faisant partie de la Direction Physique et Analyses, plus précisément dans le département Caractérisation des Matériaux, les projets avaient pour objectif le développement de modèles d’intelligence artificielle appliqués aux données de microscopie pour étudier les matériaux. L’alternance s’est articulée autour de quatre projets principaux. Dans un premier temps, l’objectif était de développer un modèle de segmentation d'instance permettant la détection des éléments de platine présents dans les images issues du microscope électronique à transmission à balayage en champ sombre annulaire à grand angle. Dans un second temps, le but était de concevoir un modèle capable d’identifier les phases actives catalytiques sous forme de feuillets déposés sur un support de catalyseur de type alumine. Ensuite, l’objectif du troisième projet était de développer un système de détection automatique des pics dans les données de chromatographie en phase gazeuse, et de pouvoir ensuite attribuer à chaque pic le nom du composé correspondant. Enfin, la finalité du quatrième projet était, d’une part, de développer un modèle de segmentation capable de détecter trois classes différentes dans les images à faible grandissement (les zones denses, les zones creuses et les zones intermédiaires), et, d’autre part, de concevoir un modèle capable de détecter des cristaux dans les images à fort grandissement. Il s’agissait ensuite, à partir des différents paramètres et statistiques extraits par ces deux modèles, d’utiliser un modèle de génération 3D booléen pour produire une microstructure 3D reflétant les différentes hétérogénéités des matériaux.

Ce rapport est structuré en quatre parties : la première est consacrée à la présentation de l’entreprise, aborde également la demande initiale de l’alternance et examine l’état de l’égalité femmes-hommes au sein de l’entreprise ; la deuxième présente le contexte et les enjeux du projet ; la troisième détaille la méthodologie et les travaux réalisés ; et la quatrième conclut le rapport en résumant le travail réalisé durant cette année d’alternance. Cette section met en lumière les accomplissements, les défis rencontrés, les résultats obtenus, ainsi que les perspectives futures.


# === Création du masque global (si besoin de visualiser) ===
zone_mask = np.zeros((height, width), dtype=np.uint8)
for poly in all_polygons:
    cv2.fillPoly(zone_mask, [np.array(poly, dtype=np.int32)], 255)

# === Calcul du volume total à partir de tous les polygones ===
volume_bille = 0.0
for poly in all_polygons:
    mask_poly = np.zeros((height, width), dtype=np.uint8)
    cv2.fillPoly(mask_poly, [np.array(poly, dtype=np.int32)], 1)

    # Appel à ta fonction existante
    T0, T1, T2 = calc_tensors_from_mask(mask_poly)

    # Ici on prend T0 comme volume
    volume_bille += T0

print(f"\nVolume total des polygones dessinés : {volume_bille}")

fraction_volumique = {cid: volume_par_classe[cid] / volume_bille for cid in volume_par_classe}

print("\n=== Fractions volumiques par classe ===")
for cid, frac in fraction_volumique.items():
    print(f"Classe {cid}: {frac:.6f}")


# ========================
# Accumulateurs globaux
# ========================
T0_all, T1_all, T2_all = [], [], []
diameters_px, diameters_nm = [], []
volumes_all = []

# ========================
# Parcours des images
# ========================
for fname in os.listdir(IMAGE_FOLDER): 
    if not fname.lower().endswith((".png", ".jpg", ".jpeg", ".tif", ".tiff")):
        continue

    image_path = os.path.join(IMAGE_FOLDER, fname)
    image = cv2.imread(image_path)

    outputs = predictor(image)
    instances = outputs["instances"].to("cpu")
    masks = instances.pred_masks.numpy()

    for mask in masks:
        # Calculer diamètre avec regionprops
        labeled_mask = label(mask)
        props = regionprops(labeled_mask)
        if not props:
            continue

        diameter_px = props[0].equivalent_diameter
        diameter_nm = diameter_px * RESOLUTION

        diameters_px.append(diameter_px)
        diameters_nm.append(diameter_nm)

        if diameter_nm > DIAMETER_THRESHOLD:
            T0, T1, T2 = calc_tensors_from_mask(mask)
            T0_all.append(T0)
            T1_all.append(T1)
            T2_all.append(T2)
            volumes_all.append(T0)  # volume pondération

# ========================
# Moyennes globales
# ========================
if len(T0_all) > 0:
    T0_mean = np.mean(T0_all)
    T1_mean = np.mean(T1_all, axis=0)
    T2_mean = np.mean(T2_all, axis=0)

    semi_axes, eigvecs = calculate_semi_axes(T0_mean, T1_mean, T2_mean)

    # Diamètre moyen pondéré par le volume
    if volumes_all and diameters_nm:
        diameter_mean_nm_weighted = np.sum(np.array(diameters_nm) * np.array(volumes_all)) / np.sum(volumes_all)
        diameter_mean_px_weighted = diameter_mean_nm_weighted / RESOLUTION
    else:
        diameter_mean_nm_weighted = None
        diameter_mean_px_weighted = None

    # ------------------------------
    # Conversion pour 250×
    # ------------------------------
    magnification_ref = 15000
    magnification_target = 250
    scale = magnification_target / magnification_ref  # = 1/60

    # Nouvelle résolution en nm/px
    resolution_target = RESOLUTION / scale  # nm/px à 250×

    # Diamètre moyen pondéré en pixels à 250×
    diameter_mean_px_250 = diameter_mean_nm_weighted / resolution_target if diameter_mean_nm_weighted else None
    diameter_mean_nm_250 = diameter_mean_nm_weighted  # reste identique

    # Demi-axes en pixels à 15000× et 250×
    semi_axes_px_ref = semi_axes / RESOLUTION
    semi_axes_px_250 = semi_axes / resolution_target

    # ------------------------------
    # Affichage résultats
    # ------------------------------
    print("✅ Demi-axes moyens (nm) :", semi_axes)
    print("📏 Diamètre moyen pondéré (px @15000×) :", diameter_mean_px_weighted)
    print("📏 Diamètre moyen pondéré (nm @15000×) :", diameter_mean_nm_weighted)
    print("📏 Diamètre moyen pondéré (px @250×) :", diameter_mean_px_250)
    print("📏 Diamètre moyen pondéré (nm @250×) :", diameter_mean_nm_250)
    print("🔹 Semi-axes (px @15000×) :", semi_axes_px_ref)
    print("🔹 Semi-axes (px @250×) :", semi_axes_px_250)
else:
    semi_axes = None
    print("⚠️ Aucun objet > 200 nm trouvé.")


mean_results = {}
for label, vals in global_results.items():
    if len(vals["T0"]) == 0:
        mean_results[label] = {"T0": 0, "T1": np.zeros(3), "T2": np.zeros((3, 3))}
        continue
    
    T0s = np.array(vals["T0"])
    T1s = np.array(vals["T1"])
    T2s = np.array(vals["T2"])

    total_T0 = np.sum(T0s)
    mean_T0 = np.mean(T0s)  # ou bien total_T0 si tu veux représenter le volume global
    
    if total_T0 > 0:
        mean_T1 = np.sum(T1s * T0s[:, None], axis=0) / total_T0
        mean_T2 = np.sum(T2s * T0s[:, None, None], axis=0) / total_T0
    else:
        mean_T1 = np.zeros(3)
        mean_T2 = np.zeros((3, 3))
    
    mean_results[label] = {"T0": mean_T0, "T1": mean_T1, "T2": mean_T2}


from sklearn.cluster import KMeans
import numpy as np

# ============================
# KMeans sur intensité des pixels pour la classe 2
# ============================
gray_image = np.array(image.convert("L"))  # image en niveaux de gris

proportions_cluster_dark = []
proportions_cluster_bright = []

for idx in indices_2:
    mask = masks_all[idx].astype(bool)  # masque binaire de l'objet
    pixels = gray_image[mask]

    if pixels.size == 0:
        continue

    # Reshape en vecteur colonne pour KMeans
    pixels_reshaped = pixels.reshape(-1, 1)

    # Appliquer KMeans avec 2 clusters
    kmeans = KMeans(n_clusters=2, n_init=10, random_state=0)
    labels = kmeans.fit_predict(pixels_reshaped)

    # Moyenne d’intensité dans chaque cluster
    mean_intensity = [pixels[labels == c].mean() for c in range(2)]

    # Identifier cluster sombre / clair
    dark_cluster = np.argmin(mean_intensity)
    bright_cluster = np.argmax(mean_intensity)

    # Calcul proportion relative à chaque type (sombre / clair)
    dark_ratio = np.sum(labels == dark_cluster) / pixels.size * 100
    bright_ratio = np.sum(labels == bright_cluster) / pixels.size * 100

    proportions_cluster_dark.append(dark_ratio)
    proportions_cluster_bright.append(bright_ratio)

if proportions_cluster_dark and proportions_cluster_bright:
    mean_dark = np.mean(proportions_cluster_dark)
    mean_bright = np.mean(proportions_cluster_bright)
    print("\n=== KMeans intensité pixels pour la classe 2 ===")
    print(f"Proportion moyenne cluster sombre : {mean_dark:.2f} %")
    print(f"Proportion moyenne cluster clair  : {mean_bright:.2f} %")
else:
    print("\nAucun objet détecté pour la classe 2 (pas de KMeans possible).")



import os
import numpy as np
from PIL import Image

# --- Paramètres ---
folder = "chemin/vers/ton/dossier"  # <--- mets le chemin de ton dossier
extensions_valides = (".png", ".jpg", ".tif", ".bmp")

# --- Variables globales ---
total_pixels = 0
total_white = 0

# --- Parcours des fichiers ---
for filename in os.listdir(folder):
    if filename.lower().endswith(extensions_valides):
        path = os.path.join(folder, filename)
        
        # Charger l'image en niveaux de gris (déjà binaire)
        img = Image.open(path).convert("L")
        arr = np.array(img)

        # Ici, on suppose que blanc = 255 et noir = 0
        white_pixels = np.count_nonzero(arr == 255)
        black_pixels = np.count_nonzero(arr == 0)

        total_white += white_pixels
        total_pixels += white_pixels + black_pixels

# --- Calculs ---
total_black = total_pixels - total_white
prop_white = total_white / total_pixels
prop_black = total_black / total_pixels

print(f"Proportion de blanc : {prop_white:.2%}")
print(f"Proportion de noir  : {prop_black:.2%}")
