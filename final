import cv2
import numpy as np
from PIL import Image
from collections import defaultdict
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg

# ========================
# Fonction calcul T0 T1 T2
# ========================
def calc_tensors_from_mask(mask, d=5):
    mask = mask.astype(np.uint8)
    H, W = mask.shape
    ys, xs = np.nonzero(mask)
    if len(xs) == 0:
        return 0, np.zeros(3), np.zeros((3, 3))

    xO = xs.mean()
    yO = ys.mean()
    y_min = ys.min()
    y_max = ys.max()
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    contour_points = set(tuple(pt[0]) for c in contours for pt in c)

    T0 = 0.0
    T1 = np.zeros(3)
    T2 = np.zeros((3, 3))

    max_offset = max(yO - y_min, y_max - yO)
    max_steps = int(np.ceil(max_offset / d))
    y_offsets, directions = [], []

    for i in range(1, max_steps + 1):
        for sign in [1, -1]:
            y_candidate = int(round(yO + sign * i * d))
            if y_candidate < y_min or y_candidate > y_max:
                continue
            if i % 2 == 1:
                direction = 'right' if sign == 1 else 'left'
            else:
                direction = 'left' if sign == 1 else 'right'
            y_offsets.append(sign * i * d)
            directions.append(direction)

    for offset, direction in zip(y_offsets, directions):
        y = int(round(yO + offset))
        if y < 0 or y >= H:
            continue

        intersections = []
        if direction == 'right':
            for x in range(int(np.ceil(xO)) + 1, W):
                if (x, y) in contour_points:
                    intersections.append((x, y))
        else:
            for x in range(int(np.floor(xO)) - 1, -1, -1):
                if (x, y) in contour_points:
                    intersections.append((x, y))

        if not intersections:
            continue

        intersections_sorted = sorted(
            intersections,
            key=lambda p: np.hypot(p[0] - xO, p[1] - yO),
            reverse=True
        )

        sign = 1
        for (x_int, y_int) in intersections_sorted:
            xr = x_int - xO
            yr = y_int - yO
            g0 = np.pi * d * xr ** 2
            g1 = np.array([0, np.pi * d * xr ** 2 * yr, 0])
            g2 = np.array([
                [np.pi / 8 * d * xr ** 4, 0, 0],
                [0, np.pi / 2 * d * xr ** 2 * yr ** 2, 0],
                [0, 0, np.pi / 8 * d * xr ** 4]
            ])
            T0 += sign * g0
            T1 += sign * g1
            T2 += sign * g2
            sign *= -1

    return T0, T1, T2

def calculate_semi_axes(T0, T1, T2):
    """Calcule les longueurs des demi-axes √† partir des tenseurs centr√©s."""
    # 1. Centrage du tenseur T2 pour √©liminer l'effet de position
    T2_centered = T2 - np.outer(T1, T1) / (2 * T0)

    # 2. Diagonalisation
    eigenvalues, eigenvectors = np.linalg.eigh(T2_centered)

    # 3. Constante pour d=3
    kappa_3 = 4 * np.pi / 3
    factor = (2 * (3 + 2) / kappa_3) ** (1/(3 + 2))  # (10 / (4œÄ/3))^(1/5)

    # Valeurs propres tri√©es
    lambda1, lambda2, lambda3 = eigenvalues

    # Demi-axes
    a1 = factor * (lambda1 ** 0.4) / ((lambda2 * lambda3) ** 0.1)
    a2 = factor * (lambda2 ** 0.4) / ((lambda1 * lambda3) ** 0.1)
    a3 = factor * (lambda3 ** 0.4) / ((lambda1 * lambda2) ** 0.1)

    return np.array([a1, a2, a3]), eigenvectors

def extract_area(mask):
    return np.count_nonzero(mask)

def subclass_label(cls, part):
    return f"{cls}_{part}"

# ============================
# Param√®tres Detectron2 & data
# ============================
image_path = "chemin/vers/ton_image.png" 
config_path = "chemin/vers/config.yaml"
weights_path = "chemin/vers/model_final.pth"

patch_size = (512, 350)
resized_size = (512, 400)
overlap = 50

# Init mod√®le
cfg = get_cfg()
cfg.merge_from_file(config_path)
cfg.MODEL.WEIGHTS = weights_path
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)

# Variables d'accumulation
global_results = defaultdict(lambda: {"T0": [], "T1": [], "T2": []})
count_per_class = defaultdict(int)
count_subclass = defaultdict(int)
area_per_class = defaultdict(int)
area_subclass = defaultdict(int)

# === Lecture image ===
image = Image.open(image_path).convert("RGB")
width, height = image.size

# Cartes pour fusion
class_map = np.full((height, width), fill_value=255, dtype=np.uint8)
score_map = np.zeros((height, width), dtype=np.float32)
masks_all = []
pred_classes_all = []

pw, ph = patch_size
for y in range(0, height, ph - overlap):
    for x in range(0, width, pw - overlap):
        crop_w = min(pw + (overlap if x + pw < width else 0), width - x)
        crop_h = min(ph + (overlap if y + ph < height else 0), height - y)

        patch = image.crop((x, y, x + crop_w, y + crop_h)).resize(resized_size)
        patch_np = np.array(patch)

        outputs = predictor(patch_np)
        instances = outputs["instances"].to("cpu")

        for i in range(len(instances)):
            class_id = int(instances.pred_classes[i])
            score = float(instances.scores[i])
            mask = instances.pred_masks[i].numpy().astype(np.uint8) * 255
            mask_resized = cv2.resize(mask, (crop_w, crop_h), interpolation=cv2.INTER_NEAREST)

            y1, y2 = y, y + crop_h
            x1, x2 = x, x + crop_w
            mask_pixels = mask_resized > 127
            update_pixels = mask_pixels & (score > score_map[y1:y2, x1:x2])

            class_map[y1:y2, x1:x2][update_pixels] = class_id
            score_map[y1:y2, x1:x2][update_pixels] = score

            full_mask = np.zeros((height, width), dtype=np.uint8)
            full_mask[y1:y2, x1:x2][mask_pixels] = 1
            masks_all.append(full_mask)
            pred_classes_all.append(class_id)

# ==== Calcul T0/T1/T2 par classe et sous-classe ====
indices_0 = [i for i, c in enumerate(pred_classes_all) if c == 0]
indices_1 = [i for i, c in enumerate(pred_classes_all) if c == 1]
indices_2 = [i for i, c in enumerate(pred_classes_all) if c == 2]

areas_0 = np.array([extract_area(masks_all[i]) for i in indices_0])
areas_1 = np.array([extract_area(masks_all[i]) for i in indices_1])

median_0 = np.median(areas_0) if len(areas_0) > 0 else 0
median_1 = np.median(areas_1) if len(areas_1) > 0 else 0

# Classe 0
for i, idx in enumerate(indices_0):
    part = 1 if areas_0[i] <= median_0 else 2
    label = subclass_label(0, part)
    T0, T1, T2 = calc_tensors_from_mask(masks_all[idx])
    global_results[label]["T0"].append(T0)
    global_results[label]["T1"].append(T1)
    global_results[label]["T2"].append(T2)
    area_per_class[0] += areas_0[i]
    area_subclass[label] += areas_0[i]
    count_per_class[0] += 1
    count_subclass[label] += 1

# Classe 1
for i, idx in enumerate(indices_1):
    part = 1 if areas_1[i] <= median_1 else 2
    label = subclass_label(1, part)
    T0, T1, T2 = calc_tensors_from_mask(masks_all[idx])
    global_results[label]["T0"].append(T0)
    global_results[label]["T1"].append(T1)
    global_results[label]["T2"].append(T2)
    area_per_class[1] += areas_1[i]
    area_subclass[label] += areas_1[i]
    count_per_class[1] += 1
    count_subclass[label] += 1

# Classe 2
for idx in indices_2:
    label = "2"
    T0, T1, T2 = calc_tensors_from_mask(masks_all[idx])
    global_results[label]["T0"].append(T0)
    global_results[label]["T1"].append(T1)
    global_results[label]["T2"].append(T2)
    area = extract_area(masks_all[idx])
    area_per_class[2] += area
    area_subclass[label] += area
    count_per_class[2] += 1

# ============================
# Moyennes finales et pourcentages
# ============================
mean_results = {
    label: {
        "T0": np.mean(vals["T0"]) if vals["T0"] else 0,
        "T1": np.mean(vals["T1"], axis=0) if vals["T1"] else np.zeros(3),
        "T2": np.mean(vals["T2"], axis=0) if vals["T2"] else np.zeros((3, 3))
    }
    for label, vals in global_results.items()
}
for label in mean_results:
    T0 = mean_results[label]["T0"]
    T1 = mean_results[label]["T1"]
    T2 = mean_results[label]["T2"]
    
    # Calcul des semi-axes pour cette classe
    semi_axes, eigenvectors = calculate_semi_axes(T0, T1, T2)
    
    # Ajout des r√©sultats
    mean_results[label]["semi_axes"] = semi_axes
    mean_results[label]["eigenvectors"] = eigenvectors
    
percentages = {}
if count_per_class[0] > 0:
    percentages["0_1"] = 100 * count_subclass["0_1"] / count_per_class[0]
    percentages["0_2"] = 100 * count_subclass["0_2"] / count_per_class[0]
if count_per_class[1] > 0:
    percentages["1_1"] = 100 * count_subclass["1_1"] / count_per_class[1]
    percentages["1_2"] = 100 * count_subclass["1_2"] / count_per_class[1]

percentages_area = {}
if area_per_class[0] > 0:
    percentages_area["0_1"] = 100 * area_subclass["0_1"] / area_per_class[0]
    percentages_area["0_2"] = 100 * area_subclass["0_2"] / area_per_class[0]
if area_per_class[1] > 0:
    percentages_area["1_1"] = 100 * area_subclass["1_1"] / area_per_class[1]
    percentages_area["1_2"] = 100 * area_subclass["1_2"] / area_per_class[1]


print("=== Moyennes T0/T1/T2 et semi-axes calcul√©s par classe ===")
for label, vals in mean_results.items():
    print(f"\nClasse {label}:")
    print(f"T0 moyen: {vals['T0']}")
    print(f"T1 moyen: {vals['T1']}")
    print(f"T2 moyen:\n{vals['T2']}")
    print(f"Demi-axes calcul√©s: {vals['semi_axes']}")
    print(f"Directions principales:\n{vals['eigenvectors']}")

print("\n=== Pourcentages par sous-classe (nombre d'objets) ===")
for label, perc in percentages.items():
    print(f"{label}: {perc:.2f} %")

print("\n=== Pourcentages par surface occup√©e ===")
for label, perc in percentages_area.items():
    print(f"{label}: {perc:.2f} %")



################################################

# ============================
# Moyennes finales et calcul des semi-axes
# ============================
mean_results = {
    label: {
        "T0": np.mean(vals["T0"]) if vals["T0"] else 0,
        "T1": np.mean(vals["T1"], axis=0) if vals["T1"] else np.zeros(3),
        "T2": np.mean(vals["T2"], axis=0) if vals["T2"] else np.zeros((3, 3)),
        # Suppression des moyennes de semi-axes existantes
    }
    for label, vals in global_results.items()
}

# Calcul des semi-axes √† partir des tenseurs moyens
for label in mean_results:
    T0 = mean_results[label]["T0"]
    T1 = mean_results[label]["T1"]
    T2 = mean_results[label]["T2"]
    
    # Calcul des semi-axes pour cette classe
    semi_axes, eigenvectors = calculate_semi_axes(T0, T1, T2)
    
    # Ajout des r√©sultats
    mean_results[label]["semi_axes"] = semi_axes
    mean_results[label]["eigenvectors"] = eigenvectors

# Le reste du code (pourcentages etc.) reste inchang√©
percentages = {}
if count_per_class[0] > 0:
    percentages["0_1"] = 100 * count_subclass["0_1"] / count_per_class[0]
    percentages["0_2"] = 100 * count_subclass["0_2"] / count_per_class[0]
if count_per_class[1] > 0:
    percentages["1_1"] = 100 * count_subclass["1_1"] / count_per_class[1]
    percentages["1_2"] = 100 * count_subclass["1_2"] / count_per_class[1]

percentages_area = {}
if area_per_class[0] > 0:
    percentages_area["0_1"] = 100 * area_subclass["0_1"] / area_per_class[0]
    percentages_area["0_2"] = 100 * area_subclass["0_2"] / area_per_class[0]
if area_per_class[1] > 0:
    percentages_area["1_1"] = 100 * area_subclass["1_1"] / area_per_class[1]
    percentages_area["1_2"] = 100 * area_subclass["1_2"] / area_per_class[1]

print("=== Moyennes T0/T1/T2 et semi-axes calcul√©s par classe ===")
for label, vals in mean_results.items():
    print(f"\nClasse {label}:")
    print(f"T0 moyen: {vals['T0']}")
    print(f"T1 moyen: {vals['T1']}")
    print(f"T2 moyen:\n{vals['T2']}")
    print(f"Demi-axes calcul√©s: {vals['semi_axes']}")
    print(f"Directions principales:\n{vals['eigenvectors']}")

print("\n=== Pourcentages par sous-classe (nombre d'objets) ===")
for label, perc in percentages.items():
    print(f"{label}: {perc:.2f} %")

print("\n=== Pourcentages par surface occup√©e ===")
for label, perc in percentages_area.items():
    print(f"{label}: {perc:.2f} %")


# ============================
# Volume par classe et calcul du cube
# ============================

# Volume total par classe (somme des T0)
volume_par_classe = {cid: 0.0 for cid in [0, 1, 2]}
for label, vals in global_results.items():
    if label.startswith("0"):
        volume_par_classe[0] += sum(vals["T0"])
    elif label.startswith("1"):
        volume_par_classe[1] += sum(vals["T0"])
    elif label == "2":
        volume_par_classe[2] += sum(vals["T0"])

# Fractions en d√©cimal (par ex. fractions = {0: 30, 1: 50, 2: 20})
fractions = {0: 30, 1: 50, 2: 20}  # <-- √† adapter selon ton cas
fractions_decimales = {cid: fractions[cid] / 100 for cid in [0, 1, 2]}

# Calcul du volume du cube estim√©
Vcube = 0
for cid in [0, 1, 2]:
    f = fractions_decimales[cid]
    v = volume_par_classe[cid]
    if f > 0:
        Vcube += v / f

# Longueur caract√©ristique
if Vcube > 0:
    L = Vcube ** (1 / 3)
    print(f"\n=== Estimation du volume global ===")
    print(f"Volume du cube estim√© : Vcube ‚âà {Vcube:.2f} px¬≥")
    print(f"Longueur caract√©ristique (L) ‚âà {L:.2f} px")
else:
    print("\nImpossible de calculer Vcube (aucune fraction d√©tect√©e).")



from sklearn.cluster import KMeans

# ============================
# KMeans sur intensit√© des pixels pour la classe 2
# ============================
gray_image = np.array(image.convert("L"))  # image en niveaux de gris

proportions_cluster0 = []
proportions_cluster1 = []

for idx in indices_2:
    mask = masks_all[idx].astype(bool)  # masque binaire de l'objet
    pixels = gray_image[mask]

    if pixels.size == 0:
        continue

    # Reshape en vecteur colonne pour KMeans
    pixels_reshaped = pixels.reshape(-1, 1)

    # Appliquer KMeans avec 2 clusters
    kmeans = KMeans(n_clusters=2, n_init=10, random_state=0)
    labels = kmeans.fit_predict(pixels_reshaped)

    # Calcul proportion de chaque cluster
    cluster0_ratio = np.sum(labels == 0) / pixels.size * 100
    cluster1_ratio = np.sum(labels == 1) / pixels.size * 100

    proportions_cluster0.append(cluster0_ratio)
    proportions_cluster1.append(cluster1_ratio)

if proportions_cluster0 and proportions_cluster1:
    mean_cluster0 = np.mean(proportions_cluster0)
    mean_cluster1 = np.mean(proportions_cluster1)
    print("\n=== KMeans intensit√© pixels pour la classe 2 ===")
    print(f"Proportion moyenne cluster 0 : {mean_cluster0:.2f} %")
    print(f"Proportion moyenne cluster 1 : {mean_cluster1:.2f} %")
else:
    print("\nAucun objet d√©tect√© pour la classe 2 (pas de KMeans possible).")


import matplotlib.pyplot as plt

# ============================
# Visualisation objets classe 2 avec clusters KMeans color√©s
# ============================

gray_image = np.array(image.convert("L"))  # image en niveaux de gris

for obj_id, idx in enumerate(indices_2, start=1):
    mask = masks_all[idx].astype(bool)  # masque binaire de l'objet
    pixels = gray_image[mask]

    if pixels.size == 0:
        continue

    # Reshape en vecteur colonne pour KMeans
    pixels_reshaped = pixels.reshape(-1, 1)

    # Appliquer KMeans avec 2 clusters
    kmeans = KMeans(n_clusters=2, n_init=10, random_state=0)
    labels = kmeans.fit_predict(pixels_reshaped)

    # Trier clusters par intensit√© (0 = sombre, 1 = clair)
    centers = kmeans.cluster_centers_.flatten()
    order = np.argsort(centers)  
    labels_sorted = np.array([order[label] for label in labels])

    # Cr√©er une image RGB pour visualisation
    cluster_img = np.zeros((*mask.shape, 3), dtype=np.uint8)

    # Colorier chaque cluster (0 = rouge, 1 = bleu)
    cluster_img[mask] = np.where(
        labels_sorted[:, None] == 0,
        [255, 0, 0],   # rouge
        [0, 0, 255]    # bleu
    )

    # Afficher l'objet
    plt.figure(figsize=(4, 4))
    plt.imshow(cluster_img)
    plt.title(f"Objet {obj_id} (classe 2)")
    plt.axis("off")
    plt.show()


import os
import cv2
import numpy as np
from skimage.measure import regionprops, label
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo


def calc_tensors_from_mask(mask, d=5):
    mask = mask.astype(np.uint8)
    H, W = mask.shape
    ys, xs = np.nonzero(mask)
    if len(xs) == 0:
        return 0, np.zeros(3), np.zeros((3, 3))

    xO = xs.mean()
    yO = ys.mean()
    y_min = ys.min()
    y_max = ys.max()
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    contour_points = set(tuple(pt[0]) for c in contours for pt in c)

    T0 = 0.0
    T1 = np.zeros(3)
    T2 = np.zeros((3, 3))

    max_offset = max(yO - y_min, y_max - yO)
    max_steps = int(np.ceil(max_offset / d))
    y_offsets, directions = [], []

    for i in range(1, max_steps + 1):
        for sign in [1, -1]:
            y_candidate = int(round(yO + sign * i * d))
            if y_candidate < y_min or y_candidate > y_max:
                continue
            if i % 2 == 1:
                direction = 'right' if sign == 1 else 'left'
            else:
                direction = 'left' if sign == 1 else 'right'
            y_offsets.append(sign * i * d)
            directions.append(direction)

    for offset, direction in zip(y_offsets, directions):
        y = int(round(yO + offset))
        if y < 0 or y >= H:
            continue

        intersections = []
        if direction == 'right':
            for x in range(int(np.ceil(xO)) + 1, W):
                if (x, y) in contour_points:
                    intersections.append((x, y))
        else:
            for x in range(int(np.floor(xO)) - 1, -1, -1):
                if (x, y) in contour_points:
                    intersections.append((x, y))

        if not intersections:
            continue

        intersections_sorted = sorted(
            intersections,
            key=lambda p: np.hypot(p[0] - xO, p[1] - yO),
            reverse=True
        )

        sign = 1
        for (x_int, y_int) in intersections_sorted:
            xr = x_int - xO
            yr = y_int - yO
            g0 = np.pi * d * xr ** 2
            g1 = np.array([0, np.pi * d * xr ** 2 * yr, 0])
            g2 = np.array([
                [np.pi / 8 * d * xr ** 4, 0, 0],
                [0, np.pi / 2 * d * xr ** 2 * yr ** 2, 0],
                [0, 0, np.pi / 8 * d * xr ** 4]
            ])
            T0 += sign * g0
            T1 += sign * g1
            T2 += sign * g2
            sign *= -1

    return T0, T1, T2


def calculate_semi_axes(T0, T1, T2):
    T2_centered = T2 - np.outer(T1, T1) / (2 * T0)
    eigenvalues, eigenvectors = np.linalg.eigh(T2_centered)

    kappa_3 = 4 * np.pi / 3
    factor = (2 * (3 + 2) / kappa_3) ** (1/(3 + 2))

    lambda1, lambda2, lambda3 = eigenvalues
    a1 = factor * (lambda1 ** 0.4) / ((lambda2 * lambda3) ** 0.1)
    a2 = factor * (lambda2 ** 0.4) / ((lambda1 * lambda3) ** 0.1)
    a3 = factor * (lambda3 ** 0.4) / ((lambda1 * lambda2) ** 0.1)

    return np.array([a1, a2, a3]), eigenvectors



IMAGE_FOLDER = "images_input"
MODEL_CONFIG = "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"
MODEL_WEIGHTS = "model_final.pth" 
RESOLUTION = 7.443  # nm/pixel
DIAMETER_THRESHOLD = 200  # nm

# ========================
# Initialisation Detectron2
# ========================
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(MODEL_CONFIG))
cfg.MODEL.WEIGHTS = MODEL_WEIGHTS
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)

# ========================
# Accumulateurs globaux
# ========================
T0_all, T1_all, T2_all = [], [], []
diameters_px, diameters_nm = [], []

# ========================
# Parcours des images
# ========================
for fname in os.listdir(IMAGE_FOLDER):
    if not fname.lower().endswith((".png", ".jpg", ".jpeg", ".tif", ".tiff")):
        continue

    image_path = os.path.join(IMAGE_FOLDER, fname)
    image = cv2.imread(image_path)

    outputs = predictor(image)
    instances = outputs["instances"].to("cpu")
    masks = instances.pred_masks.numpy()

    for mask in masks:
        # Calculer diam√®tre avec regionprops
        labeled_mask = label(mask)
        props = regionprops(labeled_mask)
        if not props:
            continue

        diameter_px = props[0].equivalent_diameter
        diameter_nm = diameter_px * RESOLUTION

        diameters_px.append(diameter_px)
        diameters_nm.append(diameter_nm)

        if diameter_nm > DIAMETER_THRESHOLD:
            T0, T1, T2 = calc_tensors_from_mask(mask)
            T0_all.append(T0)
            T1_all.append(T1)
            T2_all.append(T2)

# ========================
# Moyennes globales
# ========================
if len(T0_all) > 0:
    T0_mean = np.mean(T0_all)
    T1_mean = np.mean(T1_all, axis=0)
    T2_mean = np.mean(T2_all, axis=0)

    semi_axes, eigvecs = calculate_semi_axes(T0_mean, T1_mean, T2_mean)

    diameter_mean_px = np.mean(diameters_px) if diameters_px else None
    diameter_mean_nm = np.mean(diameters_nm) if diameters_nm else None

    print("‚úÖ Demi-axes moyens :", semi_axes)
    print("üìè Diam√®tre moyen (px) :", diameter_mean_px)
    print("üìè Diam√®tre moyen (nm) :", diameter_mean_nm)
else:
    semi_axes = None
    print("‚ö†Ô∏è Aucun objet > 200 nm trouv√©.")


if len(T0_all) > 0:
    T0_mean = np.mean(T0_all)
    T1_mean = np.mean(T1_all, axis=0)
    T2_mean = np.mean(T2_all, axis=0)

    semi_axes_px, eigvecs = calculate_semi_axes(T0_mean, T1_mean, T2_mean)
    semi_axes_nm = semi_axes_px * RESOLUTION  # conversion en nm

    diameter_mean_px = np.mean(diameters_px) if diameters_px else None
    diameter_mean_nm = np.mean(diameters_nm) if diameters_nm else None

    # ------------------------------
    # Conversion pour 250√ó
    # ------------------------------
    magnification_ref = 15000
    magnification_target = 250
    scale = magnification_target / magnification_ref  # = 1/60

    # Nouvelle r√©solution en nm/px
    resolution_ref = RESOLUTION  # nm/px √† 15000√ó
    resolution_target = resolution_ref / scale  # nm/px √† 250√ó

    # Diam√®tre moyen en pixels √† 250√ó
    diameter_mean_px_250 = diameter_mean_px * scale if diameter_mean_px else None
    # Diam√®tre moyen en nm ne change pas
    diameter_mean_nm_250 = diameter_mean_nm  

    # Semi-axes en pixels √† 250√ó
    semi_axes_px_250 = semi_axes_px * scale
    # Semi-axes en nm restent identiques
    semi_axes_nm_250 = semi_axes_nm  

    # ------------------------------
    # Affichage r√©sultats
    # ------------------------------
    print("‚úÖ Demi-axes moyens (px @15000√ó) :", semi_axes_px)
    print("‚úÖ Demi-axes moyens (nm @15000√ó) :", semi_axes_nm)
    print("üìè Diam√®tre moyen (px @15000√ó) :", diameter_mean_px)
    print("üìè Diam√®tre moyen (nm @15000√ó) :", diameter_mean_nm)

    print("üìè Diam√®tre moyen (px @250√ó) :", diameter_mean_px_250)
    print("üìè Diam√®tre moyen (nm @250√ó) :", diameter_mean_nm_250)
    print("üîπ Semi-axes (px @250√ó) :", semi_axes_px_250)
    print("üîπ Semi-axes (nm @250√ó) :", semi_axes_nm_250)

else:
    semi_axes = None
    print("‚ö†Ô∏è Aucun objet > 200 nm trouv√©.")


Dans ce contexte en pleine √©volution technologique, l‚Äôalternance s‚Äôest d√©roul√©e au sein de l‚Äôentreprise IFP √ânergies nouvelles. Faisant partie de la Direction Physique et Analyses, plus pr√©cis√©ment dans le d√©partement Caract√©risation des Mat√©riaux, les projets avaient pour objectif le d√©veloppement de mod√®les d‚Äôintelligence artificielle appliqu√©s aux donn√©es de microscopie pour √©tudier les mat√©riaux. L‚Äôalternance s‚Äôest articul√©e autour de quatre projets principaux. Dans un premier temps, l‚Äôobjectif √©tait de d√©velopper un mod√®le de segmentation d'instance permettant la d√©tection des √©l√©ments de platine pr√©sents dans les images issues du microscope √©lectronique √† transmission √† balayage en champ sombre annulaire √† grand angle. Dans un second temps, le but √©tait de concevoir un mod√®le capable d‚Äôidentifier les phases actives catalytiques sous forme de feuillets d√©pos√©s sur un support de catalyseur de type alumine. Ensuite, l‚Äôobjectif du troisi√®me projet √©tait de d√©velopper un syst√®me de d√©tection automatique des pics dans les donn√©es de chromatographie en phase gazeuse, et de pouvoir ensuite attribuer √† chaque pic le nom du compos√© correspondant. Enfin, la finalit√© du quatri√®me projet √©tait, d‚Äôune part, de d√©velopper un mod√®le de segmentation capable de d√©tecter trois classes diff√©rentes dans les images √† faible grandissement (les zones denses, les zones creuses et les zones interm√©diaires), et, d‚Äôautre part, de concevoir un mod√®le capable de d√©tecter des cristaux dans les images √† fort grandissement. Il s‚Äôagissait ensuite, √† partir des diff√©rents param√®tres et statistiques extraits par ces deux mod√®les, d‚Äôutiliser un mod√®le de g√©n√©ration 3D bool√©en pour produire une microstructure 3D refl√©tant les diff√©rentes h√©t√©rog√©n√©it√©s des mat√©riaux.

Ce rapport est structur√© en quatre parties : la premi√®re est consacr√©e √† la pr√©sentation de l‚Äôentreprise, aborde √©galement la demande initiale de l‚Äôalternance et examine l‚Äô√©tat de l‚Äô√©galit√© femmes-hommes au sein de l‚Äôentreprise ; la deuxi√®me pr√©sente le contexte et les enjeux du projet ; la troisi√®me d√©taille la m√©thodologie et les travaux r√©alis√©s ; et la quatri√®me conclut le rapport en r√©sumant le travail r√©alis√© durant cette ann√©e d‚Äôalternance. Cette section met en lumi√®re les accomplissements, les d√©fis rencontr√©s, les r√©sultats obtenus, ainsi que les perspectives futures.


# === Cr√©ation du masque global (si besoin de visualiser) ===
zone_mask = np.zeros((height, width), dtype=np.uint8)
for poly in all_polygons:
    cv2.fillPoly(zone_mask, [np.array(poly, dtype=np.int32)], 255)

# === Calcul du volume total √† partir de tous les polygones ===
volume_bille = 0.0
for poly in all_polygons:
    mask_poly = np.zeros((height, width), dtype=np.uint8)
    cv2.fillPoly(mask_poly, [np.array(poly, dtype=np.int32)], 1)

    # Appel √† ta fonction existante
    T0, T1, T2 = calc_tensors_from_mask(mask_poly)

    # Ici on prend T0 comme volume
    volume_bille += T0

print(f"\nVolume total des polygones dessin√©s : {volume_bille}")

fraction_volumique = {cid: volume_par_classe[cid] / volume_bille for cid in volume_par_classe}

print("\n=== Fractions volumiques par classe ===")
for cid, frac in fraction_volumique.items():
    print(f"Classe {cid}: {frac:.6f}")


# ========================
# Accumulateurs globaux
# ========================
T0_all, T1_all, T2_all = [], [], []
diameters_px, diameters_nm = [], []
volumes_all = []

# ========================
# Parcours des images
# ========================
for fname in os.listdir(IMAGE_FOLDER): 
    if not fname.lower().endswith((".png", ".jpg", ".jpeg", ".tif", ".tiff")):
        continue

    image_path = os.path.join(IMAGE_FOLDER, fname)
    image = cv2.imread(image_path)

    outputs = predictor(image)
    instances = outputs["instances"].to("cpu")
    masks = instances.pred_masks.numpy()

    for mask in masks:
        # Calculer diam√®tre avec regionprops
        labeled_mask = label(mask)
        props = regionprops(labeled_mask)
        if not props:
            continue

        diameter_px = props[0].equivalent_diameter
        diameter_nm = diameter_px * RESOLUTION

        diameters_px.append(diameter_px)
        diameters_nm.append(diameter_nm)

        if diameter_nm > DIAMETER_THRESHOLD:
            T0, T1, T2 = calc_tensors_from_mask(mask)
            T0_all.append(T0)
            T1_all.append(T1)
            T2_all.append(T2)
            volumes_all.append(T0)  # volume pond√©ration

# ========================
# Moyennes globales
# ========================
if len(T0_all) > 0:
    T0_mean = np.mean(T0_all)
    T1_mean = np.mean(T1_all, axis=0)
    T2_mean = np.mean(T2_all, axis=0)

    semi_axes, eigvecs = calculate_semi_axes(T0_mean, T1_mean, T2_mean)

    # Diam√®tre moyen pond√©r√© par le volume
    if volumes_all and diameters_nm:
        diameter_mean_nm_weighted = np.sum(np.array(diameters_nm) * np.array(volumes_all)) / np.sum(volumes_all)
        diameter_mean_px_weighted = diameter_mean_nm_weighted / RESOLUTION
    else:
        diameter_mean_nm_weighted = None
        diameter_mean_px_weighted = None

    # ------------------------------
    # Conversion pour 250√ó
    # ------------------------------
    magnification_ref = 15000
    magnification_target = 250
    scale = magnification_target / magnification_ref  # = 1/60

    # Nouvelle r√©solution en nm/px
    resolution_target = RESOLUTION / scale  # nm/px √† 250√ó

    # Diam√®tre moyen pond√©r√© en pixels √† 250√ó
    diameter_mean_px_250 = diameter_mean_nm_weighted / resolution_target if diameter_mean_nm_weighted else None
    diameter_mean_nm_250 = diameter_mean_nm_weighted  # reste identique

    # Demi-axes en pixels √† 15000√ó et 250√ó
    semi_axes_px_ref = semi_axes / RESOLUTION
    semi_axes_px_250 = semi_axes / resolution_target

    # ------------------------------
    # Affichage r√©sultats
    # ------------------------------
    print("‚úÖ Demi-axes moyens (nm) :", semi_axes)
    print("üìè Diam√®tre moyen pond√©r√© (px @15000√ó) :", diameter_mean_px_weighted)
    print("üìè Diam√®tre moyen pond√©r√© (nm @15000√ó) :", diameter_mean_nm_weighted)
    print("üìè Diam√®tre moyen pond√©r√© (px @250√ó) :", diameter_mean_px_250)
    print("üìè Diam√®tre moyen pond√©r√© (nm @250√ó) :", diameter_mean_nm_250)
    print("üîπ Semi-axes (px @15000√ó) :", semi_axes_px_ref)
    print("üîπ Semi-axes (px @250√ó) :", semi_axes_px_250)
else:
    semi_axes = None
    print("‚ö†Ô∏è Aucun objet > 200 nm trouv√©.")


mean_results = {}
for label, vals in global_results.items():
    if len(vals["T0"]) == 0:
        mean_results[label] = {"T0": 0, "T1": np.zeros(3), "T2": np.zeros((3, 3))}
        continue
    
    T0s = np.array(vals["T0"])
    T1s = np.array(vals["T1"])
    T2s = np.array(vals["T2"])

    total_T0 = np.sum(T0s)
    mean_T0 = np.mean(T0s)  # ou bien total_T0 si tu veux repr√©senter le volume global
    
    if total_T0 > 0:
        mean_T1 = np.sum(T1s * T0s[:, None], axis=0) / total_T0
        mean_T2 = np.sum(T2s * T0s[:, None, None], axis=0) / total_T0
    else:
        mean_T1 = np.zeros(3)
        mean_T2 = np.zeros((3, 3))
    
    mean_results[label] = {"T0": mean_T0, "T1": mean_T1, "T2": mean_T2}


from sklearn.cluster import KMeans
import numpy as np

# ============================
# KMeans sur intensit√© des pixels pour la classe 2
# ============================
gray_image = np.array(image.convert("L"))  # image en niveaux de gris

proportions_cluster_dark = []
proportions_cluster_bright = []

for idx in indices_2:
    mask = masks_all[idx].astype(bool)  # masque binaire de l'objet
    pixels = gray_image[mask]

    if pixels.size == 0:
        continue

    # Reshape en vecteur colonne pour KMeans
    pixels_reshaped = pixels.reshape(-1, 1)

    # Appliquer KMeans avec 2 clusters
    kmeans = KMeans(n_clusters=2, n_init=10, random_state=0)
    labels = kmeans.fit_predict(pixels_reshaped)

    # Moyenne d‚Äôintensit√© dans chaque cluster
    mean_intensity = [pixels[labels == c].mean() for c in range(2)]

    # Identifier cluster sombre / clair
    dark_cluster = np.argmin(mean_intensity)
    bright_cluster = np.argmax(mean_intensity)

    # Calcul proportion relative √† chaque type (sombre / clair)
    dark_ratio = np.sum(labels == dark_cluster) / pixels.size * 100
    bright_ratio = np.sum(labels == bright_cluster) / pixels.size * 100

    proportions_cluster_dark.append(dark_ratio)
    proportions_cluster_bright.append(bright_ratio)

if proportions_cluster_dark and proportions_cluster_bright:
    mean_dark = np.mean(proportions_cluster_dark)
    mean_bright = np.mean(proportions_cluster_bright)
    print("\n=== KMeans intensit√© pixels pour la classe 2 ===")
    print(f"Proportion moyenne cluster sombre : {mean_dark:.2f} %")
    print(f"Proportion moyenne cluster clair  : {mean_bright:.2f} %")
else:
    print("\nAucun objet d√©tect√© pour la classe 2 (pas de KMeans possible).")



import os
import numpy as np
from PIL import Image

# --- Param√®tres ---
folder = "chemin/vers/ton/dossier"  # <--- mets le chemin de ton dossier
extensions_valides = (".png", ".jpg", ".tif", ".bmp")

# --- Variables globales ---
total_pixels = 0
total_white = 0

# --- Parcours des fichiers ---
for filename in os.listdir(folder):
    if filename.lower().endswith(extensions_valides):
        path = os.path.join(folder, filename)
        
        # Charger l'image en niveaux de gris (d√©j√† binaire)
        img = Image.open(path).convert("L")
        arr = np.array(img)

        # Ici, on suppose que blanc = 255 et noir = 0
        white_pixels = np.count_nonzero(arr == 255)
        black_pixels = np.count_nonzero(arr == 0)

        total_white += white_pixels
        total_pixels += white_pixels + black_pixels

# --- Calculs ---
total_black = total_pixels - total_white
prop_white = total_white / total_pixels
prop_black = total_black / total_pixels

print(f"Proportion de blanc : {prop_white:.2%}")
print(f"Proportion de noir  : {prop_black:.2%}")
