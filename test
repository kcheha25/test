import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()
import numpy as np
import os, json, cv2, random
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog
from matplotlib import pyplot as plt
import torch
import distutils.core
from detectron2.engine import DefaultTrainer
import argparse

# Argument parsing
parser = argparse.ArgumentParser(description="Detectron2 Training Script")
parser.add_argument("--data-path", type=str, required=True, help="Path to the dataset")
parser.add_argument("--solver-ims-per-batch", type=int, default=4, help="Number of images per batch")
parser.add_argument("--solver-base-lr", type=float, default=0.001, help="Base learning rate")
parser.add_argument("--solver-max-iter", type=int, default=5000, help="Max iterations")
parser.add_argument("--solver-checkpoint-period", type=int, default=1000, help="Checkpoint period")
parser.add_argument("--num-classes", type=int, default=1, help="Number of classes")
args = parser.parse_args()

# Setup paths based on the argument
train_annotations = os.path.join(args.data_path, "train/_annotations.coco.json")
val_annotations = os.path.join(args.data_path, "valid/_annotations.coco.json")
test_annotations = os.path.join(args.data_path, "test/_annotations.coco.json")
train_images = os.path.join(args.data_path, "train")
val_images = os.path.join(args.data_path, "valid")
test_images = os.path.join(args.data_path, "test")

# Enregistrement des instances COCO pour les ensembles d'entraînement, de validation et de test
register_coco_instances("my_dataset_train", {}, train_annotations, train_images)
register_coco_instances("my_dataset_val", {}, val_annotations, val_images)
register_coco_instances("my_dataset_test", {}, test_annotations, test_images)

# Obtention des métadonnées et des ensembles de données
test_metadata = MetadataCatalog.get("my_dataset_test")
test_dataset_dicts = DatasetCatalog.get("my_dataset_test")
train_metadata = MetadataCatalog.get("my_dataset_train")
train_dataset_dicts = DatasetCatalog.get("my_dataset_train")
val_metadata = MetadataCatalog.get("my_dataset_val")
val_dataset_dicts = DatasetCatalog.get("my_dataset_val")

# Affichage de deux images aléatoires de l'ensemble d'entraînement avec leurs annotations
for d in random.sample(train_dataset_dicts, 2):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)
    vis = visualizer.draw_dataset_dict(d)
    plt.imshow(vis.get_image()[:, :, ::-1])
    plt.show()

# Définition d'une classe CocoTrainer qui hérite de DefaultTrainer
class CocoTrainer(DefaultTrainer):
    @classmethod
    def build_evaluator(cls, cfg, dataset_name, output_folder=None):
        if output_folder is None:
            os.makedirs("coco_eval", exist_ok=True)
            output_folder = "coco_eval"
        return COCOEvaluator(dataset_name, cfg, False, output_folder)

# Obtention de la configuration par défaut de Detectron2
cfg = get_cfg()

# Définition du périphérique
cfg.MODEL.DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# Définition du répertoire de sortie
cfg.OUTPUT_DIR = "data/projet_m1/models/Detectron2_Models7"

# Fusion des paramètres de configuration du modèle à partir du fichier YAML
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("my_dataset_train",)
cfg.DATASETS.TEST = ("my_dataset_val",)
cfg.DATALOADER.NUM_WORKERS = 0
cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False
cfg.MODEL.MASK_ON = True
cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION = 20
cfg.MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION = 20
cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[8], [16], [32], [64], [128]]
cfg.MODEL.ROI_HEADS.POSITIVE_FRACTION = 0.5
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml")

# Paramètres pris en argument
cfg.SOLVER.IMS_PER_BATCH = args.solver_ims_per_batch
cfg.SOLVER.BASE_LR = args.solver_base_lr
cfg.SOLVER.MAX_ITER = args.solver_max_iter
cfg.SOLVER.CHECKPOINT_PERIOD = args.solver_checkpoint_period

# Autres configurations
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512
cfg.MODEL.ROI_HEADS.NUM_CLASSES = args.num_classes
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2
cfg.TEST.PRECISE_BN.ENABLED = True
cfg.TEST.PRECISE_BN.NUM_ITER = 1000
cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.6
cfg.TEST.DETECTIONS_PER_IMAGE = 1000
cfg.TEST.EVAL_PERIOD = 159

# Création du répertoire de sortie et de l'entraîneur
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = CocoTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

python script.py --data-path "/path/to/dataset" --solver-ims-per-batch 8 --solver-base-lr 0.002 --solver-max-iter 6000 --solver-checkpoint-period 500 --num-classes 2
