import torch
import numpy as np
import cv2
import matplotlib.pyplot as plt
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo
from detectron2.utils.visualizer import Visualizer
from detectron2.structures import Instances
from sklearn.cluster import DBSCAN

# Chargement du modèle Detectron2
def setup_cfg():
    cfg = get_cfg()
    # Modèle pré-entraîné de Detectron2
    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Seuil de détection
    cfg.MODEL.DEVICE = 'cuda'  # Utilisation du GPU si disponible
    return cfg

cfg = setup_cfg()
predictor = DefaultPredictor(cfg)

# Étape 1 : Calcul des centres des feuillets
def calculate_centers(masks):
    centers = []
    for mask in masks:
        coords = np.argwhere(mask)  # Coordonnées des pixels du masque
        center = coords.mean(axis=0)  # Moyenne des coordonnées (barycentre)
        centers.append(center)
    return np.array(centers)

# Étape 2 : Calcul de l'orientation des feuillets (approximée par l'angle des boîtes englobantes)
def calculate_orientations(boxes):
    orientations = []
    for box in boxes:
        x1, y1, x2, y2 = box
        angle = np.arctan2(y2 - y1, x2 - x1)  # Calcul de l'angle entre les coins
        orientations.append(angle)
    return np.array(orientations)

# Étape 3 : Regroupement spatial et par orientation
def group_feuillets_spatial_orientation(centers, orientations, eps=20, min_samples=2, orientation_threshold=0.1):
    """Regroupe les feuillets en fonction de leur proximité et de leur orientation."""
    clusters = {}
    for i, (center, orientation) in enumerate(zip(centers, orientations)):
        assigned = False
        for label, (cluster_centers, cluster_orientations) in clusters.items():
            # Vérification de la proximité spatiale
            dist = np.linalg.norm(cluster_centers - center, axis=1)
            if np.min(dist) < eps and np.abs(np.mean(cluster_orientations) - orientation) < orientation_threshold:
                clusters[label][0].append(center)  # Ajouter le centre
                clusters[label][1].append(orientation)  # Ajouter l'orientation
                assigned = True
                break
        if not assigned:  # Si le feuillet n'a pas été assigné à un groupe existant
            clusters[len(clusters)] = ([center], [orientation])
    return clusters

# Fonction pour effectuer une inférence avec Detectron2 et charger une image
def detect_feuillets(image_path):
    # Lire l'image
    im = cv2.imread(image_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    
    # Inference avec Detectron2
    outputs = predictor(im)  # Inference sur l'image

    # Masques et boîtes
    masks = outputs["instances"].pred_masks.cpu().numpy()  # Masques binaires
    boxes = outputs["instances"].pred_boxes.tensor.cpu().numpy()  # Bounding boxes
    return masks, boxes, im, outputs

# Fonction pour appliquer les couleurs et overlay les groupes sur l'image
def visualize_clusters_on_image(image, clusters, masks, boxes):
    # Utiliser OverlayInstances de Detectron2 pour colorier les prédictions par groupe
    colors = plt.cm.get_cmap("tab20", len(clusters))  # Colormap pour attribuer une couleur à chaque groupe
    instance_masks = []
    instance_labels = []
    for label, (cluster_centers, cluster_orientations) in clusters.items():
        color = colors(label)  # Récupérer la couleur pour le groupe
        for i, center in enumerate(cluster_centers):
            # Trouver l'indice correspondant au centre
            distances = np.linalg.norm(masks - center, axis=1)
            idx = np.argmin(distances)
            
            # Ajouter un masque pour cette instance (avec la couleur du groupe)
            mask = masks[idx]
            instance_masks.append(mask)
            instance_labels.append(label)
    
    # Créer une nouvelle instance de "Instances" pour OverlayInstances
    instances = Instances(image.shape[:2])
    instances.pred_masks = torch.tensor(np.array(instance_masks))  # Masques des instances
    instances.pred_classes = torch.tensor(instance_labels)  # Classes des instances (groupes ici)
    
    # Visualiser avec Visualizer et OverlayInstances
    v = Visualizer(image, metadata=None, scale=1.0)
    v.overlay_instances(masks=instances.pred_masks, labels=instances.pred_classes)
    return v.get_image()

# Exemple d'utilisation sur une image de ton jeu de test
image_path = "path/to/your/image.jpg"  # Remplacer par le chemin de ton image
masks, boxes, im, outputs = detect_feuillets(image_path)

# Calcul des centres
centers = calculate_centers(masks)

# Calcul des orientations (en radians)
orientations = calculate_orientations(boxes)

# Regroupement spatial et orientation
clusters = group_feuillets_spatial_orientation(centers, orientations, eps=30, min_samples=2, orientation_threshold=0.1)

# Visualiser les regroupements sur l'image originale
image_with_clusters = visualize_clusters_on_image(im.copy(), clusters, masks, boxes)

# Affichage de l'image avec les regroupements
plt.figure(figsize=(10, 6))
plt.imshow(image_with_clusters)
plt.title("Regroupement des feuillets (proximité et orientation)")
plt.axis('off')  # Désactiver les axes
plt.show()
