import torch
import numpy as np
import cv2
import matplotlib.pyplot as plt
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo
from sklearn.cluster import DBSCAN

# Chargement du modèle Detectron2
def setup_cfg():
    cfg = get_cfg()
    # Modèle pré-entraîné de Detectron2
    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Seuil de détection
    cfg.MODEL.DEVICE = 'cuda'  # Utilisation du GPU si disponible
    return cfg

cfg = setup_cfg()
predictor = DefaultPredictor(cfg)

# Étape 1 : Calcul des centres des feuillets
def calculate_centers(masks):
    centers = []
    for mask in masks:
        coords = np.argwhere(mask)  # Coordonnées des pixels du masque
        center = coords.mean(axis=0)  # Moyenne des coordonnées (barycentre)
        centers.append(center)
    return np.array(centers)

# Étape 2 : Calcul de l'orientation des feuillets (approximée par l'angle des boîtes englobantes)
def calculate_orientations(boxes):
    orientations = []
    for box in boxes:
        x1, y1, x2, y2 = box
        angle = np.arctan2(y2 - y1, x2 - x1)  # Calcul de l'angle entre les coins
        orientations.append(angle)
    return np.array(orientations)

# Étape 3 : Regroupement spatial et par orientation
def group_feuillets_spatial_orientation(centers, orientations, eps=20, min_samples=2, orientation_threshold=0.1):
    """Regroupe les feuillets en fonction de leur proximité et de leur orientation."""
    clusters = {}
    for i, (center, orientation) in enumerate(zip(centers, orientations)):
        assigned = False
        for label, (cluster_centers, cluster_orientations) in clusters.items():
            # Vérification de la proximité spatiale
            dist = np.linalg.norm(cluster_centers - center, axis=1)
            if np.min(dist) < eps and np.abs(np.mean(cluster_orientations) - orientation) < orientation_threshold:
                clusters[label][0].append(center)  # Ajouter le centre
                clusters[label][1].append(orientation)  # Ajouter l'orientation
                assigned = True
                break
        if not assigned:  # Si le feuillet n'a pas été assigné à un groupe existant
            clusters[len(clusters)] = ([center], [orientation])
    return clusters

# Étape 4 : Calcul de la longueur moyenne pour chaque cluster
def calculate_cluster_lengths(clusters, masks, boxes):
    cluster_lengths = {}
    for label, (centers, orientations) in clusters.items():
        lengths = []
        for center in centers:
            # Trouver le masque correspondant au centre
            distances = np.linalg.norm(centers - center, axis=1)
            idx = np.argmin(distances)  # Trouver l'indice du centre le plus proche
            mask = masks[idx]  # Sélectionner le masque associé à cet indice

            # Calculer la longueur de la boîte pour ce masque
            box = boxes[idx]
            length = box[3] - box[1]  # Calculer la hauteur de la boîte englobante
            lengths.append(length)

        cluster_lengths[label] = np.mean(lengths)
    return cluster_lengths

# Fonction pour effectuer une inférence avec Detectron2 et charger une image
def detect_feuillets(image_path):
    # Lire l'image
    im = cv2.imread(image_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    
    # Inference avec Detectron2
    outputs = predictor(im)  # Inference sur l'image

    # Masques et boîtes
    masks = outputs["instances"].pred_masks.cpu().numpy()  # Masques binaires
    boxes = outputs["instances"].pred_boxes.tensor.cpu().numpy()  # Bounding boxes
    return masks, boxes, im

# Fonction pour visualiser les regroupements sur l'image originale
def visualize_clusters_on_image(image, clusters, centers, colors):
    # Dessiner les clusters sur l'image originale
    for label, (cluster_centers, cluster_orientations) in clusters.items():
        color = colors[label % len(colors)]  # Attribuer une couleur unique par cluster
        for center in cluster_centers:
            cv2.circle(image, tuple(center.astype(int)), 10, color, -1)  # Marquer les centres
    return image

# Exemple d'utilisation sur une image de ton jeu de test
image_path = "path/to/your/image.jpg"  # Remplacer par le chemin de ton image
masks, boxes, im = detect_feuillets(image_path)

# Calcul des centres
centers = calculate_centers(masks)

# Calcul des orientations (en radians)
orientations = calculate_orientations(boxes)

# Regroupement spatial et orientation
clusters = group_feuillets_spatial_orientation(centers, orientations, eps=30, min_samples=2, orientation_threshold=0.1)

# Préparer une palette de couleurs pour chaque groupe
colors = plt.cm.tab20.colors  # Extrait directement la liste des couleurs à partir de la colormap 'tab20'

# Visualiser les regroupements sur l'image originale
image_with_clusters = visualize_clusters_on_image(im.copy(), clusters, centers, colors)

# Affichage de l'image avec les regroupements
plt.figure(figsize=(10, 6))
plt.imshow(image_with_clusters)
plt.title("Regroupement des feuillets (proximité et orientation)")
plt.axis('off')  # Désactiver les axes
plt.show()

# Calcul des longueurs moyennes
cluster_lengths = calculate_cluster_lengths(clusters, masks, boxes)

# Préparation des données pour l'histogramme
empilement_counts = [len(centers) for centers in clusters.values()]
lengths_means = list(cluster_lengths.values())

# Affichage de l'histogramme
plt.figure(figsize=(10, 6))
plt.bar(empilement_counts, lengths_means, color='skyblue')
plt.xlabel("Nombre de feuillets par empilement")
plt.ylabel("Longueur moyenne (pixels)")
plt.title("Histogramme des longueurs moyennes par empilement (proximité et orientation)")
plt.grid(True)
plt.show()
