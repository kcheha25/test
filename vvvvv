import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors
from collections import defaultdict

# Charger les données
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Extraire les temps de pics et les noms des composants
pic_times = []
component_names = []
component_to_times = defaultdict(list)

for _, row in df.iterrows():
    for pic_time_str, data in row["pics"].items():
        pic_time = float(pic_time_str)
        if pic_time <= 150:
            comp_name = data[0]
            pic_times.append(pic_time)
            component_names.append(comp_name)
            component_to_times[comp_name].append(pic_time)

# Étape 1 : Créer les intervalles min/max pour chaque composant
component_intervals = {
    comp: (min(times), max(times)) for comp, times in component_to_times.items()
}

# Étape 2 : Fusionner les composants dont les intervalles se chevauchent
merged_components = []
visited = set()

for comp1 in component_intervals:
    if comp1 in visited:
        continue
    group = {comp1}
    min1, max1 = component_intervals[comp1]
    for comp2 in component_intervals:
        if comp2 != comp1 and comp2 not in visited:
            min2, max2 = component_intervals[comp2]
            if max1 >= min2 and max2 >= min1:  # chevauchement
                group.add(comp2)
                min1 = min(min1, min2)
                max1 = max(max1, max2)
    merged_components.append((group, (min1, max1)))
    visited.update(group)

# Étape 3 : Créer un mapping temps → nom commun
pic_time_to_group_name = {}
for group, (min_time, max_time) in merged_components:
    group_name = "+".join(sorted(group))
    for comp in group:
        for t in component_to_times[comp]:
            if min_time <= t <= max_time:
                pic_time_to_group_name[t] = group_name

# Reconstruction des données finales
filtered_pic_times = []
filtered_component_names = []

for t in pic_times:
    if t in pic_time_to_group_name:
        filtered_pic_times.append(t)
        filtered_component_names.append(pic_time_to_group_name[t])

# Étape 4 : NearestNeighbors pour attribution des noms
X = np.array(filtered_pic_times).reshape(-1, 1) / 150.0
component_names_array = np.array(filtered_component_names)
nbrs = NearestNeighbors(n_neighbors=5)
nbrs.fit(X)

# Exemple de prédiction de noms sur des pics détectés
# Exemple avec un tableau fictif x_full, y_full, probs_full
# (à remplacer par tes vrais vecteurs)

detected_peaks = []
pic_info_dict = {}
previous_name = None
threshold = 0.4
i = 3

while i < len(probs_full) - 3:
    if probs_full[i] > threshold:
        window = probs_full[i - 3:i + 4]
        if np.any(window > threshold):
            idx_window = np.arange(i - 3, i + 4)
            idx_max_intensity = idx_window[np.argmax(y_full[idx_window])]
            detected_peaks.append(idx_max_intensity)

            # Temps détecté
            pic_time_detected = x_full[idx_max_intensity]
            pic_time_norm = pic_time_detected / 150.0

            # Trouver les k plus proches voisins
            _, indices = nbrs.kneighbors([[pic_time_norm]])
            candidate_names = component_names_array[indices[0]]

            # Éviter de réattribuer le même nom que précédemment
            for name in candidate_names:
                if name != previous_name:
                    selected_name = name
                    break
            else:
                selected_name = candidate_names[0]

            previous_name = selected_name
            pic_info_dict[pic_time_detected] = selected_name

            i += 4
        else:
            i += 1
    else:
        i += 1

# Résultat final
print(pic_info_dict)


# Étape 2 : Fusionner les composants dont les intervalles se chevauchent
merged_components = []
visited = set()

for comp1 in component_intervals:
    if comp1 in visited:
        continue
    group = {comp1}
    min1, max1 = component_intervals[comp1]
    for comp2 in component_intervals:
        if comp2 != comp1 and comp2 not in visited:
            min2, max2 = component_intervals[comp2]
            if max1 >= min2 and max2 >= min1:  # chevauchement
                group.add(comp2)
                min1 = min(min1, min2)
                max1 = max(max1, max2)
    visited.update(group)

    # Étape 2.5 : Si plus de 4 composants, rediviser le groupe
    if len(group) > 4:
        group = list(group)
        subgroups = []
        group_remaining = set(group)

        while group_remaining:
            # Trouver le composant avec le plus grand intervalle
            max_interval_comp = max(group_remaining, key=lambda c: component_intervals[c][1] - component_intervals[c][0])
            minA, maxA = component_intervals[max_interval_comp]
            subgroup = {max_interval_comp}

            for other in group_remaining:
                if other == max_interval_comp:
                    continue
                minB, maxB = component_intervals[other]
                if maxA >= minB and maxB >= minA:  # chevauchement direct
                    subgroup.add(other)

            subgroups.append((subgroup, (
                min(component_intervals[c][0] for c in subgroup),
                max(component_intervals[c][1] for c in subgroup)
            )))
            group_remaining -= subgroup

        merged_components.extend(subgroups)
    else:
        merged_components.append((group, (min1, max1)))

# Étape 3 : Créer un mapping temps → nom commun
pic_time_to_group_name = {}
for group, (min_time, max_time) in merged_components:
    group_name = "+".join(sorted(group))
    for comp in group:
        for t in component_to_times[comp]:
            if min_time <= t <= max_time:
                pic_time_to_group_name[t] = group_name

# Reconstruction des données finales
filtered_pic_times = []
filtered_component_names = []

for t in pic_times:
    if t in pic_time_to_group_name:
        filtered_pic_times.append(t)
        filtered_component_names.append(pic_time_to_group_name[t])

all_chromatograms = []

for _, row in df.iterrows():
    chromatogram = []
    for pic_time_str, data in row["pics"].items():
        pic_time = float(pic_time_str)
        if pic_time <= 150:
            comp_name = data[0]
            chromatogram.append((pic_time, comp_name))
    chromatogram.sort()  # tri par temps croissant
    all_chromatograms.append(chromatogram)

from collections import defaultdict

group_to_sequences = defaultdict(set)
group_to_sequences = defaultdict(set)

for group, (min_time, max_time) in merged_components:
    group_name = "+".join(sorted(group))
    
    for _, row in df.iterrows():
        if not isinstance(row['pics'], dict):
            continue
        
        seen = set()
        sequence = []
        
        for pic_time_str, data in row['pics'].items():
            pic_time = float(pic_time_str)
            if min_time <= pic_time <= max_time:
                comp_name = data[0]
                if comp_name in group and comp_name not in seen:
                    sequence.append(comp_name)
                    seen.add(comp_name)
        
        if sequence:
            group_to_sequences[group_name].add(tuple(sequence))

# Affichage
for group_name, sequences in group_to_sequences.items():
    print(f"Groupe : {group_name}")
    for seq in sequences:
        print("  →", " → ".join(seq))
    print()

# Ou bien, les exporter en texte utilisable :
group_to_string_sequences = {
    group_name: ["/".join(seq) for seq in sequences]
    for group_name, sequences in group_to_sequences.items()
}


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn_crfsuite import CRF, metrics
from collections import defaultdict
import json

# Charger les données
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Fonction de génération des features pour chaque pic dans un chromatogramme
def extract_features_for_sequence(pic_times):
    pic_times = sorted(pic_times)
    features = []
    n = len(pic_times)
    for i, t in enumerate(pic_times):
        feat = {
            'retention_time': t,
            'index': i,
            'index_norm': i / n,
            'prev_time': pic_times[i - 1] if i > 0 else -1,
            'next_time': pic_times[i + 1] if i < n - 1 else -1,
            'diff_prev': t - pic_times[i - 1] if i > 0 else 0,
            'diff_next': pic_times[i + 1] - t if i < n - 1 else 0,
            'local_density': sum(1 for x in pic_times if abs(x - t) < 3)  # nombre de pics dans un voisinage de 3s
        }
        features.append(feat)
    return features

# Fonction pour transformer les features en format CRF
def transform_features_for_crf(features):
    return [
        {
            'time': f['retention_time'],
            'index_norm': f['index_norm'],
            'diff_prev': f['diff_prev'],
            'diff_next': f['diff_next'],
            'local_density': f['local_density']
        }
        for f in features
    ]

# Extraction des séquences
X = []
Y = []
component_to_times = defaultdict(list)

for _, row in df.iterrows():
    chromatogram_pics = row['pics']
    sequence = []
    labels = []
    for t_str, data in chromatogram_pics.items():
        t = float(t_str)
        if t <= 150:
            sequence.append(t)
            labels.append(data[0])
            component_to_times[data[0]].append(t)

    if len(sequence) > 1:
        feats = extract_features_for_sequence(sequence)
        X.append(transform_features_for_crf(feats))
        Y.append(labels)

# Séparation en train/test
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Entraînement du CRF
crf = CRF(algorithm='lbfgs', max_iterations=100, all_possible_transitions=True)
crf.fit(X_train, y_train)

# Évaluation
y_pred = crf.predict(X_test)
print("F1-score pondéré :", metrics.flat_f1_score(y_test, y_pred, average='weighted'))
print("Rapport de classification :\n", metrics.flat_classification_report(y_test, y_pred))


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import xgboost as xgb
from collections import defaultdict
from sklearn.metrics import accuracy_score, classification_report

# Charger les données
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Fonction de génération des features pour chaque pic dans un chromatogramme
def extract_features_for_sequence(pic_times):
    pic_times = sorted(pic_times)
    features = []
    n = len(pic_times)
    for i, t in enumerate(pic_times):
        feat = {
            'retention_time': t,
            'index': i,
            'index_norm': i / n,
            'prev_time': pic_times[i - 1] if i > 0 else -1,
            'next_time': pic_times[i + 1] if i < n - 1 else -1,
            'diff_prev': t - pic_times[i - 1] if i > 0 else 0,
            'diff_next': pic_times[i + 1] - t if i < n - 1 else 0,
            'local_density': sum(1 for x in pic_times if abs(x - t) < 3)  # nombre de pics dans un voisinage de 3s
        }
        features.append(feat)
    return features

# Extraction des séquences et des labels
X = []
Y = []
component_to_times = defaultdict(list)

for _, row in df.iterrows():
    chromatogram_pics = row['pics']
    sequence = []
    labels = []
    for t_str, data in chromatogram_pics.items():
        t = float(t_str)
        if t <= 150:
            sequence.append(t)
            labels.append(data[0])
            component_to_times[data[0]].append(t)

    if len(sequence) > 1:
        feats = extract_features_for_sequence(sequence)
        # Convertir les features en un format plat pour XGBoost
        X.append([f['retention_time'] for f in feats] +
                 [f['index_norm'] for f in feats] +
                 [f['diff_prev'] for f in feats] +
                 [f['diff_next'] for f in feats] +
                 [f['local_density'] for f in feats])
        Y.append(labels)

# Convertir les labels en indices
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
Y_flat = [item for sublist in Y for item in sublist]
label_encoder.fit(Y_flat)
Y_encoded = [label_encoder.transform(y) for y in Y]

# Aplatir X et Y pour correspondre au format de XGBoost
X_flat = [item for sublist in X for item in sublist]

# Séparer en train/test
X_train, X_test, y_train, y_test = train_test_split(X_flat, Y_encoded, test_size=0.2, random_state=42)

# Convertir les données en matrices DMatrix XGBoost
X_train = xgb.DMatrix(X_train, label=y_train)
X_test = xgb.DMatrix(X_test, label=y_test)

# Entraînement du modèle XGBoost
params = {
    'objective': 'multi:softmax',  # Classification multi-classes
    'num_class': len(label_encoder.classes_),  # Nombre de classes
    'eval_metric': 'merror'  # Erreur de classification
}
model = xgb.train(params, X_train, num_boost_round=100)

# Prédictions sur les données de test
y_pred = model.predict(X_test)

# Conversion des prédictions en labels
y_pred_labels = label_encoder.inverse_transform(y_pred.astype(int))

# Évaluation
print("Accuracy:", accuracy_score(y_test, y_pred_labels))
print("Classification Report:\n", classification_report(y_test, y_pred_labels))


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from collections import defaultdict

# Charger les données
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Fonction de génération des features pour chaque pic dans un chromatogramme
def extract_features_for_sequence(pic_times):
    pic_times = sorted(pic_times)
    features = []
    n = len(pic_times)
    for i, t in enumerate(pic_times):
        feat = {
            'retention_time': t,
            'index': i,
            'index_norm': i / n,
            'prev_time': pic_times[i - 1] if i > 0 else -1,
            'next_time': pic_times[i + 1] if i < n - 1 else -1,
            'diff_prev': t - pic_times[i - 1] if i > 0 else 0,
            'diff_next': pic_times[i + 1] - t if i < n - 1 else 0,
            'local_density': sum(1 for x in pic_times if abs(x - t) < 3)  # nombre de pics dans un voisinage de 3s
        }
        features.append(feat)
    return features

# Extraction des séquences et des labels
X = []
Y = []
component_to_times = defaultdict(list)

for _, row in df.iterrows():
    chromatogram_pics = row['pics']
    sequence = []
    labels = []
    for t_str, data in chromatogram_pics.items():
        t = float(t_str)
        if t <= 150:
            sequence.append(t)
            labels.append(data[0])
            component_to_times[data[0]].append(t)

    if len(sequence) > 1:
        feats = extract_features_for_sequence(sequence)
        # Convertir les features en un format plat pour KNN
        X.append([f['retention_time'] for f in feats] +
                 [f['index_norm'] for f in feats] +
                 [f['diff_prev'] for f in feats] +
                 [f['diff_next'] for f in feats] +
                 [f['local_density'] for f in feats])
        Y.append(labels)

# Convertir les labels en indices
label_encoder = LabelEncoder()
Y_flat = [item for sublist in Y for item in sublist]
label_encoder.fit(Y_flat)
Y_encoded = [label_encoder.transform(y) for y in Y]

# Aplatir X et Y pour correspondre au format de KNN
X_flat = [item for sublist in X for item in sublist]
Y_flat = [item for sublist in Y_encoded for item in sublist]

# Séparer en train/test
X_train, X_test, y_train, y_test = train_test_split(X_flat, Y_flat, test_size=0.2, random_state=42)

# Entraînement du modèle KNN
knn = KNeighborsClassifier(n_neighbors=5)  # Choisis un nombre approprié de voisins (k)
knn.fit(X_train, y_train)

# Prédictions sur les données de test
y_pred = knn.predict(X_test)

# Conversion des prédictions en labels
y_pred_labels = label_encoder.inverse_transform(y_pred)

# Évaluation
print("Accuracy:", accuracy_score(y_test, y_pred_labels))
print("Classification Report:\n", classification_report(y_test, y_pred_labels))
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, BertForSequenceClassification, AdamW
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd
import numpy as np
from collections import defaultdict

# Charger les données
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Fonction de génération des features pour chaque pic dans un chromatogramme
def extract_features_for_sequence(pic_times):
    pic_times = sorted(pic_times)
    features = []
    n = len(pic_times)
    for i, t in enumerate(pic_times):
        feat = {
            'retention_time': t,
            'index': i,
            'index_norm': i / n,
            'prev_time': pic_times[i - 1] if i > 0 else -1,
            'next_time': pic_times[i + 1] if i < n - 1 else -1,
            'diff_prev': t - pic_times[i - 1] if i > 0 else 0,
            'diff_next': pic_times[i + 1] - t if i < n - 1 else 0,
            'local_density': sum(1 for x in pic_times if abs(x - t) < 3)  # nombre de pics dans un voisinage de 3s
        }
        features.append(feat)
    return features

# Extraction des séquences et des labels
X = []
Y = []
component_to_times = defaultdict(list)

for _, row in df.iterrows():
    chromatogram_pics = row['pics']
    sequence = []
    labels = []
    for t_str, data in chromatogram_pics.items():
        t = float(t_str)
        if t <= 150:
            sequence.append(t)
            labels.append(data[0])
            component_to_times[data[0]].append(t)

    if len(sequence) > 1:
        feats = extract_features_for_sequence(sequence)
        # Convertir les features en un format adapté pour BERT
        X.append([f['retention_time'] for f in feats] +
                 [f['index_norm'] for f in feats] +
                 [f['diff_prev'] for f in feats] +
                 [f['diff_next'] for f in feats] +
                 [f['local_density'] for f in feats])
        Y.append(labels)

# Convertir les labels en indices
label_encoder = LabelEncoder()
Y_flat = [item for sublist in Y for item in sublist]
label_encoder.fit(Y_flat)
Y_encoded = [label_encoder.transform(y) for y in Y]

# Aplatir X et Y pour correspondre au format
X_flat = [item for sublist in X for item in sublist]
Y_flat = [item for sublist in Y_encoded for item in sublist]

# Séparer en train/test
X_train, X_test, y_train, y_test = train_test_split(X_flat, Y_flat, test_size=0.2, random_state=42)

# Transformer les séquences pour qu'elles soient compatibles avec BERT
class ChromatogramDataset(Dataset):
    def __init__(self, X, Y, tokenizer, max_len=512):
        self.X = X
        self.Y = Y
        self.tokenizer = tokenizer
        self.max_len = max_len
    
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, item):
        seq = self.X[item]
        label = self.Y[item]
        
        # Tokenization avec padding et truncation pour BERT
        inputs = self.tokenizer(
            seq, 
            max_length=self.max_len,
            padding='max_length', 
            truncation=True,
            return_tensors='pt'
        )
        return {
            'input_ids': inputs['input_ids'].flatten(),
            'attention_mask': inputs['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

# Initialiser le tokenizer BERT
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Créer les datasets
train_dataset = ChromatogramDataset(X_train, y_train, tokenizer)
test_dataset = ChromatogramDataset(X_test, y_test, tokenizer)

# Créer les DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16)

# Initialiser le modèle BERT pour la classification
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))

# Définir l'optimiseur
optimizer = AdamW(model.parameters(), lr=2e-5)

# Entraînement du modèle
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

num_epochs = 3

for epoch in range(num_epochs):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        
        # Forward pass
        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
    
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}")

# Évaluation du modèle
model.eval()
y_pred = []
y_true = []

for batch in test_loader:
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    labels = batch['labels'].to(device)
    
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        _, preds = torch.max(outputs.logits, dim=1)
    
    y_pred.extend(preds.cpu().numpy())
    y_true.extend(labels.cpu().numpy())

# Conversion des prédictions en labels
y_pred_labels = label_encoder.inverse_transform(y_pred)
y_true_labels = label_encoder.inverse_transform(y_true)

# Évaluation
print("Accuracy:", accuracy_score(y_true_labels, y_pred_labels))
print("Classification Report:\n", classification_report(y_true_labels, y_pred_labels))


merged_components = []
visited = set()

for comp1 in component_intervals:
    if comp1 in visited:
        continue
    group = {comp1}
    min1, max1 = component_intervals[comp1]
    for comp2 in component_intervals:
        if comp2 != comp1 and comp2 not in visited:
            min2, max2 = component_intervals[comp2]
            if max1 >= min2 and max2 >= min1:  # chevauchement
                group.add(comp2)
                min1 = min(min1, min2)
                max1 = max(max1, max2)
    visited.update(group)

    # Si le groupe contient plus de 4 composants, le rediviser selon chevauchement dans une fenêtre de 1s
    if len(group) > 4:
        group = list(group)
        subgroups = []
        used = set()

        for i, compA in enumerate(group):
            if compA in used:
                continue
            subgroup = {compA}
            used.add(compA)
            minA, maxA = component_intervals[compA]

            for compB in group:
                if compB in used:
                    continue
                minB, maxB = component_intervals[compB]

                # Vérifie chevauchement direct et proximité (écart max 1s entre les intervalles)
                if maxA >= minB and maxB >= minA and abs(minA - minB) <= 1 and abs(maxA - maxB) <= 1:
                    subgroup.add(compB)
                    used.add(compB)

            sub_min = min(component_intervals[c][0] for c in subgroup)
            sub_max = max(component_intervals[c][1] for c in subgroup)
            subgroups.append((subgroup, (sub_min, sub_max)))

        merged_components.extend(subgroups)
    else:
        merged_components.append((group, (min1, max1)))

# Étape 3 : Créer un mapping temps → nom commun
pic_time_to_group_name = {}
for group, (min_time, max_time) in merged_components:
    group_name = "+".join(sorted(group))
    for comp in group:
        for t in component_to_times[comp]:
            if min_time <= t <= max_time:
                pic_time_to_group_name[t] = group_name

# Reconstruction des données finales
filtered_pic_times = []
filtered_component_names = []

for t in pic_times:
    if t in pic_time_to_group_name:
        filtered_pic_times.append(t)
        filtered_component_names.append(pic_time_to_group_name[t])


def subdivide_group(group, component_intervals):
    group = list(group)
    subgroups = []
    used = set()

    for i, compA in enumerate(group):
        if compA in used:
            continue
        subgroup = {compA}
        used.add(compA)
        minA, maxA = component_intervals[compA]

        for compB in group:
            if compB in used:
                continue
            minB, maxB = component_intervals[compB]

            # Vérifie chevauchement direct et proximité (écart max 1s entre les intervalles)
            if maxA >= minB and maxB >= minA and abs(minA - minB) <= 1 and abs(maxA - maxB) <= 1:
                subgroup.add(compB)
                used.add(compB)

        sub_min = min(component_intervals[c][0] for c in subgroup)
        sub_max = max(component_intervals[c][1] for c in subgroup)
        subgroups.append((subgroup, (sub_min, sub_max)))
    
    return subgroups


merged_components = []
visited = set()

# Première fusion des composants par chevauchement
for comp1 in component_intervals:
    if comp1 in visited:
        continue
    group = {comp1}
    min1, max1 = component_intervals[comp1]
    for comp2 in component_intervals:
        if comp2 != comp1 and comp2 not in visited:
            min2, max2 = component_intervals[comp2]
            if max1 >= min2 and max2 >= min1:
                group.add(comp2)
                min1 = min(min1, min2)
                max1 = max(max1, max2)
    visited.update(group)

    merged_components.append((group, (min1, max1)))

# Répéter la subdivision 4 fois
for _ in range(4):
    new_merged_components = []
    for group, (min_time, max_time) in merged_components:
        if len(group) > 4:
            subgroups = subdivide_group(group, component_intervals)
            new_merged_components.extend(subgroups)
        else:
            new_merged_components.append((group, (min_time, max_time)))
    merged_components = new_merged_components

# Création du mapping temps → nom de groupe
pic_time_to_group_name = {}
for group, (min_time, max_time) in merged_components:
    group_name = "+".join(sorted(group))
    for comp in group:
        for t in component_to_times[comp]:
            if min_time <= t <= max_time:
                pic_time_to_group_name[t] = group_name

# Reconstruction des données finales
filtered_pic_times = []
filtered_component_names = []

for t in pic_times:
    if t in pic_time_to_group_name:
        filtered_pic_times.append(t)
        filtered_component_names.append(pic_time_to_group_name[t])

import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from collections import defaultdict, Counter
import random

# Charger les données
file_path = "chromatogrammes.json"
df = pd.read_json(file_path)
df = df.dropna(subset=['pics'])

# Charger ton modèle ici (ajuste cette ligne selon ton framework)
from tensorflow.keras.models import load_model
model = load_model("chemin_vers_ton_modele.h5")  # à adapter

# Fonction de détection de pics par le modèle
def detect_peaks(row):
    x = np.array(row["x"])
    y = np.array(row["y"])
    y = y / np.max(y)

    segment_size = 1000
    num_segments = len(x) // segment_size
    x_segments, y_segments, segments = [], [], []

    for i in range(num_segments):
        start = i * segment_size
        end = start + segment_size
        segment_x = x[start:end]
        segment_y = y[start:end]
        segment_input = np.stack([segment_x, segment_y], axis=-1)
        x_segments.append(segment_x)
        y_segments.append(segment_y)
        segments.append(segment_input)

    probs_segments = []
    for seg in segments:
        seg_input = np.expand_dims(seg, axis=0)
        pred = model.predict(seg_input, verbose=0)
        pred = pred[0, :, 0] if pred.ndim == 3 else pred[0]
        probs_segments.append(pred)

    x_full = np.concatenate(x_segments)
    y_full = np.concatenate(y_segments)
    probs_full = np.concatenate(probs_segments)

    return x_full, y_full, probs_full

# Préparation des données pour Nearest Neighbors
pic_times = []
component_names = []

for _, row in df.iterrows():
    for pic_time_str, data in row["pics"].items():
        pic_time = float(pic_time_str)
        if pic_time <= 150:
            pic_times.append(pic_time)
            component_names.append(data[0])

X_train = np.array(pic_times, dtype=np.float32).reshape(-1, 1) / 150.0
nbrs = NearestNeighbors(n_neighbors=1, radius=0.4).fit(X_train)

# Dictionnaire pour collecter les confusions
confusions = defaultdict(list)

# Analyse de tous les chromatogrammes
for _, row in df.iterrows():
    x_full, y_full, probs_full = detect_peaks(row)

    detected_peaks = []
    threshold = 0.4
    i = 3
    pred_info = {}

    while i < len(probs_full) - 3:
        if probs_full[i] > threshold:
            window = probs_full[i - 3:i + 4]
            if np.any(window > threshold):
                idx_window = np.arange(i - 3, i + 4)
                idx_max_intensity = idx_window[np.argmax(y_full[idx_window])]
                detected_peaks.append(idx_max_intensity)

                pic_time_detected = x_full[idx_max_intensity]
                pic_time_normalized = pic_time_detected / 150.0

                _, indices = nbrs.kneighbors([[pic_time_normalized]])
                closest_index = indices[0][0]
                closest_component = component_names[closest_index]

                pred_info[pic_time_detected] = closest_component
                i += 4
            else:
                i += 1
        else:
            i += 1

    # Comparaison avec la vérité terrain
    true_peaks = {
        float(k): v[0] for k, v in row["pics"].items() if float(k) <= 150
    }

    for pred_time, pred_name in pred_info.items():
        if not true_peaks:
            continue
        closest_true_time = min(true_peaks.keys(), key=lambda t: abs(t - pred_time))
        true_name = true_peaks[closest_true_time]

        if pred_name != true_name:
            confusions[(true_name, pred_name)].append((closest_true_time, pred_time))

# Analyser les confusions fréquentes
confusion_counter = Counter((min(k), max(k)) for k in confusions.keys())
groups = defaultdict(set)

for (a, b), count in confusion_counter.items():
    if count > 2:  # Ajuste ce seuil selon tes données
        groups[a].add(a)
        groups[a].add(b)
        groups[b] = groups[a]

# Fusionner les groupes
final_groups = []
seen = set()

for k, members in groups.items():
    if not members & seen:
        final_groups.append(members)
        seen.update(members)

# Affichage
print("Groupes de composants confondus :")
for i, group in enumerate(final_groups, 1):
    print(f"Groupe {i}: {', '.join(sorted(group))}")
