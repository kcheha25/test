Plus le nombre de couches augmente, plus il est difficile d’entraîner le modèle à cause du problème de dégradation du gradient. Les sauts de connexion facilitent la rétropropagation car le gradient peut passer directement à travers ces raccourcis. Cela permet d’entraîner des réseaux beaucoup plus profonds sans perte de performance.